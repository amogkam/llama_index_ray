
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.tune.impl.tuner_internal &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/versionwarning.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../../_static/js/docsearch.js"></script>
    <script src="../../../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../../_static/js/top-navigation.js"></script>
    <script src="../../../../_static/js/tags.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/tune/impl/tuner_internal.html" />
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "_modules/ray/tune/impl/tuner_internal", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/tune/impl/tuner_internal.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.tune.impl.tuner_internal</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.cloudpickle</span> <span class="k">as</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">ray.util</span> <span class="kn">import</span> <span class="n">inspect_serializability</span>
<span class="kn">from</span> <span class="nn">ray.air._internal.remote_storage</span> <span class="kn">import</span> <span class="n">download_from_uri</span><span class="p">,</span> <span class="n">is_non_local_path_uri</span>
<span class="kn">from</span> <span class="nn">ray.air._internal.uri_utils</span> <span class="kn">import</span> <span class="n">URI</span>
<span class="kn">from</span> <span class="nn">ray.air._internal.usage</span> <span class="kn">import</span> <span class="n">AirEntrypoint</span>
<span class="kn">from</span> <span class="nn">ray.air.config</span> <span class="kn">import</span> <span class="n">RunConfig</span><span class="p">,</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.tune</span> <span class="kn">import</span> <span class="n">Experiment</span><span class="p">,</span> <span class="n">TuneError</span><span class="p">,</span> <span class="n">ExperimentAnalysis</span>
<span class="kn">from</span> <span class="nn">ray.tune.execution.experiment_state</span> <span class="kn">import</span> <span class="n">_ResumeConfig</span>
<span class="kn">from</span> <span class="nn">ray.tune.tune</span> <span class="kn">import</span> <span class="n">_Config</span>
<span class="kn">from</span> <span class="nn">ray.tune.registry</span> <span class="kn">import</span> <span class="n">is_function_trainable</span>
<span class="kn">from</span> <span class="nn">ray.tune.result_grid</span> <span class="kn">import</span> <span class="n">ResultGrid</span>
<span class="kn">from</span> <span class="nn">ray.tune.trainable</span> <span class="kn">import</span> <span class="n">Trainable</span>
<span class="kn">from</span> <span class="nn">ray.tune.tune</span> <span class="kn">import</span> <span class="n">run</span>
<span class="kn">from</span> <span class="nn">ray.tune.tune_config</span> <span class="kn">import</span> <span class="n">TuneConfig</span>
<span class="kn">from</span> <span class="nn">ray.tune.utils</span> <span class="kn">import</span> <span class="n">flatten_dict</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">ray.train.trainer</span> <span class="kn">import</span> <span class="n">BaseTrainer</span>
    <span class="kn">from</span> <span class="nn">ray.util.queue</span> <span class="kn">import</span> <span class="n">Queue</span>


<span class="n">_TUNER_PKL</span> <span class="o">=</span> <span class="s2">&quot;tuner.pkl&quot;</span>
<span class="n">_TRAINABLE_KEY</span> <span class="o">=</span> <span class="s2">&quot;_trainable&quot;</span>
<span class="n">_CONVERTED_TRAINABLE_KEY</span> <span class="o">=</span> <span class="s2">&quot;_converted_trainable&quot;</span>
<span class="n">_PARAM_SPACE_KEY</span> <span class="o">=</span> <span class="s2">&quot;_param_space&quot;</span>
<span class="n">_EXPERIMENT_ANALYSIS_KEY</span> <span class="o">=</span> <span class="s2">&quot;_experiment_analysis&quot;</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">TrainableType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">Trainable</span><span class="p">]]</span>
<span class="n">TrainableTypeOrTrainer</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">TrainableType</span><span class="p">,</span> <span class="s2">&quot;BaseTrainer&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="TunerInternal"><a class="viewcode-back" href="../../../../tune/api/internals.html#ray.tune.impl.tuner_internal.TunerInternal">[docs]</a><span class="k">class</span> <span class="nc">TunerInternal</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;The real implementation behind external facing ``Tuner``.</span>

<span class="sd">    The external facing ``Tuner`` multiplexes between local Tuner and remote Tuner</span>
<span class="sd">    depending on whether in Ray client mode.</span>

<span class="sd">    In Ray client mode, external ``Tuner`` wraps ``TunerInternal`` into a remote actor,</span>
<span class="sd">    which is guaranteed to be placed on head node.</span>

<span class="sd">    ``TunerInternal`` can be constructed from fresh, in which case, ``trainable`` needs</span>
<span class="sd">    to be provided, together with optional ``param_space``, ``tune_config`` and</span>
<span class="sd">    ``run_config``.</span>

<span class="sd">    It can also be restored from a previous failed run (given ``restore_path``).</span>

<span class="sd">    Args:</span>
<span class="sd">        restore_path: The path from where the Tuner can be restored. If provided, None</span>
<span class="sd">            of the rest args are needed.</span>
<span class="sd">        resume_config: Resume config to configure which trials to continue.</span>
<span class="sd">        trainable: The trainable to be tuned.</span>
<span class="sd">        param_space: Search space of the tuning job.</span>
<span class="sd">            One thing to note is that both preprocessor and dataset can be tuned here.</span>
<span class="sd">        tune_config: Tuning algorithm specific configs.</span>
<span class="sd">            Refer to ray.tune.tune_config.TuneConfig for more info.</span>
<span class="sd">        run_config: Runtime configuration that is specific to individual trials.</span>
<span class="sd">            If passed, this will overwrite the run config passed to the Trainer,</span>
<span class="sd">            if applicable. Refer to ray.air.config.RunConfig for more info.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">restore_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resume_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ResumeConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trainable</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TrainableTypeOrTrainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">param_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tune_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TuneConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">run_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RunConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_tuner_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_entrypoint</span><span class="p">:</span> <span class="n">AirEntrypoint</span> <span class="o">=</span> <span class="n">AirEntrypoint</span><span class="o">.</span><span class="n">TUNER</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="kn">from</span> <span class="nn">ray.train.trainer</span> <span class="kn">import</span> <span class="n">BaseTrainer</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="n">BaseTrainer</span><span class="p">):</span>
            <span class="n">run_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_choose_run_config</span><span class="p">(</span>
                <span class="n">tuner_run_config</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span>
                <span class="n">trainer</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
                <span class="n">param_space</span><span class="o">=</span><span class="n">param_space</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span> <span class="o">=</span> <span class="n">tune_config</span> <span class="ow">or</span> <span class="n">TuneConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span> <span class="o">=</span> <span class="n">run_config</span> <span class="ow">or</span> <span class="n">RunConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_entrypoint</span> <span class="o">=</span> <span class="n">_entrypoint</span>

        <span class="c1"># Restore from Tuner checkpoint.</span>
        <span class="k">if</span> <span class="n">restore_path</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_restore_from_path_or_uri</span><span class="p">(</span>
                <span class="n">path_or_uri</span><span class="o">=</span><span class="n">restore_path</span><span class="p">,</span>
                <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
                <span class="n">overwrite_param_space</span><span class="o">=</span><span class="n">param_space</span><span class="p">,</span>
                <span class="n">resume_config</span><span class="o">=</span><span class="n">resume_config</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># Start from fresh</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">TuneError</span><span class="p">(</span><span class="s2">&quot;You need to provide a trainable to tune.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">trainable</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_trainable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">param_space</span> <span class="o">=</span> <span class="n">param_space</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_restored</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tuner_kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">_tuner_kwargs</span><span class="p">)</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_checkpoint_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_create_experiment_checkpoint_dir</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_analysis</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># This needs to happen before `tune.run()` is kicked in.</span>
        <span class="c1"># This is because currently tune does not exit gracefully if</span>
        <span class="c1"># run in ray client mode - if crash happens, it just exits immediately</span>
        <span class="c1"># without allowing for checkpointing tuner and trainable.</span>
        <span class="c1"># Thus this has to happen before tune.run() so that we can have something</span>
        <span class="c1"># to restore from.</span>
        <span class="n">experiment_checkpoint_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_experiment_checkpoint_dir</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">experiment_checkpoint_path</span> <span class="o">/</span> <span class="n">_TUNER_PKL</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">(),</span> <span class="n">fp</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_warn_resource_contention</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_run_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RunConfig</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span>

    <span class="c1"># For Jupyter output with Ray Client</span>
    <span class="k">def</span> <span class="nf">set_run_config_and_remote_string_queue</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">run_config</span><span class="p">:</span> <span class="n">RunConfig</span><span class="p">,</span> <span class="n">string_queue</span><span class="p">:</span> <span class="s2">&quot;Queue&quot;</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span> <span class="o">=</span> <span class="n">run_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tuner_kwargs</span><span class="p">[</span><span class="s2">&quot;_remote_string_queue&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">string_queue</span>

    <span class="k">def</span> <span class="nf">clear_remote_string_queue</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tuner_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_remote_string_queue&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_expected_utilization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cpus_per_trial</span><span class="p">,</span> <span class="n">cpus_total</span><span class="p">):</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">num_samples</span>
        <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># TODO: simplify this in Tune</span>
            <span class="n">num_samples</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">concurrent_trials</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">max_concurrent_trials</span> <span class="ow">or</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">concurrent_trials</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># TODO: simplify this in Tune</span>
            <span class="n">concurrent_trials</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">inf</span>

        <span class="n">actual_concurrency</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="p">(</span><span class="n">cpus_total</span> <span class="o">//</span> <span class="n">cpus_per_trial</span><span class="p">)</span> <span class="k">if</span> <span class="n">cpus_per_trial</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="p">,</span>
                <span class="n">concurrent_trials</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">actual_concurrency</span> <span class="o">*</span> <span class="n">cpus_per_trial</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">cpus_total</span> <span class="o">+</span> <span class="mf">0.001</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_maybe_warn_resource_contention</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ray</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
            <span class="k">return</span>

        <span class="n">trainable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span>

        <span class="c1"># This may not be precise, but we don&#39;t have a great way of</span>
        <span class="c1"># accessing the actual scaling config if it is being tuned.</span>
        <span class="n">scaling_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">get_scaling_config</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="s2">&quot;base_scaling_config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">get_scaling_config</span><span class="p">):</span>
            <span class="n">scaling_config</span> <span class="o">=</span> <span class="n">get_scaling_config</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">scaling_config</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">scaling_config</span><span class="o">.</span><span class="n">_max_cpu_fraction_per_node</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">has_base_dataset</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="s2">&quot;has_base_dataset&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="n">cpus_per_trial</span> <span class="o">=</span> <span class="n">scaling_config</span><span class="o">.</span><span class="n">total_resources</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">cpus_left</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">available_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># avoid div by 0</span>
        <span class="c1"># TODO(amogkam): Remove this warning after _max_cpu_fraction_per_node is no</span>
        <span class="c1"># longer experimental.</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">has_base_dataset</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expected_utilization</span><span class="p">(</span><span class="n">cpus_per_trial</span><span class="p">,</span> <span class="n">cpus_left</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.8</span>
        <span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Executing `.fit()` may leave less than 20</span><span class="si">% o</span><span class="s2">f CPUs in &quot;</span>
                <span class="s2">&quot;this cluster for Dataset execution, which can lead to &quot;</span>
                <span class="s2">&quot;resource contention or hangs. To avoid this, &quot;</span>
                <span class="s2">&quot;reserve at least 20</span><span class="si">% o</span><span class="s2">f node CPUs for Dataset execution by &quot;</span>
                <span class="s2">&quot;setting `_max_cpu_fraction_per_node = 0.8` in the Trainer &quot;</span>
                <span class="s2">&quot;scaling_config. See &quot;</span>
                <span class="s2">&quot;https://docs.ray.io/en/master/data/dataset-internals.html&quot;</span>
                <span class="s2">&quot;#datasets-and-tune for more info.&quot;</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_trainable</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableType</span><span class="p">,</span> <span class="n">required_trainable_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Determines whether or not the trainable is valid.</span>

<span class="sd">        This includes checks on the serializability of the trainable, as well</span>
<span class="sd">        asserting that the trainable name is as expected on restoration.</span>

<span class="sd">        This trainable name validation is needed due to an implementation detail</span>
<span class="sd">        where the trainable name (which is differently generated depending on</span>
<span class="sd">        the trainable type) is saved in the Trial metadata and needs to match</span>
<span class="sd">        upon restoration. This does not affect the typical path, since `Tuner.restore`</span>
<span class="sd">        expects the exact same trainable (which will have the same name).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if the trainable name does not match or if the trainable</span>
<span class="sd">                is not serializable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">trainable</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">sio</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">()</span>
            <span class="n">inspect_serializability</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="n">print_file</span><span class="o">=</span><span class="n">sio</span><span class="p">)</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;The provided trainable is not serializable, which is a requirement &quot;</span>
                <span class="s2">&quot;since the trainable is serialized and deserialized when transferred &quot;</span>
                <span class="s2">&quot;to remote workers. See below for a trace of the non-serializable &quot;</span>
                <span class="s2">&quot;objects that were found in your trainable:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sio</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">required_trainable_name</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">trainable_name</span> <span class="o">=</span> <span class="n">Experiment</span><span class="o">.</span><span class="n">get_trainable_name</span><span class="p">(</span><span class="n">trainable</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">trainable_name</span> <span class="o">!=</span> <span class="n">required_trainable_name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid `trainable` input to `Tuner.restore()`. To fix this error, &quot;</span>
                <span class="s2">&quot;pass in the same trainable that was used to initialize the Tuner. &quot;</span>
                <span class="s2">&quot;Got a trainable with identifier &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">trainable_name</span><span class="si">}</span><span class="s2">&#39; but expected &#39;</span><span class="si">{</span><span class="n">required_trainable_name</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_trainable_on_restore</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableType</span><span class="p">,</span> <span class="n">old_trainable_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="kn">from</span> <span class="nn">ray.train.base_trainer</span> <span class="kn">import</span> <span class="n">BaseTrainer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">trainable</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_trainable</span><span class="p">(</span>
            <span class="n">trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span><span class="p">,</span>
            <span class="n">required_trainable_name</span><span class="o">=</span><span class="n">old_trainable_name</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainable</span><span class="p">,</span> <span class="n">BaseTrainer</span><span class="p">):</span>
            <span class="c1"># Log a warning in case the user tries to modify the</span>
            <span class="c1"># `RunConfig` from the Trainer</span>
            <span class="n">trainer</span><span class="p">:</span> <span class="n">BaseTrainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span>

            <span class="c1"># Only log if the Trainer has a non-default RunConfig</span>
            <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run_config</span> <span class="o">!=</span> <span class="n">RunConfig</span><span class="p">():</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;The Tune experiment will restore using the original run&#39;s &quot;</span>
                    <span class="s2">&quot;`RunConfig`. If you made any changes to the `RunConfig` &quot;</span>
                    <span class="s2">&quot;within the Trainer you passed into `Tuner.restore`, &quot;</span>
                    <span class="s2">&quot;they will be ignored in the resumed run.&quot;</span>
                <span class="p">)</span>

            <span class="n">trainer</span><span class="o">.</span><span class="n">run_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span>

    <span class="k">def</span> <span class="nf">_validate_param_space_on_restore</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">new_param_space</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">flattened_param_space_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Determines whether the (optionally) re-specified `param_space` is valid.</span>

<span class="sd">        This method performs very loose validation on the new param_space to</span>
<span class="sd">        prevent users from trying to specify new hyperparameters to tune over.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if not all keys match the original param_space.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">flattened_param_space_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Backwards compatibility: skip validation</span>
            <span class="k">return</span>

        <span class="n">keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">flatten_dict</span><span class="p">(</span><span class="n">new_param_space</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">keys</span> <span class="o">!=</span> <span class="n">flattened_param_space_keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid `param_space` input to `Tuner.restore()`. To fix this error, &quot;</span>
                <span class="s2">&quot;pass in the same `param_space` that was used to initialize the Tuner. &quot;</span>
                <span class="s2">&quot;Only re-specify the `param_space` to refresh Ray object references &quot;</span>
                <span class="s2">&quot;that no longer exist due to restoring from a new Ray cluster session. &quot;</span>
                <span class="s2">&quot;It should not be used to introduce new hyperparameters to tune.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Got: </span><span class="si">{</span><span class="n">keys</span><span class="si">}</span><span class="se">\n</span><span class="s2">Expected: </span><span class="si">{</span><span class="n">flattened_param_space_keys</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_param_space_on_restore</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">param_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="n">flattened_param_space_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_space</span> <span class="o">=</span> <span class="n">param_space</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_space</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># param_space = None -&gt; use the original param_space</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_param_space_on_restore</span><span class="p">(</span>
                <span class="n">new_param_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param_space</span><span class="p">,</span>
                <span class="n">flattened_param_space_keys</span><span class="o">=</span><span class="n">flattened_param_space_keys</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_load_tuner_state</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tuner_pkl_path</span><span class="p">:</span> <span class="n">Path</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]:</span>
        <span class="sd">&quot;&quot;&quot;Loads Tuner state from the previously saved `tuner.pkl`.</span>

<span class="sd">        Args:</span>
<span class="sd">            tuner_pkl_path: pathlib.Path of the `tuner.pkl` file saved during the</span>
<span class="sd">                original Tuner initialization.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: of `(old_trainable_name, flattened_param_space_keys)` used for</span>
<span class="sd">                validating the re-specified `trainable` and `param_space`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tuner_pkl_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not find Tuner state in restore directory. Did you pass&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;the correct path (the top-level experiment directory?) Got: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tuner_pkl_path</span><span class="o">.</span><span class="n">parent</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">tuner_pkl_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">tuner_state</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tuner_state</span><span class="p">,</span> <span class="n">TunerInternal</span><span class="p">):</span>
                <span class="c1"># TODO(ml-team): Remove in 2.7.</span>
                <span class="c1"># Backwards compatibility: ray&lt;=2.4 pickles the full Tuner object</span>
                <span class="c1"># within `tuner.pkl`. ray&gt;=2.5 pickles the object state as a dict.</span>
                <span class="n">tuner</span><span class="p">:</span> <span class="n">TunerInternal</span> <span class="o">=</span> <span class="n">tuner_state</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">())</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;You are restoring a Tune experiment that was run with an older &quot;</span>
                    <span class="s2">&quot;version of Ray. Note that backwards compatibility of restoring &quot;</span>
                    <span class="s2">&quot;this experiment will only be guaranteed until Ray 2.7.&quot;</span>
                <span class="p">)</span>

                <span class="n">old_trainable_name</span><span class="p">,</span> <span class="n">flattened_param_space_keys</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># NOTE: These are magic keys used for validating restore args.</span>
                <span class="n">old_trainable_name</span> <span class="o">=</span> <span class="n">tuner_state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;__trainable_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">flattened_param_space_keys</span> <span class="o">=</span> <span class="n">tuner_state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                    <span class="s2">&quot;__flattened_param_space_keys&quot;</span><span class="p">,</span> <span class="kc">None</span>
                <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">tuner_state</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">old_trainable_name</span><span class="p">,</span> <span class="n">flattened_param_space_keys</span>

    <span class="k">def</span> <span class="nf">_restore_from_path_or_uri</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path_or_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableTypeOrTrainer</span><span class="p">,</span>
        <span class="n">overwrite_param_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="n">resume_config</span><span class="p">:</span> <span class="n">_ResumeConfig</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Sync down from cloud storage if needed</span>
        <span class="p">(</span>
            <span class="n">restoring_from_cloud</span><span class="p">,</span>
            <span class="n">local_experiment_checkpoint_dir</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_sync_down_tuner_state</span><span class="p">(</span><span class="n">path_or_uri</span><span class="p">)</span>
        <span class="n">experiment_checkpoint_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_experiment_checkpoint_dir</span><span class="p">)</span>

        <span class="n">old_trainable_name</span><span class="p">,</span> <span class="n">flattened_param_space_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_tuner_state</span><span class="p">(</span>
            <span class="n">experiment_checkpoint_path</span> <span class="o">/</span> <span class="n">_TUNER_PKL</span>
        <span class="p">)</span>

        <span class="c1"># Perform validation and set the re-specified `trainable` and `param_space`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_trainable_on_restore</span><span class="p">(</span>
            <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span> <span class="n">old_trainable_name</span><span class="o">=</span><span class="n">old_trainable_name</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_param_space_on_restore</span><span class="p">(</span>
            <span class="n">param_space</span><span class="o">=</span><span class="n">overwrite_param_space</span><span class="p">,</span>
            <span class="n">flattened_param_space_keys</span><span class="o">=</span><span class="n">flattened_param_space_keys</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update RunConfig to reflect changes in the experiment directory</span>
        <span class="n">path_or_uri_obj</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">URI</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">URI</span><span class="p">(</span><span class="n">path_or_uri</span><span class="p">)</span> <span class="k">if</span> <span class="n">restoring_from_cloud</span> <span class="k">else</span> <span class="n">experiment_checkpoint_path</span>
        <span class="p">)</span>
        <span class="c1"># Infer the `storage_path` and run `name` of the restored run using the</span>
        <span class="c1"># experiment directory.</span>
        <span class="c1"># Ex: ~/ray_results/exp_name -&gt; ~/ray_results, exp_name</span>
        <span class="c1"># Ex: s3://bucket/exp_name -&gt; s3://bucket, exp_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">path_or_uri_obj</span><span class="o">.</span><span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">storage_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">path_or_uri_obj</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>

        <span class="c1"># Set the experiment directory</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">restoring_from_cloud</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_checkpoint_dir</span> <span class="o">=</span> <span class="n">local_experiment_checkpoint_dir</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If we synced, `experiment_checkpoint_dir` will contain a temporary</span>
            <span class="c1"># directory. Create an experiment checkpoint dir instead and move</span>
            <span class="c1"># our data there.</span>
            <span class="n">new_exp_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">setup_create_experiment_checkpoint_dir</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">file_dir</span> <span class="ow">in</span> <span class="n">experiment_checkpoint_path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">):</span>
                <span class="n">file_dir</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">new_exp_path</span> <span class="o">/</span> <span class="n">file_dir</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">experiment_checkpoint_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_checkpoint_dir</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_exp_path</span><span class="p">)</span>

        <span class="c1"># Load the experiment results at the point where it left off.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_analysis</span> <span class="o">=</span> <span class="n">ExperimentAnalysis</span><span class="p">(</span>
                <span class="n">experiment_checkpoint_path</span><span class="o">=</span><span class="n">path_or_uri</span><span class="p">,</span>
                <span class="n">default_metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span>
                <span class="n">default_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_analysis</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span> <span class="o">=</span> <span class="n">resume_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_restored</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_maybe_sync_down_tuner_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">restore_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Sync down trainable state from remote storage.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple of (downloaded from remote, local_dir)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_non_local_path_uri</span><span class="p">(</span><span class="n">restore_path</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">restore_path</span><span class="p">))</span>

        <span class="n">tempdir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">(</span><span class="s2">&quot;tmp_experiment_dir&quot;</span><span class="p">))</span>

        <span class="n">restore_uri</span> <span class="o">=</span> <span class="n">URI</span><span class="p">(</span><span class="n">restore_path</span><span class="p">)</span>
        <span class="n">download_from_uri</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">restore_uri</span> <span class="o">/</span> <span class="n">_TUNER_PKL</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">tempdir</span> <span class="o">/</span> <span class="n">_TUNER_PKL</span><span class="p">))</span>
        <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">tempdir</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_choose_run_config</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tuner_run_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RunConfig</span><span class="p">],</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;BaseTrainer&quot;</span><span class="p">,</span>
        <span class="n">param_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RunConfig</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Chooses which `RunConfig` to use when multiple can be passed in</span>
<span class="sd">        through a Trainer or the Tuner itself.</span>

<span class="sd">        Args:</span>
<span class="sd">            tuner_run_config: The run config passed into the Tuner constructor.</span>
<span class="sd">            trainer: The AIR Trainer instance to use with Tune, which may have</span>
<span class="sd">                a RunConfig specified by the user.</span>
<span class="sd">            param_space: The param space passed to the Tuner.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if the `run_config` is specified as a hyperparameter.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">param_space</span> <span class="ow">and</span> <span class="s2">&quot;run_config&quot;</span> <span class="ow">in</span> <span class="n">param_space</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`RunConfig` cannot be tuned as part of the `param_space`! &quot;</span>
                <span class="s2">&quot;Move the run config to be a parameter of the `Tuner`: &quot;</span>
                <span class="s2">&quot;Tuner(..., run_config=RunConfig(...))&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Both Tuner RunConfig + Trainer RunConfig --&gt; prefer Tuner RunConfig</span>
        <span class="k">if</span> <span class="n">tuner_run_config</span> <span class="ow">and</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run_config</span> <span class="o">!=</span> <span class="n">RunConfig</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;A `RunConfig` was passed to both the `Tuner` and the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">trainer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">`. The run config passed to &quot;</span>
                <span class="s2">&quot;the `Tuner` is the one that will be used.&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">tuner_run_config</span>

        <span class="c1"># No Tuner RunConfig -&gt; pass the Trainer config through</span>
        <span class="c1"># This returns either a user-specified config, or the default RunConfig</span>
        <span class="c1"># if nothing was provided to both the Trainer or Tuner.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tuner_run_config</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">run_config</span>

        <span class="c1"># Tuner RunConfig + No Trainer RunConfig --&gt; Use the Tuner config</span>
        <span class="k">return</span> <span class="n">tuner_run_config</span>

    <span class="k">def</span> <span class="nf">_process_scaling_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Converts ``self._param_space[&quot;scaling_config&quot;]`` to a dict.</span>

<span class="sd">        The dict is converted back to a dataclass by the Trainer, after the</span>
<span class="sd">        Tune search specification is resolved.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: introduce `ray.tune.sample.TuneableDataclass` and allow Tune to</span>
        <span class="c1"># natively resolve specs with dataclasses.</span>
        <span class="n">scaling_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_space</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scaling_config&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scaling_config</span><span class="p">,</span> <span class="n">ScalingConfig</span><span class="p">):</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_param_space</span><span class="p">[</span><span class="s2">&quot;scaling_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaling_config</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<div class="viewcode-block" id="TunerInternal.setup_create_experiment_checkpoint_dir"><a class="viewcode-back" href="../../../../tune/api/internals.html#ray.tune.impl.tuner_internal.TunerInternal.setup_create_experiment_checkpoint_dir">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">setup_create_experiment_checkpoint_dir</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableType</span><span class="p">,</span> <span class="n">run_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RunConfig</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sets up experiment checkpoint dir before actually running the experiment.&quot;&quot;&quot;</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">Experiment</span><span class="o">.</span><span class="n">get_experiment_checkpoint_dir</span><span class="p">(</span>
            <span class="n">trainable</span><span class="p">,</span>
            <span class="n">run_config</span><span class="o">.</span><span class="n">storage_path</span><span class="p">,</span>
            <span class="n">run_config</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">path</span></div>

    <span class="c1"># This has to be done through a function signature (@property won&#39;t do).</span>
    <span class="k">def</span> <span class="nf">get_experiment_checkpoint_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_checkpoint_dir</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainableTypeOrTrainer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainable</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">converted_trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainableType</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_converted_trainable</span>

    <span class="nd">@trainable</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableTypeOrTrainer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainable</span> <span class="o">=</span> <span class="n">trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_converted_trainable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_trainable</span><span class="p">(</span><span class="n">trainable</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">param_space</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_space</span>

    <span class="nd">@param_space</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">param_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]):</span>
        <span class="c1"># Handle any configs that adhere to the `to_dict` interface.</span>
        <span class="c1"># Ex: AlgorithmConfig from RLlib</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="n">_Config</span><span class="p">):</span>
            <span class="n">param_space</span> <span class="o">=</span> <span class="n">param_space</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="n">param_space</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The `param_space` passed to the `Tuner` must be a dict. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got &#39;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">param_space</span><span class="p">)</span><span class="si">}</span><span class="s2">&#39; instead.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_param_space</span> <span class="o">=</span> <span class="n">param_space</span>

        <span class="k">if</span> <span class="n">param_space</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_process_scaling_config</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_convert_trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableTypeOrTrainer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainableType</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Converts an AIR Trainer to a Tune trainable and saves the converted</span>
<span class="sd">        trainable. If not using an AIR Trainer, this leaves the trainable as is.&quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.train.trainer</span> <span class="kn">import</span> <span class="n">BaseTrainer</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">trainable</span><span class="o">.</span><span class="n">as_trainable</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="n">BaseTrainer</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">trainable</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResultGrid</span><span class="p">:</span>
        <span class="n">trainable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">converted_trainable</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_checkpoint_dir</span>
        <span class="n">param_space</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_space</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_restored</span><span class="p">:</span>
            <span class="n">analysis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_internal</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="n">param_space</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">analysis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_resume</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="n">param_space</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_analysis</span> <span class="o">=</span> <span class="n">analysis</span>

        <span class="k">return</span> <span class="n">ResultGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_experiment_analysis</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_results</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResultGrid</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experiment_analysis</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Can&#39;t return results as experiment has not been run, yet. &quot;</span>
                <span class="s2">&quot;Call `Tuner.fit()` to run the experiment first.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">ResultGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_experiment_analysis</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_tune_run_arguments</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Get tune.run arguments common for both new and resumed runs.&quot;&quot;&quot;</span>
        <span class="c1"># Avoid overwriting the originally configured checkpoint config.</span>
        <span class="n">checkpoint_config</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">checkpoint_config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_frequency</span><span class="p">:</span>
            <span class="c1"># Function trainables (and thus most of our trainers) usually don&#39;t handle</span>
            <span class="c1"># this argument.</span>
            <span class="n">handle_checkpoint_freq</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="n">trainable</span><span class="p">,</span> <span class="s2">&quot;_handles_checkpoint_freq&quot;</span><span class="p">,</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">handle_checkpoint_freq</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="c1"># If we specifically know this trainable doesn&#39;t support the</span>
                <span class="c1"># argument, raise an error</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;You passed `checkpoint_frequency=&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_frequency</span><span class="si">}</span><span class="s2">` to your &quot;</span>
                    <span class="s2">&quot;CheckpointConfig, but this trainer does not support &quot;</span>
                    <span class="s2">&quot;this argument. If you passed in an AIR trainer that takes in a &quot;</span>
                    <span class="s2">&quot;custom training loop, you will need to &quot;</span>
                    <span class="s2">&quot;report a checkpoint every `checkpoint_frequency` iterations &quot;</span>
                    <span class="s2">&quot;within your training loop using &quot;</span>
                    <span class="s2">&quot;`ray.air.session.report(metrics=..., checkpoint=...)` &quot;</span>
                    <span class="s2">&quot;to get this behavior.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">handle_checkpoint_freq</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="c1"># If we specifically support it, it&#39;s handled in the training loop,</span>
                <span class="c1"># so we disable tune&#39;s bookkeeping.</span>
                <span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_frequency</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Otherwise, the trainable is not an AIR trainer and we just keep the</span>
            <span class="c1"># user-supplied value.</span>
            <span class="c1"># Function trainables will raise a runtime error later if set &gt; 0</span>
        <span class="k">if</span> <span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_at_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Again, function trainables usually don&#39;t handle this argument.</span>
            <span class="n">handle_cp_at_end</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="s2">&quot;_handles_checkpoint_at_end&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">handle_cp_at_end</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="c1"># If we specifically know we don&#39;t support it, raise an error.</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;You passed `checkpoint_at_end=&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_at_end</span><span class="si">}</span><span class="s2">` &quot;</span>
                    <span class="s2">&quot;to your CheckpointConfig, but this trainer does not support &quot;</span>
                    <span class="s2">&quot;this argument. If you passed in an AIR trainer that takes in a &quot;</span>
                    <span class="s2">&quot;custom training loop, you should include one last call to &quot;</span>
                    <span class="s2">&quot;`ray.air.session.report(metrics=..., checkpoint=...)` &quot;</span>
                    <span class="s2">&quot;at the end of your training loop to get this behavior.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">handle_cp_at_end</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="c1"># If we specifically support it, it&#39;s handled in the training loop,</span>
                <span class="c1"># so we disable tune&#39;s internal bookkeeping.</span>
                <span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_at_end</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># If this is a user-defined trainable, just keep the value</span>
            <span class="c1"># Function trainables will raise a runtime error later if set to True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Set default to False for function trainables and True for everything else</span>
            <span class="k">if</span> <span class="n">is_function_trainable</span><span class="p">(</span><span class="n">trainable</span><span class="p">):</span>
                <span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_at_end</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">checkpoint_config</span><span class="o">.</span><span class="n">checkpoint_at_end</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">storage_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">storage_path</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
            <span class="n">sync_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">sync_config</span><span class="p">,</span>
            <span class="n">stop</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span>
            <span class="n">max_failures</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">failure_config</span><span class="o">.</span><span class="n">max_failures</span><span class="p">,</span>
            <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">checkpoint_config</span><span class="p">,</span>
            <span class="n">_experiment_checkpoint_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_experiment_checkpoint_dir</span><span class="p">,</span>
            <span class="n">raise_on_failed_trial</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">fail_fast</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">failure_config</span><span class="o">.</span><span class="n">fail_fast</span><span class="p">),</span>
            <span class="n">progress_reporter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">progress_reporter</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">reuse_actors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">reuse_actors</span><span class="p">,</span>
            <span class="n">max_concurrent_trials</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">max_concurrent_trials</span><span class="p">,</span>
            <span class="n">time_budget_s</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">time_budget_s</span><span class="p">,</span>
            <span class="n">trial_name_creator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">trial_name_creator</span><span class="p">,</span>
            <span class="n">trial_dirname_creator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">trial_dirname_creator</span><span class="p">,</span>
            <span class="n">chdir_to_trial_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">chdir_to_trial_dir</span><span class="p">,</span>
            <span class="n">_entrypoint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_entrypoint</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_fit_internal</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableType</span><span class="p">,</span> <span class="n">param_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExperimentAnalysis</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Fitting for a fresh Tuner.&quot;&quot;&quot;</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_tune_run_arguments</span><span class="p">(</span><span class="n">trainable</span><span class="p">),</span>
            <span class="o">**</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">run_or_experiment</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="n">param_space</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span>
                <span class="n">search_alg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">search_alg</span><span class="p">,</span>
                <span class="n">scheduler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">log_to_file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_config</span><span class="o">.</span><span class="n">log_to_file</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_tuner_kwargs</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">analysis</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span>
            <span class="o">**</span><span class="n">args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_remote_string_queue</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">analysis</span>

    <span class="k">def</span> <span class="nf">_fit_resume</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">trainable</span><span class="p">:</span> <span class="n">TrainableType</span><span class="p">,</span> <span class="n">param_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExperimentAnalysis</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Fitting for a restored Tuner.&quot;&quot;&quot;</span>
        <span class="n">resume</span> <span class="o">=</span> <span class="s2">&quot;AUTO&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span><span class="o">.</span><span class="n">resume_unfinished</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span><span class="o">.</span><span class="n">resume_errored</span><span class="p">:</span>
                    <span class="n">resume</span> <span class="o">+=</span> <span class="s2">&quot;+ERRORED_ONLY&quot;</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span><span class="o">.</span><span class="n">restart_errored</span><span class="p">:</span>
                    <span class="n">resume</span> <span class="o">+=</span> <span class="s2">&quot;+RESTART_ERRORED_ONLY&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span><span class="o">.</span><span class="n">resume_errored</span><span class="p">:</span>
                    <span class="n">resume</span> <span class="o">+=</span> <span class="s2">&quot;+ERRORED&quot;</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resume_config</span><span class="o">.</span><span class="n">restart_errored</span><span class="p">:</span>
                    <span class="n">resume</span> <span class="o">+=</span> <span class="s2">&quot;+RESTART_ERRORED&quot;</span>

        <span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_tune_run_arguments</span><span class="p">(</span><span class="n">trainable</span><span class="p">),</span>
            <span class="o">**</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">run_or_experiment</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="n">param_space</span><span class="p">,</span>
                <span class="n">resume</span><span class="o">=</span><span class="n">resume</span><span class="p">,</span>
                <span class="n">search_alg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">search_alg</span><span class="p">,</span>
                <span class="n">scheduler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tune_config</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_tuner_kwargs</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">analysis</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_remote_string_queue</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">analysis</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_tuner_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_tuner_kwargs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_tuner_kwargs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_remote_string_queue&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">_TRAINABLE_KEY</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">trainable</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">_CONVERTED_TRAINABLE_KEY</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">param_space</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">_PARAM_SPACE_KEY</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">_EXPERIMENT_ANALYSIS_KEY</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;__trainable_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Experiment</span><span class="o">.</span><span class="n">get_trainable_name</span><span class="p">(</span><span class="n">trainable</span><span class="p">)</span> <span class="k">if</span> <span class="n">trainable</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;__flattened_param_space_keys&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">sorted</span><span class="p">(</span><span class="n">flatten_dict</span><span class="p">(</span><span class="n">param_space</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">param_space</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Make sure the magic metadata gets removed first.</span>
        <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;__flattened_param_space_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;__trainable_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>