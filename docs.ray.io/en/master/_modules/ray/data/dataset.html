
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.data.dataset &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/versionwarning.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../_static/js/docsearch.js"></script>
    <script src="../../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../_static/js/top-navigation.js"></script>
    <script src="../../../_static/js/tags.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/data/dataset.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "_modules/ray/data/dataset", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/data/dataset.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.data.dataset</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">html</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Generic</span><span class="p">,</span>
    <span class="n">Iterable</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Mapping</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">uuid</span> <span class="kn">import</span> <span class="n">uuid4</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.cloudpickle</span> <span class="k">as</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">ray._private.thirdparty.tabulate.tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">from</span> <span class="nn">ray._private.usage</span> <span class="kn">import</span> <span class="n">usage_lib</span>
<span class="kn">from</span> <span class="nn">ray.air.constants</span> <span class="kn">import</span> <span class="n">TENSOR_COLUMN_NAME</span>
<span class="kn">from</span> <span class="nn">ray.air.util.data_batch_conversion</span> <span class="kn">import</span> <span class="n">BlockFormat</span>
<span class="kn">from</span> <span class="nn">ray.air.util.tensor_extensions.utils</span> <span class="kn">import</span> <span class="n">_create_possibly_ragged_ndarray</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.block_list</span> <span class="kn">import</span> <span class="n">BlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.compute</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ActorPoolStrategy</span><span class="p">,</span>
    <span class="n">CallableClass</span><span class="p">,</span>
    <span class="n">ComputeStrategy</span><span class="p">,</span>
    <span class="n">TaskPoolStrategy</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.delegating_block_builder</span> <span class="kn">import</span> <span class="n">DelegatingBlockBuilder</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.equalize</span> <span class="kn">import</span> <span class="n">_equalize</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.execution.interfaces</span> <span class="kn">import</span> <span class="n">RefBundle</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.execution.legacy_compat</span> <span class="kn">import</span> <span class="n">_block_list_to_bundles</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.iterator.iterator_impl</span> <span class="kn">import</span> <span class="n">DataIteratorImpl</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.iterator.stream_split_iterator</span> <span class="kn">import</span> <span class="n">StreamSplitDataIterator</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.lazy_block_list</span> <span class="kn">import</span> <span class="n">LazyBlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.all_to_all_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">RandomizeBlocks</span><span class="p">,</span>
    <span class="n">RandomShuffle</span><span class="p">,</span>
    <span class="n">Repartition</span><span class="p">,</span>
    <span class="n">Sort</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.input_data_operator</span> <span class="kn">import</span> <span class="n">InputData</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.map_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Filter</span><span class="p">,</span>
    <span class="n">FlatMap</span><span class="p">,</span>
    <span class="n">MapBatches</span><span class="p">,</span>
    <span class="n">MapRows</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.n_ary_operator</span> <span class="kn">import</span> <span class="n">Zip</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.one_to_one_operator</span> <span class="kn">import</span> <span class="n">Limit</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.write_operator</span> <span class="kn">import</span> <span class="n">Write</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.optimizers</span> <span class="kn">import</span> <span class="n">LogicalPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">ExecutionPlan</span><span class="p">,</span> <span class="n">OneToOneStage</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.filter</span> <span class="kn">import</span> <span class="n">generate_filter_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.flat_map</span> <span class="kn">import</span> <span class="n">generate_flat_map_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.map_batches</span> <span class="kn">import</span> <span class="n">generate_map_batches_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.map_rows</span> <span class="kn">import</span> <span class="n">generate_map_rows_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.write</span> <span class="kn">import</span> <span class="n">generate_write_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.progress_bar</span> <span class="kn">import</span> <span class="n">ProgressBar</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.remote_fn</span> <span class="kn">import</span> <span class="n">cached_remote_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.split</span> <span class="kn">import</span> <span class="n">_get_num_rows</span><span class="p">,</span> <span class="n">_split_at_indices</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.stage_impl</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LimitStage</span><span class="p">,</span>
    <span class="n">RandomizeBlocksStage</span><span class="p">,</span>
    <span class="n">RandomShuffleStage</span><span class="p">,</span>
    <span class="n">RepartitionStage</span><span class="p">,</span>
    <span class="n">SortStage</span><span class="p">,</span>
    <span class="n">ZipStage</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.stats</span> <span class="kn">import</span> <span class="n">DatasetStats</span><span class="p">,</span> <span class="n">DatasetStatsSummary</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.util</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConsumptionAPI</span><span class="p">,</span>
    <span class="n">_estimate_available_parallelism</span><span class="p">,</span>
    <span class="n">_is_local_scheme</span><span class="p">,</span>
    <span class="n">validate_compute</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.aggregate</span> <span class="kn">import</span> <span class="n">AggregateFn</span><span class="p">,</span> <span class="n">Max</span><span class="p">,</span> <span class="n">Mean</span><span class="p">,</span> <span class="n">Min</span><span class="p">,</span> <span class="n">Std</span><span class="p">,</span> <span class="n">Sum</span>
<span class="kn">from</span> <span class="nn">ray.data.block</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">STRICT_MODE_EXPLANATION</span><span class="p">,</span>
    <span class="n">VALID_BATCH_FORMATS</span><span class="p">,</span>
    <span class="n">Block</span><span class="p">,</span>
    <span class="n">BlockAccessor</span><span class="p">,</span>
    <span class="n">BlockMetadata</span><span class="p">,</span>
    <span class="n">BlockPartition</span><span class="p">,</span>
    <span class="n">DataBatch</span><span class="p">,</span>
    <span class="n">StrictModeError</span><span class="p">,</span>
    <span class="n">T</span><span class="p">,</span>
    <span class="n">U</span><span class="p">,</span>
    <span class="n">UserDefinedFunction</span><span class="p">,</span>
    <span class="n">_apply_strict_mode_batch_format</span><span class="p">,</span>
    <span class="n">_apply_strict_mode_batch_size</span><span class="p">,</span>
    <span class="n">_validate_key_fn</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.context</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ESTIMATED_SAFE_MEMORY_FRACTION</span><span class="p">,</span>
    <span class="n">OK_PREFIX</span><span class="p">,</span>
    <span class="n">WARN_PREFIX</span><span class="p">,</span>
    <span class="n">DataContext</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BlockWritePathProvider</span><span class="p">,</span>
    <span class="n">CSVDatasource</span><span class="p">,</span>
    <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">DefaultBlockWritePathProvider</span><span class="p">,</span>
    <span class="n">JSONDatasource</span><span class="p">,</span>
    <span class="n">NumpyDatasource</span><span class="p">,</span>
    <span class="n">ParquetDatasource</span><span class="p">,</span>
    <span class="n">ReadTask</span><span class="p">,</span>
    <span class="n">TFRecordDatasource</span><span class="p">,</span>
    <span class="n">WriteResult</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.file_based_datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">,</span>
    <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.iterator</span> <span class="kn">import</span> <span class="n">DataIterator</span>
<span class="kn">from</span> <span class="nn">ray.data.random_access_dataset</span> <span class="kn">import</span> <span class="n">RandomAccessDataset</span>
<span class="kn">from</span> <span class="nn">ray.types</span> <span class="kn">import</span> <span class="n">ObjectRef</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">Deprecated</span><span class="p">,</span> <span class="n">DeveloperAPI</span><span class="p">,</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.util.scheduling_strategies</span> <span class="kn">import</span> <span class="n">NodeAffinitySchedulingStrategy</span>
<span class="kn">from</span> <span class="nn">ray.widgets</span> <span class="kn">import</span> <span class="n">Template</span>
<span class="kn">from</span> <span class="nn">ray.widgets.util</span> <span class="kn">import</span> <span class="n">repr_with_fallback</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">typing_extensions</span> <span class="kn">import</span> <span class="n">Literal</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dask</span>
    <span class="kn">import</span> <span class="nn">mars</span>
    <span class="kn">import</span> <span class="nn">modin</span>
    <span class="kn">import</span> <span class="nn">pandas</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span>
    <span class="kn">import</span> <span class="nn">pyspark</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.utils.data</span>
    <span class="kn">from</span> <span class="nn">tensorflow_metadata.proto.v0</span> <span class="kn">import</span> <span class="n">schema_pb2</span>

    <span class="kn">from</span> <span class="nn">ray.data._internal.execution.interfaces</span> <span class="kn">import</span> <span class="n">Executor</span><span class="p">,</span> <span class="n">NodeIdStr</span>
    <span class="kn">from</span> <span class="nn">ray.data._internal.torch_iterable_dataset</span> <span class="kn">import</span> <span class="n">TorchTensorBatchType</span>
    <span class="kn">from</span> <span class="nn">ray.data.dataset_pipeline</span> <span class="kn">import</span> <span class="n">DatasetPipeline</span>
    <span class="kn">from</span> <span class="nn">ray.data.grouped_data</span> <span class="kn">import</span> <span class="n">GroupedData</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">TensorflowFeatureTypeSpec</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span>
    <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">TensorFlowTensorBatchType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">]]</span>


<div class="viewcode-block" id="Dataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.html#ray.data.Dataset">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A Dataset is a distributed data collection for data loading and processing.</span>

<span class="sd">    Datasets are distributed pipelines that produce ``ObjectRef[Block]`` outputs,</span>
<span class="sd">    where each block holds data in Arrow format, representing a shard of the overall</span>
<span class="sd">    data collection. The block also determines the unit of parallelism.</span>

<span class="sd">    Datasets can be created in multiple ways: from synthetic data via ``range_*()``</span>
<span class="sd">    APIs, from existing memory data via ``from_*()`` APIs (this creates a subclass</span>
<span class="sd">    of Dataset called ``MaterializedDataset``), or from external storage</span>
<span class="sd">    systems such as local disk, S3, HDFS etc. via the ``read_*()`` APIs. The</span>
<span class="sd">    (potentially processed) Dataset can be saved back to external storage systems</span>
<span class="sd">    via the ``write_*()`` APIs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; # Create dataset from synthetic data.</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">        &gt;&gt;&gt; # Create dataset from in-memory data.</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.from_items(</span>
<span class="sd">        ...     [{&quot;col1&quot;: i, &quot;col2&quot;: i * 2} for i in range(1000)])</span>
<span class="sd">        &gt;&gt;&gt; # Create dataset from external storage system.</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; # Save dataset back to external storage system.</span>
<span class="sd">        &gt;&gt;&gt; ds.write_csv(&quot;s3://bucket/output&quot;) # doctest: +SKIP</span>

<span class="sd">    Dataset has two kinds of operations: transformation, which takes in Dataset</span>
<span class="sd">    and outputs a new Dataset (e.g. :py:meth:`.map_batches()`); and consumption,</span>
<span class="sd">    which produces values (not Datatream) as output (e.g. :py:meth:`.iter_batches()`).</span>

<span class="sd">    Dataset transformations are lazy, with execution of the transformations being</span>
<span class="sd">    triggered by downstream consumption.</span>

<span class="sd">    Dataset supports parallel processing at scale: transformations such as</span>
<span class="sd">    :py:meth:`.map_batches()`, aggregations such as</span>
<span class="sd">    :py:meth:`.min()`/:py:meth:`.max()`/:py:meth:`.mean()`, grouping via</span>
<span class="sd">    :py:meth:`.groupby()`, shuffling operations such as :py:meth:`.sort()`,</span>
<span class="sd">    :py:meth:`.random_shuffle()`, and :py:meth:`.repartition()`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">        &gt;&gt;&gt; # Transform batches (Dict[str, np.ndarray]) with map_batches().</span>
<span class="sd">        &gt;&gt;&gt; ds.map_batches(lambda batch: {&quot;id&quot;: batch[&quot;id&quot;] * 2})  # doctest: +ELLIPSIS</span>
<span class="sd">        MapBatches(&lt;lambda&gt;)</span>
<span class="sd">        +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; # Compute the maximum.</span>
<span class="sd">        &gt;&gt;&gt; ds.max(&quot;id&quot;)</span>
<span class="sd">        999</span>
<span class="sd">        &gt;&gt;&gt; # Shuffle this dataset randomly.</span>
<span class="sd">        &gt;&gt;&gt; ds.random_shuffle()  # doctest: +ELLIPSIS</span>
<span class="sd">        RandomShuffle</span>
<span class="sd">        +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; # Sort it back in order.</span>
<span class="sd">        &gt;&gt;&gt; ds.sort(&quot;id&quot;)  # doctest: +ELLIPSIS</span>
<span class="sd">        Sort</span>
<span class="sd">        +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>

<span class="sd">    Both unexecuted and materialized Datasets can be passed between Ray tasks and</span>
<span class="sd">    actors without incurring a copy. Dataset supports conversion to/from several</span>
<span class="sd">    more featureful dataframe libraries (e.g., Spark, Dask, Modin, MARS), and are also</span>
<span class="sd">    compatible with distributed TensorFlow / PyTorch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Dataset.__init__"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.__init__.html#ray.data.Dataset.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">plan</span><span class="p">:</span> <span class="n">ExecutionPlan</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">lazy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LogicalPlan</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a Dataset (internal API).</span>

<span class="sd">        The constructor is not part of the Dataset API. Use the ``ray.data.*``</span>
<span class="sd">        read methods to construct a dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">ExecutionPlan</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">plan</span><span class="p">)</span>
        <span class="n">usage_lib</span><span class="o">.</span><span class="n">record_library_usage</span><span class="p">(</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span>  <span class="c1"># Legacy telemetry name.</span>

        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">log_once</span><span class="p">(</span><span class="s2">&quot;strict_mode_explanation&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">STRICT_MODE_EXPLANATION</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span> <span class="o">=</span> <span class="n">plan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">hex</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span> <span class="o">=</span> <span class="n">lazy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span> <span class="o">=</span> <span class="n">logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">link_logical_plan</span><span class="p">(</span><span class="n">logical_plan</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">lazy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">allow_clear_input_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Handle to currently running executor for this dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Executor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span>
        <span class="n">ds</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="n">_deep_copy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">_as</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">type</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_as</span><span class="p">:</span>
            <span class="n">_as</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_deep_copy</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_as</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">deep_copy</span><span class="p">(),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_as</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.map"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.map.html#ray.data.Dataset.map">[docs]</a>    <span class="k">def</span> <span class="nf">map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Apply the given function to each record of this dataset.</span>

<span class="sd">        Note that mapping individual records can be quite slow. Consider using</span>
<span class="sd">        `.map_batches()` for performance.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Transform python objects.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; # The function goes from record (Dict[str, Any]) to record.</span>
<span class="sd">            &gt;&gt;&gt; ds.map(lambda record: {&quot;id&quot;: record[&quot;id&quot;] * 2})</span>
<span class="sd">            Map</span>
<span class="sd">            +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>
<span class="sd">            &gt;&gt;&gt; # Transform Arrow records.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items(</span>
<span class="sd">            ...     [{&quot;value&quot;: i} for i in range(1000)])</span>
<span class="sd">            &gt;&gt;&gt; ds.map(lambda record: {&quot;v2&quot;: record[&quot;value&quot;] * 2})</span>
<span class="sd">            Map</span>
<span class="sd">            +- Dataset(num_blocks=200, num_rows=1000, schema={value: int64})</span>
<span class="sd">            &gt;&gt;&gt; # Define a callable class that persists state across</span>
<span class="sd">            &gt;&gt;&gt; # function invocations for efficiency.</span>
<span class="sd">            &gt;&gt;&gt; init_model = ... # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; class CachedModel:</span>
<span class="sd">            ...    def __init__(self):</span>
<span class="sd">            ...        self.model = init_model()</span>
<span class="sd">            ...    def __call__(self, batch):</span>
<span class="sd">            ...        return self.model(batch)</span>
<span class="sd">            &gt;&gt;&gt; # Apply the transform in parallel on GPUs. Since</span>
<span class="sd">            &gt;&gt;&gt; # compute=ActorPoolStrategy(size=8) the transform will be applied on a</span>
<span class="sd">            &gt;&gt;&gt; # pool of 8 Ray actors, each allocated 1 GPU by Ray.</span>
<span class="sd">            &gt;&gt;&gt; ds.map(CachedModel, # doctest: +SKIP</span>
<span class="sd">            ...        compute=ray.data.ActorPoolStrategy(size=8),</span>
<span class="sd">            ...        num_gpus=1)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function to apply to each record, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy.</span>
<span class="sd">            compute: The compute strategy, either None (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map</span>
<span class="sd">                worker.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray for each map worker.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.flat_map`:</span>
<span class="sd">                Call this method to create new records from existing ones. Unlike</span>
<span class="sd">                :meth:`~Dataset.map`, a function passed to</span>
<span class="sd">                :meth:`~Dataset.flat_map` can return multiple records.</span>

<span class="sd">                :meth:`~Dataset.flat_map` isn&#39;t recommended because it&#39;s slow; call</span>
<span class="sd">                :meth:`~Dataset.map_batches` instead.</span>

<span class="sd">            :meth:`~Dataset.map_batches`</span>
<span class="sd">                Call this method to transform batches of data. It&#39;s faster and more</span>
<span class="sd">                flexible than :meth:`~Dataset.map` and :meth:`~Dataset.flat_map`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_warn_slow</span><span class="p">()</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_map_rows_fn</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">OneToOneStage</span><span class="p">(</span>
                <span class="s2">&quot;Map&quot;</span><span class="p">,</span>
                <span class="n">transform_fn</span><span class="p">,</span>
                <span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="p">,</span>
                <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">map_op</span> <span class="o">=</span> <span class="n">MapRows</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">map_op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.map_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.map_batches.html#ray.data.Dataset.map_batches">[docs]</a>    <span class="k">def</span> <span class="nf">map_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">DataBatch</span><span class="p">,</span> <span class="n">DataBatch</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">zero_copy_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fn_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Apply the given function to batches of data.</span>

<span class="sd">        This applies the ``fn`` in parallel with map tasks, with each task handling</span>
<span class="sd">        a batch of data (typically Dict[str, np.ndarray] or pd.DataFrame).</span>

<span class="sd">        To learn more, see the :ref:`Transforming batches user guide &lt;transforming_batches&gt;`.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If ``fn`` does not mutate its input, set ``zero_copy_batch=True`` to elide a</span>
<span class="sd">            batch copy, which can improve performance and decrease memory utilization.</span>
<span class="sd">            ``fn`` will then receive zero-copy read-only batches.</span>
<span class="sd">            If ``fn`` mutates its input, you will need to ensure that the batch provided</span>
<span class="sd">            to ``fn`` is writable by setting ``zero_copy_batch=False`` (default). This</span>
<span class="sd">            will create an extra, mutable copy of each batch before handing it to</span>
<span class="sd">            ``fn``.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The size of the batches provided to ``fn`` may be smaller than the provided</span>
<span class="sd">            ``batch_size`` if ``batch_size`` doesn&#39;t evenly divide the block(s) sent to</span>
<span class="sd">            a given map task. When ``batch_size`` is specified, each map task will be</span>
<span class="sd">            sent a single block if the block is equal to or larger than ``batch_size``,</span>
<span class="sd">            and will be sent a bundle of blocks up to (but not exceeding)</span>
<span class="sd">            ``batch_size`` if blocks are smaller than ``batch_size``.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([</span>
<span class="sd">            ...     {&quot;name&quot;: &quot;Luna&quot;, &quot;age&quot;: 4},</span>
<span class="sd">            ...     {&quot;name&quot;: &quot;Rory&quot;, &quot;age&quot;: 14},</span>
<span class="sd">            ...     {&quot;name&quot;: &quot;Scout&quot;, &quot;age&quot;: 9},</span>
<span class="sd">            ... ])</span>
<span class="sd">            &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">            MaterializedDataset(</span>
<span class="sd">                num_blocks=3,</span>
<span class="sd">                num_rows=3,</span>
<span class="sd">                schema={name: string, age: int64}</span>
<span class="sd">            )</span>

<span class="sd">            Here ``fn`` returns the same batch type as the input, but your ``fn`` can</span>
<span class="sd">            also return a different batch type (e.g., pd.DataFrame). Read more about</span>
<span class="sd">            :ref:`Transforming batches &lt;transforming_batches&gt;`.</span>

<span class="sd">            &gt;&gt;&gt; from typing import Dict</span>
<span class="sd">            &gt;&gt;&gt; def map_fn(batch: Dict[str, np.ndarray]) -&gt; Dict[str, np.ndarray]:</span>
<span class="sd">            ...     batch[&quot;age_in_dog_years&quot;] = 7 * batch[&quot;age&quot;]</span>
<span class="sd">            ...     return batch</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.map_batches(map_fn)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            MapBatches(map_fn)</span>
<span class="sd">            +- Dataset(num_blocks=3, num_rows=3, schema={name: string, age: int64})</span>

<span class="sd">            :ref:`Actors &lt;actor-guide&gt;` can improve the performance of some workloads.</span>
<span class="sd">            For example, you can use :ref:`actors &lt;actor-guide&gt;` to load a model once</span>
<span class="sd">            per worker instead of once per inference.</span>

<span class="sd">            To transform batches with :ref:`actors &lt;actor-guide&gt;`, pass a callable type</span>
<span class="sd">            to ``fn`` and specify an :class:`~ray.data.ActorPoolStrategy`.</span>

<span class="sd">            In the example below, ``CachedModel`` is called on an autoscaling pool of</span>
<span class="sd">            two to eight :ref:`actors &lt;actor-guide&gt;`, each allocated one GPU by Ray.</span>

<span class="sd">            &gt;&gt;&gt; init_large_model = ... # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; class CachedModel:</span>
<span class="sd">            ...    def __init__(self):</span>
<span class="sd">            ...        self.model = init_large_model()</span>
<span class="sd">            ...    def __call__(self, item):</span>
<span class="sd">            ...        return self.model(item)</span>
<span class="sd">            &gt;&gt;&gt; ds.map_batches( # doctest: +SKIP</span>
<span class="sd">            ...     CachedModel, # doctest: +SKIP</span>
<span class="sd">            ...     batch_size=256, # doctest: +SKIP</span>
<span class="sd">            ...     compute=ray.data.ActorPoolStrategy(size=8), # doctest: +SKIP</span>
<span class="sd">            ...     num_gpus=1,</span>
<span class="sd">            ... ) # doctest: +SKIP</span>

<span class="sd">            ``fn`` can also be a generator, yielding multiple batches in a single</span>
<span class="sd">            invocation. This is useful when returning large objects. Instead of</span>
<span class="sd">            returning a very large output batch, ``fn`` can instead yield the</span>
<span class="sd">            output batch in chunks.</span>

<span class="sd">            &gt;&gt;&gt; def map_fn_with_large_output(batch):</span>
<span class="sd">            ...     for i in range(3):</span>
<span class="sd">            ...         yield {&quot;large_output&quot;: np.ones((100, 1000))}</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([1])</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.map_batches(map_fn_with_large_output)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            MapBatches(map_fn_with_large_output)</span>
<span class="sd">            +- Dataset(num_blocks=1, num_rows=1, schema={item: int64})</span>


<span class="sd">        Args:</span>
<span class="sd">            fn: The function or generator to apply to each record batch, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy. Note ``fn`` must be</span>
<span class="sd">                pickle-able.</span>
<span class="sd">            batch_size: The desired number of rows in each batch, or None to use entire</span>
<span class="sd">                blocks as batches (blocks may contain different number of rows).</span>
<span class="sd">                The actual size of the batch provided to ``fn`` may be smaller than</span>
<span class="sd">                ``batch_size`` if ``batch_size`` doesn&#39;t evenly divide the block(s) sent</span>
<span class="sd">                to a given map task. Default batch_size is 4096 with &quot;default&quot;.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            batch_format: Specify ``&quot;default&quot;`` to use the default block format</span>
<span class="sd">                (NumPy), ``&quot;pandas&quot;`` to select ``pandas.DataFrame``, &quot;pyarrow&quot; to</span>
<span class="sd">                select ``pyarrow.Table``, or ``&quot;numpy&quot;`` to select</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``, or None to return the underlying block</span>
<span class="sd">                exactly as is with no additional formatting.</span>
<span class="sd">            zero_copy_batch: Whether ``fn`` should be provided zero-copy, read-only</span>
<span class="sd">                batches. If this is ``True`` and no copy is required for the</span>
<span class="sd">                ``batch_format`` conversion, the batch will be a zero-copy, read-only</span>
<span class="sd">                view on data in Ray&#39;s object store, which can decrease memory</span>
<span class="sd">                utilization and improve performance. If this is ``False``, the batch</span>
<span class="sd">                will be writable, which will require an extra copy to guarantee.</span>
<span class="sd">                If ``fn`` mutates its input, this will need to be ``False`` in order to</span>
<span class="sd">                avoid &quot;assignment destination is read-only&quot; or &quot;buffer source array is</span>
<span class="sd">                read-only&quot; errors. Default is ``False``.</span>
<span class="sd">            fn_args: Positional arguments to pass to ``fn`` after the first argument.</span>
<span class="sd">                These arguments are top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_kwargs: Keyword arguments to pass to ``fn``. These arguments are</span>
<span class="sd">                top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_constructor_args: Positional arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                You can only provide this if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            fn_constructor_kwargs: Keyword arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                This can only be provided if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map worker.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray for each map worker.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.iter_batches`</span>
<span class="sd">                Call this function to iterate over batches of data.</span>

<span class="sd">            :meth:`~Dataset.flat_map`:</span>
<span class="sd">                Call this method to create new records from existing ones. Unlike</span>
<span class="sd">                :meth:`~Dataset.map`, a function passed to :meth:`~Dataset.flat_map`</span>
<span class="sd">                can return multiple records.</span>

<span class="sd">                :meth:`~Dataset.flat_map` isn&#39;t recommended because it&#39;s slow; call</span>
<span class="sd">                :meth:`~Dataset.map_batches` instead.</span>

<span class="sd">            :meth:`~Dataset.map`</span>
<span class="sd">                Call this method to transform one record at time.</span>

<span class="sd">                This method isn&#39;t recommended because it&#39;s slow; call</span>
<span class="sd">                :meth:`~Dataset.map_batches` instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_format</span> <span class="o">==</span> <span class="s2">&quot;native&quot;</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;The &#39;native&#39; batch format has been renamed &#39;default&#39;.&quot;</span><span class="p">)</span>

        <span class="n">target_block_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Batch size cannot be negative or 0&quot;</span><span class="p">)</span>
            <span class="c1"># Enable blocks bundling when batch_size is specified by caller.</span>
            <span class="n">target_block_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_size</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="s2">&quot;num_gpus&quot;</span> <span class="ow">in</span> <span class="n">ray_remote_args</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">batch_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">VALID_BATCH_FORMATS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The batch format must be one of </span><span class="si">{</span><span class="n">VALID_BATCH_FORMATS</span><span class="si">}</span><span class="s2">, got: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">batch_format</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fn_constructor_args</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">fn_constructor_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">compute</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="n">compute</span> <span class="o">!=</span> <span class="s2">&quot;actors&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">compute</span><span class="p">,</span> <span class="n">ActorPoolStrategy</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;fn_constructor_args and fn_constructor_kwargs can only be &quot;</span>
                    <span class="s2">&quot;specified if using the actor pool compute strategy, but got: &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">compute</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">CallableClass</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;fn_constructor_args and fn_constructor_kwargs can only be &quot;</span>
                    <span class="s2">&quot;specified if providing a CallableClass instance for fn, but got: &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_map_batches_fn</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="n">zero_copy_batch</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># TODO(chengsu): pass function name to MapBatches logical operator.</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;__self__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">fn</span><span class="o">.</span><span class="vm">__self__</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessor</span><span class="o">.</span><span class="n">Preprocessor</span>
        <span class="p">):</span>
            <span class="n">stage_name</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="vm">__self__</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stage_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;MapBatches(</span><span class="si">{</span><span class="nb">getattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;__name__&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span><span class="si">}</span><span class="s1">)&#39;</span>

        <span class="n">stage</span> <span class="o">=</span> <span class="n">OneToOneStage</span><span class="p">(</span>
            <span class="n">stage_name</span><span class="p">,</span>
            <span class="n">transform_fn</span><span class="p">,</span>
            <span class="n">compute</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="c1"># TODO(Clark): Add a strict cap here.</span>
            <span class="n">target_block_size</span><span class="o">=</span><span class="n">target_block_size</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">map_batches_op</span> <span class="o">=</span> <span class="n">MapBatches</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
                <span class="n">zero_copy_batch</span><span class="o">=</span><span class="n">zero_copy_batch</span><span class="p">,</span>
                <span class="n">target_block_size</span><span class="o">=</span><span class="n">target_block_size</span><span class="p">,</span>
                <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
                <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
                <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
                <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">map_batches_op</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.add_column"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.add_column.html#ray.data.Dataset.add_column">[docs]</a>    <span class="k">def</span> <span class="nf">add_column</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">],</span> <span class="s2">&quot;pandas.Series&quot;</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Add the given column to the dataset.</span>

<span class="sd">        This is only supported for datasets convertible to pandas format.</span>
<span class="sd">        A function generating the new column values given the batch in pandas</span>
<span class="sd">        format must be specified.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; # Add a new column equal to value * 2.</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.add_column(&quot;new_col&quot;, lambda df: df[&quot;id&quot;] * 2)</span>
<span class="sd">            &gt;&gt;&gt; # Overwrite the existing &quot;value&quot; with zeros.</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.add_column(&quot;id&quot;, lambda df: 0)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            col: Name of the column to add. If the name already exists, the</span>
<span class="sd">                column will be overwritten.</span>
<span class="sd">            fn: Map function generating the column values given a batch of</span>
<span class="sd">                records in pandas format.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">:</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">batch</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`fn` must be callable, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="n">process_batch</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>  <span class="c1"># TODO(ekl) we should make this configurable.</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.drop_columns"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.drop_columns.html#ray.data.Dataset.drop_columns">[docs]</a>    <span class="k">def</span> <span class="nf">drop_columns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cols</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Drop one or more columns from the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; # Add a new column equal to value * 2.</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.add_column(&quot;new_col&quot;, lambda df: df[&quot;id&quot;] * 2)</span>
<span class="sd">            &gt;&gt;&gt; # Drop the existing &quot;value&quot; column.</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.drop_columns([&quot;id&quot;])</span>


<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            cols: Names of the columns to drop. If any name does not exist,</span>
<span class="sd">                an exception will be raised.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">batch</span><span class="p">:</span> <span class="n">batch</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">),</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.select_columns"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.select_columns.html#ray.data.Dataset.select_columns">[docs]</a>    <span class="k">def</span> <span class="nf">select_columns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cols</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Select one or more columns from the dataset.</span>

<span class="sd">        All input columns used to select need to be in the schema of the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset with 3 columns</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([{&quot;col1&quot;: i, &quot;col2&quot;: i+1, &quot;col3&quot;: i+2}</span>
<span class="sd">            ...      for i in range(10)])</span>
<span class="sd">            &gt;&gt;&gt; # Select only &quot;col1&quot; and &quot;col2&quot; columns.</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.select_columns(cols=[&quot;col1&quot;, &quot;col2&quot;])</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            MapBatches(&lt;lambda&gt;)</span>
<span class="sd">            +- Dataset(</span>
<span class="sd">                  num_blocks=10,</span>
<span class="sd">                  num_rows=10,</span>
<span class="sd">                  schema={col1: int64, col2: int64, col3: int64}</span>
<span class="sd">               )</span>


<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            cols: Names of the columns to select. If any name is not included in the</span>
<span class="sd">                dataset schema, an exception will be raised.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">batch</span><span class="p">:</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">),</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.flat_map"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.flat_map.html#ray.data.Dataset.flat_map">[docs]</a>    <span class="k">def</span> <span class="nf">flat_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Apply the given function to each record and then flatten results.</span>

<span class="sd">        Consider using ``.map_batches()`` for better performance (the batch size can be</span>
<span class="sd">        altered in map_batches).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; ds.flat_map(lambda x: [{&quot;id&quot;: 1}, {&quot;id&quot;: 2}, {&quot;id&quot;: 4}])</span>
<span class="sd">            FlatMap</span>
<span class="sd">            +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function or generator to apply to each record, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map</span>
<span class="sd">                worker.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray for each map worker.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.map_batches`</span>
<span class="sd">                Call this method to transform batches of data. It&#39;s faster and more</span>
<span class="sd">                flexible than :meth:`~Dataset.map` and :meth:`~Dataset.flat_map`.</span>

<span class="sd">            :meth:`~Dataset.map`</span>
<span class="sd">                Call this method to transform one record at time.</span>

<span class="sd">                This method isn&#39;t recommended because it&#39;s slow; call</span>
<span class="sd">                :meth:`~Dataset.map_batches` instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_warn_slow</span><span class="p">()</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_flat_map_fn</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">OneToOneStage</span><span class="p">(</span><span class="s2">&quot;FlatMap&quot;</span><span class="p">,</span> <span class="n">transform_fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">FlatMap</span><span class="p">(</span>
                <span class="n">input_op</span><span class="o">=</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.filter"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.filter.html#ray.data.Dataset.filter">[docs]</a>    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="nb">bool</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Filter out records that do not satisfy the given predicate.</span>

<span class="sd">        Consider using ``.map_batches()`` for better performance (you can implement</span>
<span class="sd">        filter by dropping records).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.filter(lambda x: x[&quot;id&quot;] % 2 == 0)</span>
<span class="sd">            Filter</span>
<span class="sd">            +- Dataset(num_blocks=..., num_rows=100, schema={id: int64})</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The predicate to apply to each record, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_warn_slow</span><span class="p">()</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_filter_fn</span><span class="p">()</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">OneToOneStage</span><span class="p">(</span><span class="s2">&quot;Filter&quot;</span><span class="p">,</span> <span class="n">transform_fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Filter</span><span class="p">(</span>
                <span class="n">input_op</span><span class="o">=</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.repartition"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.repartition.html#ray.data.Dataset.repartition">[docs]</a>    <span class="k">def</span> <span class="nf">repartition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Repartition the dataset into exactly this number of blocks.</span>

<span class="sd">        After repartitioning, all blocks in the returned dataset will have</span>
<span class="sd">        approximately the same number of rows.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; # Set the number of output partitions to write to disk.</span>
<span class="sd">            &gt;&gt;&gt; ds.repartition(10).write_parquet(&quot;/tmp/test&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            num_blocks: The number of blocks.</span>
<span class="sd">            shuffle: Whether to perform a distributed shuffle during the</span>
<span class="sd">                repartition. When shuffle is enabled, each output block</span>
<span class="sd">                contains a subset of data rows from each input block, which</span>
<span class="sd">                requires all-to-all data movement. When shuffle is disabled,</span>
<span class="sd">                output blocks are created from adjacent input blocks,</span>
<span class="sd">                minimizing data movement.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The repartitioned dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">RepartitionStage</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Repartition</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.random_shuffle"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.random_shuffle.html#ray.data.Dataset.random_shuffle">[docs]</a>    <span class="k">def</span> <span class="nf">random_shuffle</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Randomly shuffle the elements of this dataset.</span>

<span class="sd">        .. tip::</span>

<span class="sd">            ``random_shuffle`` can be slow. For better performance, try</span>
<span class="sd">            `Iterating over batches with shuffling &lt;iterating-over-data#iterating-over-batches-with-shuffling&gt;`_.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; # Shuffle this dataset randomly.</span>
<span class="sd">            &gt;&gt;&gt; ds.random_shuffle()</span>
<span class="sd">            RandomShuffle</span>
<span class="sd">            +- Dataset(num_blocks=..., num_rows=100, schema={id: int64})</span>
<span class="sd">            &gt;&gt;&gt; # Shuffle this dataset with a fixed random seed.</span>
<span class="sd">            &gt;&gt;&gt; ds.random_shuffle(seed=12345)</span>
<span class="sd">            RandomShuffle</span>
<span class="sd">            +- Dataset(num_blocks=..., num_rows=100, schema={id: int64})</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: Fix the random seed to use, otherwise one will be chosen</span>
<span class="sd">                based on system randomness.</span>
<span class="sd">            num_blocks: The number of output blocks after the shuffle, or None</span>
<span class="sd">                to retain the number of blocks.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The shuffled dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">RandomShuffleStage</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">RandomShuffle</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.randomize_block_order"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.randomize_block_order.html#ray.data.Dataset.randomize_block_order">[docs]</a>    <span class="k">def</span> <span class="nf">randomize_block_order</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Randomly shuffle the blocks of this dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; # Randomize the block order.</span>
<span class="sd">            &gt;&gt;&gt; ds.randomize_block_order() # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; # Randomize the block order with a fixed random seed.</span>
<span class="sd">            &gt;&gt;&gt; ds.randomize_block_order(seed=12345) # doctest: +SKIP</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: Fix the random seed to use, otherwise one will be chosen</span>
<span class="sd">                based on system randomness.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The block-shuffled dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">RandomizeBlocksStage</span><span class="p">(</span><span class="n">seed</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">RandomizeBlocks</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.random_sample"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.random_sample.html#ray.data.Dataset.random_sample">[docs]</a>    <span class="k">def</span> <span class="nf">random_sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">fraction</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Randomly samples a fraction of the elements of this dataset.</span>

<span class="sd">        Note that the exact number of elements returned is not guaranteed,</span>
<span class="sd">        and that the number of elements being returned is roughly fraction * total_rows.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ds.random_sample(0.1) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ds.random_sample(0.2, seed=12345) # doctest: +SKIP</span>

<span class="sd">        Args:</span>
<span class="sd">            fraction: The fraction of elements to sample.</span>
<span class="sd">            seed: Seeds the python random pRNG generator.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Returns a Dataset containing the sampled elements.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">random</span>

        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_blocks</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot sample from an empty Dataset.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fraction</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">fraction</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fraction must be between 0 and 1.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">):</span>
                <span class="c1"># Lets the item pass if weight generated for that item &lt;= fraction</span>
                <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)))</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="n">fraction</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">_create_possibly_ragged_ndarray</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported batch type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.streaming_split"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.streaming_split.html#ray.data.Dataset.streaming_split">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">streaming_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">equal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">locality_hints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;NodeIdStr&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">DataIterator</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns ``n`` :class:`DataIterators &lt;ray.data.DataIterator&gt;` that can</span>
<span class="sd">        be used to read disjoint subsets of the dataset in parallel.</span>

<span class="sd">        This method is the recommended way to consume Datasets from multiple</span>
<span class="sd">        processes (e.g., for distributed training), and requires streaming execution</span>
<span class="sd">        mode.</span>

<span class="sd">        Streaming split works by delegating the execution of this Dataset to a</span>
<span class="sd">        coordinator actor. The coordinator pulls block references from the executed</span>
<span class="sd">        stream, and divides those blocks among `n` output iterators. Iterators pull</span>
<span class="sd">        blocks from the coordinator actor to return to their caller on `next`.</span>

<span class="sd">        The returned iterators are also repeatable; each iteration will trigger a</span>
<span class="sd">        new execution of the Dataset. There is an implicit barrier at the start of</span>
<span class="sd">        each iteration, which means that `next` must be called on all iterators before</span>
<span class="sd">        the iteration starts.</span>

<span class="sd">        Warning: because iterators are pulling blocks from the same Dataset</span>
<span class="sd">        execution, if one iterator falls behind other iterators may be stalled.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000000)</span>
<span class="sd">            &gt;&gt;&gt; it1, it2 = ds.streaming_split(2, equal=True)</span>

<span class="sd">            &gt;&gt;&gt; # Can consume from both iterators in parallel.</span>
<span class="sd">            &gt;&gt;&gt; @ray.remote</span>
<span class="sd">            ... def consume(it):</span>
<span class="sd">            ...    for batch in it.iter_batches():</span>
<span class="sd">            ...        print(batch)</span>
<span class="sd">            &gt;&gt;&gt; ray.get([consume.remote(it1), consume.remote(it2)])  # doctest: +SKIP</span>

<span class="sd">            &gt;&gt;&gt; # Can loop over the iterators multiple times (multiple epochs).</span>
<span class="sd">            &gt;&gt;&gt; @ray.remote</span>
<span class="sd">            ... def train(it):</span>
<span class="sd">            ...    NUM_EPOCHS = 100</span>
<span class="sd">            ...    for _ in range(NUM_EPOCHS):</span>
<span class="sd">            ...        for batch in it.iter_batches():</span>
<span class="sd">            ...            print(batch)</span>
<span class="sd">            &gt;&gt;&gt; ray.get([train.remote(it1), train.remote(it2)])  # doctest: +SKIP</span>

<span class="sd">            &gt;&gt;&gt; # ERROR: this will block waiting for a read on `it2` to start.</span>
<span class="sd">            &gt;&gt;&gt; ray.get(train.remote(it1))  # doctest: +SKIP</span>

<span class="sd">        Args:</span>
<span class="sd">            n: Number of output iterators to return.</span>
<span class="sd">            equal: If True, each output iterator will see an exactly equal number</span>
<span class="sd">                of rows, dropping data if necessary. If False, some iterators may see</span>
<span class="sd">                slightly more or less rows than other, but no data will be dropped.</span>
<span class="sd">            locality_hints: Specify the node ids corresponding to each iterator</span>
<span class="sd">                location. Dataset will try to minimize data movement based on the</span>
<span class="sd">                iterator output locations. This list must have length ``n``. You can</span>
<span class="sd">                get the current node id of a task or actor by calling</span>
<span class="sd">                ``ray.get_runtime_context().get_node_id()``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The output iterator splits. These iterators are Ray-serializable and can</span>
<span class="sd">            be freely passed to any Ray task or actor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">StreamSplitDataIterator</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">equal</span><span class="p">,</span> <span class="n">locality_hints</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.split"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split.html#ray.data.Dataset.split">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">equal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">locality_hints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset into ``n`` disjoint pieces.</span>

<span class="sd">        This returns a list of MaterializedDatasets that can be passed to Ray tasks</span>
<span class="sd">        and actors and used to read the dataset records in parallel.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; workers = ... # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; # Split up a dataset to process over `n` worker actors.</span>
<span class="sd">            &gt;&gt;&gt; shards = ds.split(len(workers), locality_hints=workers) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; for shard, worker in zip(shards, workers): # doctest: +SKIP</span>
<span class="sd">            ...     worker.consume.remote(shard) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        See also: ``Dataset.split_at_indices``, ``Dataset.split_proportionately``,</span>
<span class="sd">            and ``Dataset.streaming_split``.</span>

<span class="sd">        Args:</span>
<span class="sd">            n: Number of child datasets to return.</span>
<span class="sd">            equal: Whether to guarantee each split has an equal</span>
<span class="sd">                number of records. This may drop records if they cannot be</span>
<span class="sd">                divided equally among the splits.</span>
<span class="sd">            locality_hints: [Experimental] A list of Ray actor handles of size ``n``.</span>
<span class="sd">                The system will try to co-locate the blocks of the i-th dataset</span>
<span class="sd">                with the i-th actor to maximize data locality.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of ``n`` disjoint dataset splits.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The number of splits </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is not positive.&quot;</span><span class="p">)</span>

        <span class="c1"># fallback to split_at_indices for equal split without locality hints.</span>
        <span class="c1"># simple benchmarks shows spilit_at_indices yields more stable performance.</span>
        <span class="c1"># https://github.com/ray-project/ray/pull/26641 for more context.</span>
        <span class="k">if</span> <span class="n">equal</span> <span class="ow">and</span> <span class="n">locality_hints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
            <span class="n">split_index</span> <span class="o">=</span> <span class="n">count</span> <span class="o">//</span> <span class="n">n</span>
            <span class="c1"># we are creating n split_indices which will generate</span>
            <span class="c1"># n + 1 splits; the last split will at most contains (n - 1)</span>
            <span class="c1"># rows, which could be safely dropped.</span>
            <span class="n">split_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">split_index</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">shards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">shards</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">locality_hints</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The length of locality_hints </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;doesn&#39;t equal the number of splits </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
            <span class="c1"># TODO: this is unreachable code.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;locality_hints must not contain duplicate actor handles&quot;</span>
                <span class="p">)</span>

        <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">owned_by_consumer</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="n">block_refs</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">blocks</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">locality_hints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">block_refs</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="n">meta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

            <span class="n">split_datasets</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">meta</span><span class="p">):</span>
                <span class="n">block_list</span> <span class="o">=</span> <span class="n">BlockList</span><span class="p">(</span>
                    <span class="n">b</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">m</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span>
                <span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span>
                <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">ref_bundles</span> <span class="o">=</span> <span class="n">_block_list_to_bundles</span><span class="p">(</span><span class="n">block_list</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="p">)</span>
                    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
                <span class="n">split_datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">MaterializedDataset</span><span class="p">(</span>
                        <span class="n">ExecutionPlan</span><span class="p">(</span>
                            <span class="n">block_list</span><span class="p">,</span>
                            <span class="n">stats</span><span class="p">,</span>
                            <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
                        <span class="n">logical_plan</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">split_datasets</span>

        <span class="n">metadata_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="n">b</span><span class="p">:</span> <span class="n">m</span> <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">block_refs</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)}</span>

        <span class="c1"># If the locality_hints is set, we use a two-round greedy algorithm</span>
        <span class="c1"># to co-locate the blocks with the actors based on block</span>
        <span class="c1"># and actor&#39;s location (node_id).</span>
        <span class="c1">#</span>
        <span class="c1"># The split algorithm tries to allocate equally-sized blocks regardless</span>
        <span class="c1"># of locality. Thus we first calculate the expected number of blocks</span>
        <span class="c1"># for each split.</span>
        <span class="c1">#</span>
        <span class="c1"># In the first round, for each actor, we look for all blocks that</span>
        <span class="c1"># match the actor&#39;s node_id, then allocate those matched blocks to</span>
        <span class="c1"># this actor until we reach the limit(expected number).</span>
        <span class="c1">#</span>
        <span class="c1"># In the second round: fill each actor&#39;s allocation with</span>
        <span class="c1"># remaining unallocated blocks until we reach the limit.</span>

        <span class="k">def</span> <span class="nf">build_allocation_size_map</span><span class="p">(</span>
            <span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">actors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Given the total number of blocks and a list of actors, calcuate</span>
<span class="sd">            the expected number of blocks to allocate for each actor.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">num_actors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actors</span><span class="p">)</span>
            <span class="n">num_blocks_per_actor</span> <span class="o">=</span> <span class="n">num_blocks</span> <span class="o">//</span> <span class="n">num_actors</span>
            <span class="n">num_blocks_left</span> <span class="o">=</span> <span class="n">num_blocks</span> <span class="o">-</span> <span class="n">num_blocks_per_actor</span> <span class="o">*</span> <span class="n">n</span>
            <span class="n">num_blocks_by_actor</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">actor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">actors</span><span class="p">):</span>
                <span class="n">num_blocks_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_blocks_per_actor</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_blocks_left</span><span class="p">:</span>
                    <span class="n">num_blocks_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">num_blocks_by_actor</span>

        <span class="k">def</span> <span class="nf">build_block_refs_by_node_id</span><span class="p">(</span>
            <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]],</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]]:</span>
            <span class="sd">&quot;&quot;&quot;Build the reverse index from node_id to block_refs. For</span>
<span class="sd">            simplicity, if the block is stored on multiple nodes we</span>
<span class="sd">            only pick the first one.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">block_ref_locations</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">get_object_locations</span><span class="p">(</span><span class="n">blocks</span><span class="p">)</span>
            <span class="n">block_refs_by_node_id</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">:</span>
                <span class="n">node_ids</span> <span class="o">=</span> <span class="n">block_ref_locations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block_ref</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node_ids&quot;</span><span class="p">,</span> <span class="p">[])</span>
                <span class="n">node_id</span> <span class="o">=</span> <span class="n">node_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">node_ids</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="n">block_refs_by_node_id</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block_ref</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">block_refs_by_node_id</span>

        <span class="k">def</span> <span class="nf">build_node_id_by_actor</span><span class="p">(</span><span class="n">actors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Build a map from a actor to its node_id.&quot;&quot;&quot;</span>
            <span class="n">actors_state</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">actors</span><span class="p">()</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">actor</span><span class="p">:</span> <span class="n">actors_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">actor</span><span class="o">.</span><span class="n">_actor_id</span><span class="o">.</span><span class="n">hex</span><span class="p">(),</span> <span class="p">{})</span>
                <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;Address&quot;</span><span class="p">,</span> <span class="p">{})</span>
                <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;NodeID&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">actors</span>
            <span class="p">}</span>

        <span class="c1"># expected number of blocks to be allocated for each actor</span>
        <span class="n">expected_block_count_by_actor</span> <span class="o">=</span> <span class="n">build_allocation_size_map</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">block_refs</span><span class="p">),</span> <span class="n">locality_hints</span>
        <span class="p">)</span>
        <span class="c1"># the reverse index from node_id to block_refs</span>
        <span class="n">block_refs_by_node_id</span> <span class="o">=</span> <span class="n">build_block_refs_by_node_id</span><span class="p">(</span><span class="n">block_refs</span><span class="p">)</span>
        <span class="c1"># the map from actor to its node_id</span>
        <span class="n">node_id_by_actor</span> <span class="o">=</span> <span class="n">build_node_id_by_actor</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span>

        <span class="n">allocation_per_actor</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

        <span class="c1"># In the first round, for each actor, we look for all blocks that</span>
        <span class="c1"># match the actor&#39;s node_id, then allocate those matched blocks to</span>
        <span class="c1"># this actor until we reach the limit(expected number)</span>
        <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span><span class="p">:</span>
            <span class="n">node_id</span> <span class="o">=</span> <span class="n">node_id_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="n">matching_blocks</span> <span class="o">=</span> <span class="n">block_refs_by_node_id</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span>
            <span class="n">expected_block_count</span> <span class="o">=</span> <span class="n">expected_block_count_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="n">allocation</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="n">matching_blocks</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">allocation</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">expected_block_count</span><span class="p">:</span>
                <span class="n">allocation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matching_blocks</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>
            <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">=</span> <span class="n">allocation</span>

        <span class="c1"># In the second round: fill each actor&#39;s allocation with</span>
        <span class="c1"># remaining unallocated blocks until we reach the limit</span>
        <span class="n">remaining_block_refs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">block_refs_by_node_id</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span><span class="p">:</span>
            <span class="k">while</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">expected_block_count_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="p">)</span>

        <span class="n">per_split_block_lists</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">BlockList</span><span class="p">(</span>
                <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">],</span>
                <span class="p">[</span><span class="n">metadata_mapping</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]],</span>
                <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">equal</span><span class="p">:</span>
            <span class="c1"># equalize the splits</span>
            <span class="n">per_split_block_lists</span> <span class="o">=</span> <span class="n">_equalize</span><span class="p">(</span><span class="n">per_split_block_lists</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="p">)</span>

        <span class="n">split_datasets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">block_split</span> <span class="ow">in</span> <span class="n">per_split_block_lists</span><span class="p">:</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span>
            <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ref_bundles</span> <span class="o">=</span> <span class="n">_block_list_to_bundles</span><span class="p">(</span><span class="n">block_split</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
            <span class="n">split_datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">MaterializedDataset</span><span class="p">(</span>
                    <span class="n">ExecutionPlan</span><span class="p">(</span>
                        <span class="n">block_split</span><span class="p">,</span>
                        <span class="n">stats</span><span class="p">,</span>
                        <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
                    <span class="n">logical_plan</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">split_datasets</span></div>

<div class="viewcode-block" id="Dataset.split_at_indices"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split_at_indices.html#ray.data.Dataset.split_at_indices">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">split_at_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset at the given indices (like np.split).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; d1, d2, d3 = ds.split_at_indices([2, 5])</span>
<span class="sd">            &gt;&gt;&gt; d1.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1])}</span>
<span class="sd">            &gt;&gt;&gt; d2.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 4])}</span>
<span class="sd">            &gt;&gt;&gt; d3.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([5, 6, 7, 8, 9])}</span>

<span class="sd">        Time complexity: O(num splits)</span>

<span class="sd">        See also: ``Dataset.split_at_indices``, ``Dataset.split_proportionately``,</span>
<span class="sd">            and ``Dataset.streaming_split``.</span>

<span class="sd">        Args:</span>
<span class="sd">            indices: List of sorted integers which indicate where the dataset</span>
<span class="sd">                will be split. If an index exceeds the length of the dataset,</span>
<span class="sd">                an empty dataset will be returned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The dataset splits.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be at least of length 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">!=</span> <span class="n">indices</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be sorted&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be positive&quot;</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">block_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="n">_split_at_indices</span><span class="p">(</span>
            <span class="n">block_list</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">(),</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">split_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="n">parent_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
            <span class="n">stats</span> <span class="o">=</span> <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Split&quot;</span><span class="p">:</span> <span class="n">ms</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="n">parent_stats</span><span class="p">)</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">time_total_s</span> <span class="o">=</span> <span class="n">split_duration</span>

            <span class="n">split_block_list</span> <span class="o">=</span> <span class="n">BlockList</span><span class="p">(</span>
                <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span>
            <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ref_bundles</span> <span class="o">=</span> <span class="n">_block_list_to_bundles</span><span class="p">(</span>
                    <span class="n">split_block_list</span><span class="p">,</span> <span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
                <span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>

            <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">MaterializedDataset</span><span class="p">(</span>
                    <span class="n">ExecutionPlan</span><span class="p">(</span>
                        <span class="n">split_block_list</span><span class="p">,</span>
                        <span class="n">stats</span><span class="p">,</span>
                        <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
                    <span class="n">logical_plan</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">splits</span></div>

<div class="viewcode-block" id="Dataset.split_proportionately"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split_proportionately.html#ray.data.Dataset.split_proportionately">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">split_proportionately</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">proportions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset using proportions.</span>

<span class="sd">        A common use case for this would be splitting the dataset into train</span>
<span class="sd">        and test sets (equivalent to eg. scikit-learn&#39;s ``train_test_split``).</span>
<span class="sd">        See also ``Dataset.train_test_split`` for a higher level abstraction.</span>

<span class="sd">        The indices to split at will be calculated in such a way so that all splits</span>
<span class="sd">        always contains at least one element. If that is not possible,</span>
<span class="sd">        an exception will be raised.</span>

<span class="sd">        This is equivalent to caulculating the indices manually and calling</span>
<span class="sd">        ``Dataset.split_at_indices``.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; d1, d2, d3 = ds.split_proportionately([0.2, 0.5])</span>
<span class="sd">            &gt;&gt;&gt; d1.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1])}</span>
<span class="sd">            &gt;&gt;&gt; d2.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 4, 5, 6])}</span>
<span class="sd">            &gt;&gt;&gt; d3.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([7, 8, 9])}</span>

<span class="sd">        Time complexity: O(num splits)</span>

<span class="sd">        See also: ``Dataset.split``, ``Dataset.split_at_indices``,</span>
<span class="sd">        ``Dataset.train_test_split``</span>

<span class="sd">        Args:</span>
<span class="sd">            proportions: List of proportions to split the dataset according to.</span>
<span class="sd">                Must sum up to less than 1, and each proportion has to be bigger</span>
<span class="sd">                than 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The dataset splits.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must be at least of length 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must sum to less than 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">proportions</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must be bigger than 0&quot;</span><span class="p">)</span>

        <span class="n">dataset_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
        <span class="n">cumulative_proportions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span>
        <span class="n">split_indices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">dataset_length</span> <span class="o">*</span> <span class="n">proportion</span><span class="p">)</span> <span class="k">for</span> <span class="n">proportion</span> <span class="ow">in</span> <span class="n">cumulative_proportions</span>
        <span class="p">]</span>

        <span class="c1"># Ensure each split has at least one element</span>
        <span class="n">subtract</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">subtract</span>
            <span class="k">if</span> <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="n">subtract</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">split_indices</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Couldn&#39;t create non-empty splits with the given proportions.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.train_test_split"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.train_test_split.html#ray.data.Dataset.train_test_split">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">train_test_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">test_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">,</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset into train and test subsets.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(8)</span>
<span class="sd">            &gt;&gt;&gt; train, test = ds.train_test_split(test_size=0.25)</span>
<span class="sd">            &gt;&gt;&gt; train.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4, 5])}</span>
<span class="sd">            &gt;&gt;&gt; test.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([6, 7])}</span>

<span class="sd">        Args:</span>
<span class="sd">            test_size: If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">                proportion of the dataset to include in the test split. If int,</span>
<span class="sd">                represents the absolute number of test samples. The train split will</span>
<span class="sd">                always be the compliment of the test split.</span>
<span class="sd">            shuffle: Whether or not to globally shuffle the dataset before splitting.</span>
<span class="sd">                Defaults to False. This may be a very expensive operation with large</span>
<span class="sd">                dataset.</span>
<span class="sd">            seed: Fix the random seed to use for shuffle, otherwise one will be chosen</span>
<span class="sd">                based on system randomness. Ignored if ``shuffle=False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Train and test subsets as two MaterializedDatasets.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">random_shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`test_size` must be int or float got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If `test_size` is a float, it must be bigger than 0 and smaller &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;than 1. Got </span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">split_proportionately</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ds_length</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="n">ds_length</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If `test_size` is an int, it must be bigger than 0 and smaller &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;than the size of the dataset (</span><span class="si">{</span><span class="n">ds_length</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">([</span><span class="n">ds_length</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">])</span></div>

<div class="viewcode-block" id="Dataset.union"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.union.html#ray.data.Dataset.union">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Args:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">union</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">other</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and combine this dataset with others of the same type.</span>

<span class="sd">        The order of the blocks in the datasets is preserved, as is the</span>
<span class="sd">        relative ordering between the datasets passed in the argument list.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Unioned datasets are not lineage-serializable, i.e. they can not be</span>
<span class="sd">            used as a tunable hyperparameter in Ray Tune.</span>

<span class="sd">        Args:</span>
<span class="sd">            other: List of datasets to combine with this one. The datasets</span>
<span class="sd">                must have the same schema as this dataset, otherwise the</span>
<span class="sd">                behavior is undefined.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new dataset holding the union of their data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>

        <span class="n">owned_by_consumer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
        <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
        <span class="n">bls</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">has_nonlazy</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
            <span class="n">bl</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bl</span><span class="p">,</span> <span class="n">LazyBlockList</span><span class="p">):</span>
                <span class="n">has_nonlazy</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">bls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bl</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">has_nonlazy</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">bl</span> <span class="ow">in</span> <span class="n">bls</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bl</span><span class="p">,</span> <span class="n">LazyBlockList</span><span class="p">):</span>
                    <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span> <span class="o">=</span> <span class="n">bl</span><span class="o">.</span><span class="n">_get_blocks_with_metadata</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span> <span class="o">=</span> <span class="n">bl</span><span class="o">.</span><span class="n">_blocks</span><span class="p">,</span> <span class="n">bl</span><span class="o">.</span><span class="n">_metadata</span>
                <span class="n">blocks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span>
                <span class="n">metadata</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ms</span><span class="p">)</span>
            <span class="n">blocklist</span> <span class="o">=</span> <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tasks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ReadTask</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">block_partition_refs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">BlockPartition</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">block_partition_meta_refs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">BlockMetadata</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Gather read task names from input blocks of unioned Datasets,</span>
            <span class="c1"># and concat them before passing to resulting LazyBlockList</span>
            <span class="n">read_task_names</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">self_read_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_in_blocks</span><span class="o">.</span><span class="n">_read_stage_name</span> <span class="ow">or</span> <span class="s2">&quot;Read&quot;</span>
            <span class="n">read_task_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">self_read_name</span><span class="p">)</span>
            <span class="n">other_read_names</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">o</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_in_blocks</span><span class="o">.</span><span class="n">_read_stage_name</span> <span class="ow">or</span> <span class="s2">&quot;Read&quot;</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">other</span>
            <span class="p">]</span>
            <span class="n">read_task_names</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">other_read_names</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">bl</span> <span class="ow">in</span> <span class="n">bls</span><span class="p">:</span>
                <span class="n">tasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bl</span><span class="o">.</span><span class="n">_tasks</span><span class="p">)</span>
                <span class="n">block_partition_refs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bl</span><span class="o">.</span><span class="n">_block_partition_refs</span><span class="p">)</span>
                <span class="n">block_partition_meta_refs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bl</span><span class="o">.</span><span class="n">_block_partition_meta_refs</span><span class="p">)</span>
            <span class="n">blocklist</span> <span class="o">=</span> <span class="n">LazyBlockList</span><span class="p">(</span>
                <span class="n">tasks</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;Union(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">read_task_names</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
                <span class="n">block_partition_refs</span><span class="p">,</span>
                <span class="n">block_partition_meta_refs</span><span class="p">,</span>
                <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ds</span><span class="o">.</span><span class="n">_get_epoch</span><span class="p">()</span> <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
        <span class="n">max_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="o">*</span><span class="n">epochs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">log_once</span><span class="p">(</span><span class="s2">&quot;dataset_epoch_warned&quot;</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Dataset contains data from multiple epochs: </span><span class="si">{}</span><span class="s2">, &quot;</span>
                    <span class="s2">&quot;likely due to a `rewindow()` call. The higher epoch &quot;</span>
                    <span class="s2">&quot;number </span><span class="si">{}</span><span class="s2"> will be used. This warning will not &quot;</span>
                    <span class="s2">&quot;be shown again.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">max_epoch</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">DatasetStats</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Union&quot;</span><span class="p">:</span> <span class="p">[]},</span>
            <span class="n">parent</span><span class="o">=</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">time_total_s</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">blocklist</span><span class="p">,</span> <span class="n">stats</span><span class="p">,</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">),</span>
            <span class="n">max_epoch</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.groupby"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.groupby.html#ray.data.Dataset.groupby">[docs]</a>    <span class="k">def</span> <span class="nf">groupby</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;GroupedData&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Group the dataset by the key function or column name.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Group by a table column and aggregate.</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: x % 3, &quot;B&quot;: x} for x in range(100)]).groupby(</span>
<span class="sd">            ...     &quot;A&quot;).count()</span>
<span class="sd">            Aggregate</span>
<span class="sd">            +- Dataset(num_blocks=100, num_rows=100, schema={A: int64, B: int64})</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            key: A column name. If this is None, the grouping is global.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A lazy GroupedData that can be aggregated later.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data.grouped_data</span> <span class="kn">import</span> <span class="n">GroupedData</span>

        <span class="c1"># Always allow None since groupby interprets that as grouping all</span>
        <span class="c1"># records into a single global group.</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_validate_key_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">key</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">GroupedData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.aggregate"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.aggregate.html#ray.data.Dataset.aggregate">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">aggs</span><span class="p">:</span> <span class="n">AggregateFn</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Aggregate the entire dataset as one group.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; from ray.data.aggregate import Max, Mean</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).aggregate(Max(&quot;id&quot;), Mean(&quot;id&quot;))</span>
<span class="sd">            {&#39;max(id)&#39;: 99, &#39;mean(id)&#39;: 49.5}</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            aggs: Aggregations to do.</span>

<span class="sd">        Returns:</span>
<span class="sd">            If the input dataset is a simple dataset then the output is</span>
<span class="sd">            a tuple of ``(agg1, agg2, ...)`` where each tuple element is</span>
<span class="sd">            the corresponding aggregation result.</span>
<span class="sd">            If the input dataset is an Arrow dataset then the output is</span>
<span class="sd">            an dict where each column is the corresponding aggregation result.</span>
<span class="sd">            If the dataset is empty, return ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="o">*</span><span class="n">aggs</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Dataset.sum"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.sum.html#ray.data.Dataset.sum">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute sum over entire dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).sum(&quot;id&quot;)</span>
<span class="sd">            4950</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)]).sum([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;sum(A)&#39;: 4950, &#39;sum(B)&#39;: 328350}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values will be ignored when computing the sum; if ``False``,</span>
<span class="sd">                if a null value is encountered, the output will be None.</span>
<span class="sd">                We consider np.nan, None, and pd.NaT to be null values.</span>
<span class="sd">                Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The sum result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: a dict containing the column-wise sum of all</span>
<span class="sd">              columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the sum of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column ``dict``</span>
<span class="sd">              containing the column-wise sum of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null, or any value is null</span>
<span class="sd">            AND ``ignore_nulls`` is ``False``, then the output will be None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Sum</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.min"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.min.html#ray.data.Dataset.min">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">min</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute minimum over entire dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).min(&quot;id&quot;)</span>
<span class="sd">            0</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)]).min([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;min(A)&#39;: 0, &#39;min(B)&#39;: 0}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values will be ignored when computing the min; if ``False``,</span>
<span class="sd">                if a null value is encountered, the output will be None.</span>
<span class="sd">                We consider np.nan, None, and pd.NaT to be null values.</span>
<span class="sd">                Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The min result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise min of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the min of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise min of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null, or any value is null</span>
<span class="sd">            AND ``ignore_nulls`` is ``False``, then the output will be None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Min</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.max"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.max.html#ray.data.Dataset.max">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">max</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute maximum over entire dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).max(&quot;id&quot;)</span>
<span class="sd">            99</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)]).max([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;max(A)&#39;: 99, &#39;max(B)&#39;: 9801}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values will be ignored when computing the max; if ``False``,</span>
<span class="sd">                if a null value is encountered, the output will be None.</span>
<span class="sd">                We consider np.nan, None, and pd.NaT to be null values.</span>
<span class="sd">                Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The max result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise max of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the max of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise max of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null, or any value is null</span>
<span class="sd">            AND ``ignore_nulls`` is ``False``, then the output will be None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Max</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.mean"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.mean.html#ray.data.Dataset.mean">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute mean over entire dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).mean(&quot;id&quot;)</span>
<span class="sd">            49.5</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)]).mean([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;mean(A)&#39;: 49.5, &#39;mean(B)&#39;: 3283.5}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values will be ignored when computing the mean; if ``False``,</span>
<span class="sd">                if a null value is encountered, the output will be None.</span>
<span class="sd">                We consider np.nan, None, and pd.NaT to be null values.</span>
<span class="sd">                Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The mean result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise mean of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the mean of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise mean of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null, or any value is null</span>
<span class="sd">            AND ``ignore_nulls`` is ``False``, then the output will be None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Mean</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.std"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.std.html#ray.data.Dataset.std">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ddof</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute standard deviation over entire dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; round(ray.data.range(100).std(&quot;id&quot;, ddof=0), 5)</span>
<span class="sd">            28.86607</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)]).std([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;std(A)&#39;: 29.011491975882016, &#39;std(B)&#39;: 2968.1748039269296}</span>

<span class="sd">        .. note:: This uses Welford&#39;s online method for an accumulator-style computation</span>
<span class="sd">            of the standard deviation. This method was chosen due to it&#39;s numerical</span>
<span class="sd">            stability, and it being computable in a single pass. This may give different</span>
<span class="sd">            (but more accurate) results than NumPy, Pandas, and sklearn, which use a</span>
<span class="sd">            less numerically stable two-pass algorithm.</span>
<span class="sd">            See</span>
<span class="sd">            https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford&#39;s_online_algorithm</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ddof: Delta Degrees of Freedom. The divisor used in calculations</span>
<span class="sd">                is ``N - ddof``, where ``N`` represents the number of elements.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values will be ignored when computing the std; if ``False``,</span>
<span class="sd">                if a null value is encountered, the output will be None.</span>
<span class="sd">                We consider np.nan, None, and pd.NaT to be null values.</span>
<span class="sd">                Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The standard deviation result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise std of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the std of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise std of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null, or any value is null</span>
<span class="sd">            AND ``ignore_nulls`` is ``False``, then the output will be None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Std</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.sort"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.sort.html#ray.data.Dataset.sort">[docs]</a>    <span class="k">def</span> <span class="nf">sort</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">descending</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sort the dataset by the specified key column or key function.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Sort by a single column in descending order.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items(</span>
<span class="sd">            ...     [{&quot;value&quot;: i} for i in range(1000)])</span>
<span class="sd">            &gt;&gt;&gt; ds.sort(&quot;value&quot;, descending=True)</span>
<span class="sd">            Sort</span>
<span class="sd">            +- Dataset(num_blocks=200, num_rows=1000, schema={value: int64})</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            key: The column to sort by. To sort by multiple columns, use a map function</span>
<span class="sd">                to generate the sort column beforehand.</span>
<span class="sd">            descending: Whether to sort in descending order.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new, sorted dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">SortStage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">descending</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Sort</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
                <span class="n">descending</span><span class="o">=</span><span class="n">descending</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.zip"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.zip.html#ray.data.Dataset.zip">[docs]</a>    <span class="k">def</span> <span class="nf">zip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and zip this dataset with the elements of another.</span>

<span class="sd">        The datasets must have the same number of rows. Their column sets will be</span>
<span class="sd">        merged, and any duplicate column names disambiguated with _1, _2, etc. suffixes.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The smaller of the two datasets will be repartitioned to align the number</span>
<span class="sd">            of rows per block with the larger dataset.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Zipped datasets are not lineage-serializable, i.e. they can not be used</span>
<span class="sd">            as a tunable hyperparameter in Ray Tune.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds1 = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds2 = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds1.zip(ds2).take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4]), &#39;id_1&#39;: array([0, 1, 2, 3, 4])}</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            other: The dataset to zip with on the right hand side.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A ``Dataset`` containing the columns of the second dataset</span>
<span class="sd">            concatenated horizontally with the columns of the first dataset,</span>
<span class="sd">            with duplicate column names disambiguated with _1, _2, etc. suffixes.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">ZipStage</span><span class="p">(</span><span class="n">other</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="n">other_logical_plan</span> <span class="o">=</span> <span class="n">other</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">other_logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Zip</span><span class="p">(</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span> <span class="n">other_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.limit"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.limit.html#ray.data.Dataset.limit">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">limit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and truncate the dataset to the first ``limit`` records.</span>

<span class="sd">        Contrary to :meth`.take`, this will not move any data to the caller&#39;s</span>
<span class="sd">        machine. Instead, it will return a new ``Dataset`` pointing to the truncated</span>
<span class="sd">        distributed data.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; ds.limit(5).take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4])}</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The size of the dataset to truncate to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The truncated dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">LimitStage</span><span class="p">(</span><span class="n">limit</span><span class="p">))</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Limit</span><span class="p">(</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="n">limit</span><span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.take_batch"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take_batch.html#ray.data.Dataset.take_batch">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">take_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataBatch</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return up to ``batch_size`` records from the dataset in a batch.</span>

<span class="sd">        Unlike take(), the records are returned in the same format as used for</span>
<span class="sd">        `iter_batches` and `map_batches`.</span>

<span class="sd">        This will move up to ``batch_size`` records to the caller&#39;s machine; if</span>
<span class="sd">        ``batch_size`` is very large, this can result in an OutOfMemory crash on</span>
<span class="sd">        the caller.</span>

<span class="sd">        Time complexity: O(batch_size specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size: The max number of records to return.</span>
<span class="sd">            batch_format: Specify ``&quot;default&quot;`` to use the default block format</span>
<span class="sd">                (NumPy), ``&quot;pandas&quot;`` to select ``pandas.DataFrame``, &quot;pyarrow&quot; to</span>
<span class="sd">                select ``pyarrow.Table``, or ``&quot;numpy&quot;`` to select</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``, or None to return the underlying block</span>
<span class="sd">                exactly as is with no additional formatting.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A batch of up to ``batch_size`` records from the dataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError if the dataset is empty.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">prefetch_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The dataset is empty.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="Dataset.take"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take.html#ray.data.Dataset.take">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">take</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return up to ``limit`` records from the dataset.</span>

<span class="sd">        This will move up to ``limit`` records to the caller&#39;s machine; if</span>
<span class="sd">        ``limit`` is very large, this can result in an OutOfMemory crash on</span>
<span class="sd">        the caller.</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The max number of records to return.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of up to ``limit`` records from the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">log_once</span><span class="p">(</span><span class="s2">&quot;dataset_take&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Tip: Use `take_batch()` instead of `take() / show()` to return &quot;</span>
                <span class="s2">&quot;records in pandas or numpy batch format.&quot;</span>
            <span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">():</span>
            <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Dataset.take_all"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take_all.html#ray.data.Dataset.take_all">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">take_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return all of the records in the dataset.</span>

<span class="sd">        This will move the entire dataset to the caller&#39;s machine; if the</span>
<span class="sd">        dataset is very large, this can result in an OutOfMemory crash on</span>
<span class="sd">        the caller.</span>

<span class="sd">        Time complexity: O(dataset size)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: Raise an error if the size exceeds the specified limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of all the records in the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">():</span>
            <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The dataset has more than the given limit of </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> records.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Dataset.show"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.show.html#ray.data.Dataset.show">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Print up to the given number of records from the dataset.</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The max number of records to print.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">limit</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.count"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.count.html#ray.data.Dataset.count">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;row count&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Count the number of records in the dataset.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism), O(1) for parquet</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of records in the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle empty dataset.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_blocks</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="c1"># For parquet, we can return the count directly from metadata.</span>
        <span class="n">meta_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_meta_count</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">meta_count</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">meta_count</span>

        <span class="n">get_num_rows</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_num_rows</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="p">[</span><span class="n">get_num_rows</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()]</span>
            <span class="p">)</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.schema"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.schema.html#ray.data.Dataset.schema">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;schema&quot;</span><span class="p">,</span>
        <span class="n">extra_condition</span><span class="o">=</span><span class="s2">&quot;or if ``fetch_if_missing=True`` (the default)&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">schema</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetch_if_missing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Schema&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the schema of the dataset.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            fetch_if_missing: If True, synchronously fetch the schema if it&#39;s</span>
<span class="sd">                not known. If False, None is returned if the schema is not known.</span>
<span class="sd">                Default is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The ``ray.data.Schema`` class of the records, or None if the</span>
<span class="sd">            schema is not known and fetch_if_missing is False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="n">base_schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="n">fetch_if_missing</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">base_schema</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">Schema</span><span class="p">(</span><span class="n">base_schema</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">base_schema</span></div>

<div class="viewcode-block" id="Dataset.columns"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.columns.html#ray.data.Dataset.columns">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;schema&quot;</span><span class="p">,</span>
        <span class="n">extra_condition</span><span class="o">=</span><span class="s2">&quot;or if ``fetch_if_missing=True`` (the default)&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetch_if_missing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the columns of this Dataset.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Create dataset from synthetic data.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; ds.columns()</span>
<span class="sd">            [&#39;id&#39;]</span>

<span class="sd">        Args:</span>
<span class="sd">            fetch_if_missing: If True, synchronously fetch the column names from the</span>
<span class="sd">                schema if it&#39;s not known. If False, None is returned if the schema is</span>
<span class="sd">                not known. Default is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of the column names for this Dataset or None if schema is not known</span>
<span class="sd">            and `fetch_if_missing` is False.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="n">fetch_if_missing</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">schema</span><span class="o">.</span><span class="n">names</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Dataset.num_blocks"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.num_blocks.html#ray.data.Dataset.num_blocks">[docs]</a>    <span class="k">def</span> <span class="nf">num_blocks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the number of blocks of this dataset.</span>

<span class="sd">        Note that during read and transform operations, the number of blocks</span>
<span class="sd">        may be dynamically adjusted to respect memory limits, increasing the</span>
<span class="sd">        number of blocks at runtime.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of blocks of this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.size_bytes"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.size_bytes.html#ray.data.Dataset.size_bytes">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">size_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the in-memory size of the dataset.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The in-memory size of the dataset in bytes, or None if the</span>
<span class="sd">            in-memory size is not known.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span> <span class="ow">or</span> <span class="n">metadata</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size_bytes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">size_bytes</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metadata</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.input_files"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.input_files.html#ray.data.Dataset.input_files">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">input_files</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the list of input files for the dataset.</span>

<span class="sd">        Time complexity: O(num input files)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The list of input files used to create the dataset, or an empty</span>
<span class="sd">            list if the input files is not known.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
        <span class="n">files</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metadata</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">input_files</span><span class="p">:</span>
                <span class="n">files</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">files</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_parquet"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_parquet.html#ray.data.Dataset.write_parquet">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_parquet</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">arrow_parquet_args_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{},</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the dataset to parquet.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of files, use ``.repartition()``.</span>

<span class="sd">        Unless a custom block path provider is given, the format of the output</span>
<span class="sd">        files will be {uuid}_{block_idx}.parquet, where ``uuid`` is an unique</span>
<span class="sd">        id for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ds.write_parquet(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where Parquet</span>
<span class="sd">                files will be written to.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: Try to create all directories in destination path</span>
<span class="sd">                if True. Does nothing if all directories already exist.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                pyarrow.fs.FileSystem.open_output_stream</span>
<span class="sd">            block_path_provider: BlockWritePathProvider implementation to</span>
<span class="sd">                write each dataset block to a custom output path.</span>
<span class="sd">            arrow_parquet_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments to use when writing each block to a file. Overrides</span>
<span class="sd">                any duplicate keys from arrow_parquet_args. This should be used</span>
<span class="sd">                instead of arrow_parquet_args if any of your write arguments</span>
<span class="sd">                cannot be pickled, or if you&#39;d like to lazily resolve the write</span>
<span class="sd">                arguments for each dataset block.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>
<span class="sd">            arrow_parquet_args: Options to pass to</span>
<span class="sd">                pyarrow.parquet.write_table(), which is used to write out each</span>
<span class="sd">                block to a file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">ParquetDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">write_args_fn</span><span class="o">=</span><span class="n">arrow_parquet_args_fn</span><span class="p">,</span>
            <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_json"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_json.html#ray.data.Dataset.write_json">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_json</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">pandas_json_args_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{},</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">pandas_json_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the dataset to json.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of files, use ``.repartition()``.</span>

<span class="sd">        Unless a custom block path provider is given, the format of the output</span>
<span class="sd">        files will be {self._uuid}_{block_idx}.json, where ``uuid`` is an</span>
<span class="sd">        unique id for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ds.write_json(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where json</span>
<span class="sd">                files will be written to.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: Try to create all directories in destination path</span>
<span class="sd">                if True. Does nothing if all directories already exist.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                pyarrow.fs.FileSystem.open_output_stream</span>
<span class="sd">            block_path_provider: BlockWritePathProvider implementation to</span>
<span class="sd">                write each dataset block to a custom output path.</span>
<span class="sd">            pandas_json_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments to use when writing each block to a file. Overrides</span>
<span class="sd">                any duplicate keys from pandas_json_args. This should be used</span>
<span class="sd">                instead of pandas_json_args if any of your write arguments</span>
<span class="sd">                cannot be pickled, or if you&#39;d like to lazily resolve the write</span>
<span class="sd">                arguments for each dataset block.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>
<span class="sd">            pandas_json_args: These args will be passed to</span>
<span class="sd">                pandas.DataFrame.to_json(), which we use under the hood to</span>
<span class="sd">                write out each Dataset block. These</span>
<span class="sd">                are dict(orient=&quot;records&quot;, lines=True) by default.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">JSONDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">write_args_fn</span><span class="o">=</span><span class="n">pandas_json_args_fn</span><span class="p">,</span>
            <span class="o">**</span><span class="n">pandas_json_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_csv"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_csv.html#ray.data.Dataset.write_csv">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_csv</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">arrow_csv_args_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{},</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the dataset to csv.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of files, use ``.repartition()``.</span>

<span class="sd">        Unless a custom block path provider is given, the format of the output</span>
<span class="sd">        files will be {uuid}_{block_idx}.csv, where ``uuid`` is an unique id</span>
<span class="sd">        for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ds.write_csv(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where csv</span>
<span class="sd">                files will be written to.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: Try to create all directories in destination path</span>
<span class="sd">                if True. Does nothing if all directories already exist.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                pyarrow.fs.FileSystem.open_output_stream</span>
<span class="sd">            block_path_provider: BlockWritePathProvider implementation to</span>
<span class="sd">                write each dataset block to a custom output path.</span>
<span class="sd">            arrow_csv_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments to use when writing each block to a file. Overrides</span>
<span class="sd">                any duplicate keys from arrow_csv_args. This should be used</span>
<span class="sd">                instead of arrow_csv_args if any of your write arguments</span>
<span class="sd">                cannot be pickled, or if you&#39;d like to lazily resolve the write</span>
<span class="sd">                arguments for each dataset block.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>
<span class="sd">            arrow_csv_args: Other CSV write options to pass to pyarrow.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">CSVDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">write_args_fn</span><span class="o">=</span><span class="n">arrow_csv_args_fn</span><span class="p">,</span>
            <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_tfrecords"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_tfrecords.html#ray.data.Dataset.write_tfrecords">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_tfrecords</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tf_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;schema_pb2.Schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the dataset to TFRecord files.</span>

<span class="sd">        The `TFRecord &lt;https://www.tensorflow.org/tutorials/load_data/tfrecord&gt;`_</span>
<span class="sd">        files will contain</span>
<span class="sd">        `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/Example&gt;`_ # noqa: E501</span>
<span class="sd">        records, with one Example record for each row in the dataset.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            tf.train.Feature only natively stores ints, floats, and bytes,</span>
<span class="sd">            so this function only supports datasets with these data types,</span>
<span class="sd">            and will error if the dataset contains unsupported types.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of files, use ``.repartition()``.</span>

<span class="sd">        Unless a custom block path provider is given, the format of the output</span>
<span class="sd">        files will be {uuid}_{block_idx}.tfrecords, where ``uuid`` is an unique id</span>
<span class="sd">        for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([</span>
<span class="sd">            ...     { &quot;name&quot;: &quot;foo&quot;, &quot;score&quot;: 42 },</span>
<span class="sd">            ...     { &quot;name&quot;: &quot;bar&quot;, &quot;score&quot;: 43 },</span>
<span class="sd">            ... ])</span>
<span class="sd">            &gt;&gt;&gt; ds.write_tfrecords(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where tfrecords</span>
<span class="sd">                files will be written to.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: Try to create all directories in destination path</span>
<span class="sd">                if True. Does nothing if all directories already exist.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                pyarrow.fs.FileSystem.open_output_stream</span>
<span class="sd">            block_path_provider: BlockWritePathProvider implementation to</span>
<span class="sd">                write each dataset block to a custom output path.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">TFRecordDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">tf_schema</span><span class="o">=</span><span class="n">tf_schema</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_webdataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_webdataset.html#ray.data.Dataset.write_webdataset">[docs]</a>    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_webdataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">callable</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the dataset to WebDataset files.</span>

<span class="sd">        The `TFRecord &lt;https://www.tensorflow.org/tutorials/load_data/tfrecord&gt;`_</span>
<span class="sd">        files will contain</span>
<span class="sd">        `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/Example&gt;`_ # noqa: E501</span>
<span class="sd">        records, with one Example record for each row in the dataset.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            tf.train.Feature only natively stores ints, floats, and bytes,</span>
<span class="sd">            so this function only supports datasets with these data types,</span>
<span class="sd">            and will error if the dataset contains unsupported types.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of files, use ``.repartition()``.</span>

<span class="sd">        Unless a custom block path provider is given, the format of the output</span>
<span class="sd">        files will be {uuid}_{block_idx}.tfrecords, where ``uuid`` is an unique id</span>
<span class="sd">        for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([</span>
<span class="sd">            ...     { &quot;name&quot;: &quot;foo&quot;, &quot;score&quot;: 42 },</span>
<span class="sd">            ...     { &quot;name&quot;: &quot;bar&quot;, &quot;score&quot;: 43 },</span>
<span class="sd">            ... ])</span>
<span class="sd">            &gt;&gt;&gt; ds.write_webdataset(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where tfrecords</span>
<span class="sd">                files will be written to.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: Try to create all directories in destination path</span>
<span class="sd">                if True. Does nothing if all directories already exist.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                pyarrow.fs.FileSystem.open_output_stream</span>
<span class="sd">            block_path_provider: BlockWritePathProvider implementation to</span>
<span class="sd">                write each dataset block to a custom output path.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="kn">from</span> <span class="nn">ray.data.datasource.webdataset_datasource</span> <span class="kn">import</span> <span class="n">WebDatasetDatasource</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">WebDatasetDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_numpy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_numpy.html#ray.data.Dataset.write_numpy">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_numpy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write a tensor column of the dataset to npy files.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records that</span>
<span class="sd">        contain a TensorArray column. To control the number of files, use</span>
<span class="sd">        ``.repartition()``.</span>

<span class="sd">        Unless a custom block path provider is given, the format of the output</span>
<span class="sd">        files will be {self._uuid}_{block_idx}.npy, where ``uuid`` is an unique</span>
<span class="sd">        id for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ds.write_numpy(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where npy</span>
<span class="sd">                files will be written to.</span>
<span class="sd">            column: The name of the table column that contains the tensor to</span>
<span class="sd">                be written.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: Try to create all directories in destination path</span>
<span class="sd">                if True. Does nothing if all directories already exist.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                pyarrow.fs.FileSystem.open_output_stream</span>
<span class="sd">            block_path_provider: BlockWritePathProvider implementation to</span>
<span class="sd">                write each dataset block to a custom output path.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">strict_mode</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">column</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">StrictModeError</span><span class="p">(</span>
                <span class="s2">&quot;In Ray 2.5, the column must be specified &quot;</span>
                <span class="s2">&quot;(e.g., `write_numpy(column=&#39;data&#39;)`).&quot;</span>
            <span class="p">)</span>
        <span class="n">column</span> <span class="o">=</span> <span class="n">column</span> <span class="ow">or</span> <span class="n">TENSOR_COLUMN_NAME</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">NumpyDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_mongo"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_mongo.html#ray.data.Dataset.write_mongo">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_mongo</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">database</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">collection</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the dataset to a MongoDB datasource.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of parallel write tasks, use ``.repartition()``</span>
<span class="sd">        before calling this method.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Currently, this supports only a subset of the pyarrow&#39;s types, due to the</span>
<span class="sd">            limitation of pymongoarrow which is used underneath. Writing unsupported</span>
<span class="sd">            types will fail on type checking. See all the supported types at:</span>
<span class="sd">            https://mongo-arrow.readthedocs.io/en/latest/data_types.html.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The records will be inserted into MongoDB as new documents. If a record has</span>
<span class="sd">            the _id field, this _id must be non-existent in MongoDB, otherwise the write</span>
<span class="sd">            will be rejected and fail (hence preexisting documents are protected from</span>
<span class="sd">            being mutated). It&#39;s fine to not have _id field in record and MongoDB will</span>
<span class="sd">            auto generate one at insertion.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">            &gt;&gt;&gt; docs = [{&quot;title&quot;: &quot;MongoDB Datasource test&quot;} for key in range(4)]</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_pandas(pd.DataFrame(docs))</span>
<span class="sd">            &gt;&gt;&gt; ds.write_mongo( # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt;     MongoDatasource(), # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt;     uri=&quot;mongodb://username:password@mongodb0.example.com:27017/?authSource=admin&quot;, # noqa: E501 # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt;     database=&quot;my_db&quot;, # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt;     collection=&quot;my_collection&quot;, # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ) # doctest: +SKIP</span>

<span class="sd">        Args:</span>
<span class="sd">            uri: The URI to the destination MongoDB where the dataset will be</span>
<span class="sd">                written to. For the URI format, see details in</span>
<span class="sd">                https://www.mongodb.com/docs/manual/reference/connection-string/.</span>
<span class="sd">            database: The name of the database. This database must exist otherwise</span>
<span class="sd">                ValueError will be raised.</span>
<span class="sd">            collection: The name of the collection in the database. This collection</span>
<span class="sd">                must exist otherwise ValueError will be raised.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="n">MongoDatasource</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">MongoDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">uri</span><span class="o">=</span><span class="n">uri</span><span class="p">,</span>
            <span class="n">database</span><span class="o">=</span><span class="n">database</span><span class="p">,</span>
            <span class="n">collection</span><span class="o">=</span><span class="n">collection</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_datasource"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_datasource.html#ray.data.Dataset.write_datasource">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_datasource</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datasource</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">write_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the dataset to a custom datasource.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; from ray.data.datasource import Datasource</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; class CustomDatasource(Datasource): # doctest: +SKIP</span>
<span class="sd">            ...     # define custom data source</span>
<span class="sd">            ...     pass # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; ds.write_datasource(CustomDatasource(...)) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            datasource: The datasource to write to.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>
<span class="sd">            write_args: Additional write args to pass to the datasource.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ray_remote_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">write_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;path&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">and</span> <span class="n">_is_local_scheme</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">ray</span><span class="o">.</span><span class="n">is_connected</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The local scheme paths </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> are not supported in Ray Client.&quot;</span>
                <span class="p">)</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
                <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span>
                <span class="n">soft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">datasource</span><span class="p">)</span><span class="o">.</span><span class="n">write</span> <span class="o">!=</span> <span class="n">Datasource</span><span class="o">.</span><span class="n">write</span><span class="p">:</span>
            <span class="n">write_fn</span> <span class="o">=</span> <span class="n">generate_write_fn</span><span class="p">(</span><span class="n">datasource</span><span class="p">,</span> <span class="o">**</span><span class="n">write_args</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">write_fn_wrapper</span><span class="p">(</span><span class="n">blocks</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Block</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Block</span><span class="p">]:</span>
                <span class="k">return</span> <span class="n">write_fn</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>

            <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
                <span class="n">OneToOneStage</span><span class="p">(</span>
                    <span class="s2">&quot;Write&quot;</span><span class="p">,</span>
                    <span class="n">write_fn_wrapper</span><span class="p">,</span>
                    <span class="n">TaskPoolStrategy</span><span class="p">(),</span>
                    <span class="n">ray_remote_args</span><span class="p">,</span>
                    <span class="n">fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
            <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">write_op</span> <span class="o">=</span> <span class="n">Write</span><span class="p">(</span>
                    <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                    <span class="n">datasource</span><span class="p">,</span>
                    <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">write_args</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">write_op</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                    <span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span>
                <span class="p">)</span><span class="o">.</span><span class="n">materialize</span><span class="p">()</span>
                <span class="n">blocks</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_blocks</span><span class="p">())</span>
                <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
                    <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span>
                <span class="p">)</span>
                <span class="n">write_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">block</span><span class="p">[</span><span class="s2">&quot;write_result&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_complete</span><span class="p">(</span><span class="n">write_results</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_failed</span><span class="p">([],</span> <span class="n">e</span><span class="p">)</span>
                <span class="k">raise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;The Datasource.do_write() is deprecated in &quot;</span>
                <span class="s2">&quot;Ray 2.4 and will be removed in future release. Use &quot;</span>
                <span class="s2">&quot;Datasource.write() instead.&quot;</span>
            <span class="p">)</span>

            <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">())</span>
            <span class="c1"># Prepare write in a remote task so that in Ray client mode, we</span>
            <span class="c1"># don&#39;t do metadata resolution from the client machine.</span>
            <span class="n">do_write</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_do_write</span><span class="p">,</span> <span class="n">retry_exceptions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_cpus</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">write_results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">WriteResult</span><span class="p">]]</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="n">do_write</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span>
                    <span class="n">datasource</span><span class="p">,</span>
                    <span class="n">ctx</span><span class="p">,</span>
                    <span class="n">blocks</span><span class="p">,</span>
                    <span class="n">metadata</span><span class="p">,</span>
                    <span class="n">ray_remote_args</span><span class="p">,</span>
                    <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">write_args</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="n">progress</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Write Progress&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">write_results</span><span class="p">))</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">progress</span><span class="o">.</span><span class="n">block_until_complete</span><span class="p">(</span><span class="n">write_results</span><span class="p">)</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_complete</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">write_results</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_failed</span><span class="p">(</span><span class="n">write_results</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
                <span class="k">raise</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="n">progress</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.iterator"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iterator.html#ray.data.Dataset.iterator">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">delegate</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Calling any of the consumption methods on the returned ``DataIterator``&quot;</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataIterator</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a :class:`~ray.data.DataIterator` that</span>
<span class="sd">        can be used to repeatedly iterate over the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for batch in ray.data.range(</span>
<span class="sd">            ...     1000000</span>
<span class="sd">            ... ).iterator().iter_batches(): # doctest: +SKIP</span>
<span class="sd">            ...     print(batch) # doctest: +SKIP</span>

<span class="sd">        .. note::</span>
<span class="sd">            It is recommended to use ``DataIterator`` methods over directly</span>
<span class="sd">            calling methods such as ``iter_batches()``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">DataIteratorImpl</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_rows"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_rows.html#ray.data.Dataset.iter_rows">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return a local row iterator over the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for i in ray.data.range(1000000).iter_rows(): # doctest: +SKIP</span>
<span class="sd">            ...     print(i) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_blocks: The number of blocks to prefetch ahead of the</span>
<span class="sd">                current block during the scan.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A local iterator over the entire dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">(</span><span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_batches.html#ray.data.Dataset.iter_batches">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">DataBatch</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated.</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">DataBatch</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return a local batched iterator over the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for batch in ray.data.range(1000000).iter_batches(): # doctest: +SKIP</span>
<span class="sd">            ...     print(batch) # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool will be used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1. You can revert back to the old</span>
<span class="sd">                prefetching behavior that uses `prefetch_blocks` by setting</span>
<span class="sd">                `use_legacy_iter_batches` to True in the datasetContext.</span>
<span class="sd">            batch_size: The number of rows in each batch, or None to use entire blocks</span>
<span class="sd">                as batches (blocks may contain different number of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            batch_format: Specify ``&quot;default&quot;`` to use the default block format</span>
<span class="sd">                (NumPy), ``&quot;pandas&quot;`` to select ``pandas.DataFrame``, &quot;pyarrow&quot; to</span>
<span class="sd">                select ``pyarrow.Table``, or ``&quot;numpy&quot;`` to select</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``, or None to return the underlying block</span>
<span class="sd">                exactly as is with no additional formatting.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data will be randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer will be drained.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over record batches.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_format</span> <span class="o">==</span> <span class="s2">&quot;native&quot;</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;The &#39;native&#39; batch format has been renamed &#39;default&#39;.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
            <span class="n">_collate_fn</span><span class="o">=</span><span class="n">_collate_fn</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_torch_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_torch_batches.html#ray.data.Dataset.iter_torch_batches">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_torch_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.dtype&quot;</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Callable</span><span class="p">[[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]],</span> <span class="n">Any</span><span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="s2">&quot;TorchTensorBatchType&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return a local batched iterator of Torch Tensors over the dataset.</span>

<span class="sd">        This iterator will yield single-tensor batches if the underlying dataset</span>
<span class="sd">        consists of a single column; otherwise, it will yield a dictionary of</span>
<span class="sd">        column-tensors. If looking for more flexibility in the tensor conversion (e.g.</span>
<span class="sd">        casting dtypes) or the batch format, try use `.iter_batches` directly, which is</span>
<span class="sd">        a lower-level API.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for batch in ray.data.range( # doctest: +SKIP</span>
<span class="sd">            ...     12,</span>
<span class="sd">            ... ).iter_torch_batches(batch_size=4):</span>
<span class="sd">            ...     print(batch.shape) # doctest: +SKIP</span>
<span class="sd">            torch.Size([4, 1])</span>
<span class="sd">            torch.Size([4, 1])</span>
<span class="sd">            torch.Size([4, 1])</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool will be used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1. You can revert back to the old</span>
<span class="sd">                prefetching behavior that uses `prefetch_blocks` by setting</span>
<span class="sd">                `use_legacy_iter_batches` to True in the datasetContext.</span>
<span class="sd">            batch_size: The number of rows in each batch, or None to use entire blocks</span>
<span class="sd">                as batches (blocks may contain different number of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            dtypes: The Torch dtype(s) for the created tensor(s); if None, the dtype</span>
<span class="sd">                will be inferred from the tensor data.</span>
<span class="sd">            device: The device on which the tensor should be placed; if None, the Torch</span>
<span class="sd">                tensor will be constructed on the CPU.</span>
<span class="sd">            collate_fn: A function to convert a Numpy batch to a PyTorch tensor batch.</span>
<span class="sd">                Potential use cases include collating along a dimension other than the</span>
<span class="sd">                first, padding sequences of various lengths, or generally handling</span>
<span class="sd">                batches of different length tensors. If not provided, the default</span>
<span class="sd">                collate function is used which simply converts the batch of numpy</span>
<span class="sd">                arrays to a batch of PyTorch tensors. This API is still experimental</span>
<span class="sd">                and is subject to change.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data will be randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer will be drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over Torch Tensor batches.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_tf_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_tf_batches.html#ray.data.Dataset.iter_tf_batches">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_tf_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.dtypes.DType&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.dtypes.DType&quot;</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorFlowTensorBatchType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return a local batched iterator of TensorFlow Tensors over the dataset.</span>

<span class="sd">        This iterator will yield single-tensor batches of the underlying dataset</span>
<span class="sd">        consists of a single column; otherwise, it will yield a dictionary of</span>
<span class="sd">        column-tensors.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If you don&#39;t need the additional flexibility provided by this method,</span>
<span class="sd">            consider using :meth:`~ray.data.Dataset.to_tf` instead. It&#39;s easier</span>
<span class="sd">            to use.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for batch in ray.data.range( # doctest: +SKIP</span>
<span class="sd">            ...     12,</span>
<span class="sd">            ... ).iter_tf_batches(batch_size=4):</span>
<span class="sd">            ...     print(batch.shape) # doctest: +SKIP</span>
<span class="sd">            (4, 1)</span>
<span class="sd">            (4, 1)</span>
<span class="sd">            (4, 1)</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool will be used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1. You can revert back to the old</span>
<span class="sd">                prefetching behavior that uses `prefetch_blocks` by setting</span>
<span class="sd">                `use_legacy_iter_batches` to True in the datasetContext.</span>
<span class="sd">            batch_size: The number of rows in each batch, or None to use entire blocks</span>
<span class="sd">                as batches (blocks may contain different number of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            dtypes: The TensorFlow dtype(s) for the created tensor(s); if None, the</span>
<span class="sd">                dtype will be inferred from the tensor data.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data will be randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer will be drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over TensorFlow Tensor batches.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_tf_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_torch"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_torch.html#ray.data.Dataset.to_torch">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_torch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">label_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">label_column_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_column_dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.dtype&quot;</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">unsqueeze_label_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">unsqueeze_feature_tensors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;torch.utils.data.IterableDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a Torch IterableDataset over this dataset.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>

<span class="sd">        It is recommended to use the returned ``IterableDataset`` directly</span>
<span class="sd">        instead of passing it into a torch ``DataLoader``.</span>

<span class="sd">        Each element in IterableDataset will be a tuple consisting of 2</span>
<span class="sd">        elements. The first item contains the feature tensor(s), and the</span>
<span class="sd">        second item is the label tensor. Those can take on different</span>
<span class="sd">        forms, depending on the specified arguments.</span>

<span class="sd">        For the features tensor (N is the ``batch_size`` and n, m, k</span>
<span class="sd">        are the number of features per tensor):</span>

<span class="sd">        * If ``feature_columns`` is a ``List[str]``, the features will be</span>
<span class="sd">          a tensor of shape (N, n), with columns corresponding to</span>
<span class="sd">          ``feature_columns``</span>

<span class="sd">        * If ``feature_columns`` is a ``List[List[str]]``, the features will be</span>
<span class="sd">          a list of tensors of shape [(N, m),...,(N, k)], with columns of each</span>
<span class="sd">          tensor corresponding to the elements of ``feature_columns``</span>

<span class="sd">        * If ``feature_columns`` is a ``Dict[str, List[str]]``, the features</span>
<span class="sd">          will be a dict of key-tensor pairs of shape</span>
<span class="sd">          {key1: (N, m),..., keyN: (N, k)}, with columns of each</span>
<span class="sd">          tensor corresponding to the value of ``feature_columns`` under the</span>
<span class="sd">          key.</span>

<span class="sd">        If ``unsqueeze_label_tensor=True`` (default), the label tensor will be</span>
<span class="sd">        of shape (N, 1). Otherwise, it will be of shape (N,).</span>
<span class="sd">        If ``label_column`` is specified as ``None``, then no column from the</span>
<span class="sd">        ``Dataset`` will be treated as the label, and the output label tensor</span>
<span class="sd">        will be ``None``.</span>

<span class="sd">        Note that you probably want to call ``.split()`` on this dataset if</span>
<span class="sd">        there are to be multiple Torch workers consuming the data.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            label_column: The name of the column used as the</span>
<span class="sd">                label (second element of the output list). Can be None for</span>
<span class="sd">                prediction, in which case the second element of returned</span>
<span class="sd">                tuple will also be None.</span>
<span class="sd">            feature_columns: The names of the columns</span>
<span class="sd">                to use as the features. Can be a list of lists or</span>
<span class="sd">                a dict of string-list pairs for multi-tensor output.</span>
<span class="sd">                If None, then use all columns except the label column as</span>
<span class="sd">                the features.</span>
<span class="sd">            label_column_dtype: The torch dtype to</span>
<span class="sd">                use for the label column. If None, then automatically infer</span>
<span class="sd">                the dtype.</span>
<span class="sd">            feature_column_dtypes: The dtypes to use for the feature</span>
<span class="sd">                tensors. This should match the format of ``feature_columns``,</span>
<span class="sd">                or be a single dtype, in which case it will be applied to</span>
<span class="sd">                all tensors. If None, then automatically infer the dtype.</span>
<span class="sd">            batch_size: How many samples per batch to yield at a time.</span>
<span class="sd">                Defaults to 1.</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool will be used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1. You can revert back to the old</span>
<span class="sd">                prefetching behavior that uses `prefetch_blocks` by setting</span>
<span class="sd">                `use_legacy_iter_batches` to True in the datasetContext.</span>
<span class="sd">            drop_last: Set to True to drop the last incomplete batch,</span>
<span class="sd">                if the dataset size is not divisible by the batch size. If</span>
<span class="sd">                False and the size of the stream is not divisible by the batch</span>
<span class="sd">                size, then the last batch will be smaller. Defaults to False.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data will be randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer will be drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>
<span class="sd">            unsqueeze_label_tensor: If set to True, the label tensor</span>
<span class="sd">                will be unsqueezed (reshaped to (N, 1)). Otherwise, it will</span>
<span class="sd">                be left as is, that is (N, ). In general, regression loss</span>
<span class="sd">                functions expect an unsqueezed tensor, while classification</span>
<span class="sd">                loss functions expect a squeezed one. Defaults to True.</span>
<span class="sd">            unsqueeze_feature_tensors: If set to True, the features tensors</span>
<span class="sd">                will be unsqueezed (reshaped to (N, 1)) before being concatenated into</span>
<span class="sd">                the final features tensor. Otherwise, they will be left as is, that is</span>
<span class="sd">                (N, ). Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A torch IterableDataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span>
            <span class="n">label_column</span><span class="o">=</span><span class="n">label_column</span><span class="p">,</span>
            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
            <span class="n">label_column_dtype</span><span class="o">=</span><span class="n">label_column_dtype</span><span class="p">,</span>
            <span class="n">feature_column_dtypes</span><span class="o">=</span><span class="n">feature_column_dtypes</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
            <span class="n">unsqueeze_label_tensor</span><span class="o">=</span><span class="n">unsqueeze_label_tensor</span><span class="p">,</span>
            <span class="n">unsqueeze_feature_tensors</span><span class="o">=</span><span class="n">unsqueeze_feature_tensors</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_tf"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_tf.html#ray.data.Dataset.to_tf">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">to_tf</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feature_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">label_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;tf.data.Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a TF Dataset over this dataset.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            If your dataset contains ragged tensors, this method errors. To prevent</span>
<span class="sd">            errors, :ref:`resize your tensors &lt;transforming_tensors&gt;`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@air-example-data/iris.csv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            Dataset(</span>
<span class="sd">               num_blocks=1,</span>
<span class="sd">               num_rows=150,</span>
<span class="sd">               schema={</span>
<span class="sd">                  sepal length (cm): double,</span>
<span class="sd">                  sepal width (cm): double,</span>
<span class="sd">                  petal length (cm): double,</span>
<span class="sd">                  petal width (cm): double,</span>
<span class="sd">                  target: int64</span>
<span class="sd">               }</span>
<span class="sd">            )</span>

<span class="sd">            If your model accepts a single tensor as input, specify a single feature column.</span>

<span class="sd">            &gt;&gt;&gt; ds.to_tf(feature_columns=&quot;sepal length (cm)&quot;, label_columns=&quot;target&quot;)  # doctest: +SKIP</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal length (cm)&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">            If your model accepts a dictionary as input, specify a list of feature columns.</span>

<span class="sd">            &gt;&gt;&gt; ds.to_tf([&quot;sepal length (cm)&quot;, &quot;sepal width (cm)&quot;], &quot;target&quot;)  # doctest: +SKIP</span>
<span class="sd">            &lt;_OptionsDataset element_spec=({&#39;sepal length (cm)&#39;: TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal length (cm)&#39;), &#39;sepal width (cm)&#39;: TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal width (cm)&#39;)}, TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">            If your dataset contains multiple features but your model accepts a single</span>
<span class="sd">            tensor as input, combine features with</span>
<span class="sd">            :class:`~ray.data.preprocessors.Concatenator`.</span>

<span class="sd">            &gt;&gt;&gt; from ray.data.preprocessors import Concatenator</span>
<span class="sd">            &gt;&gt;&gt; preprocessor = Concatenator(output_column_name=&quot;features&quot;, exclude=&quot;target&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds = preprocessor.transform(ds)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            Concatenator</span>
<span class="sd">            +- Dataset(</span>
<span class="sd">                  num_blocks=1,</span>
<span class="sd">                  num_rows=150,</span>
<span class="sd">                  schema={</span>
<span class="sd">                     sepal length (cm): double,</span>
<span class="sd">                     sepal width (cm): double,</span>
<span class="sd">                     petal length (cm): double,</span>
<span class="sd">                     petal width (cm): double,</span>
<span class="sd">                     target: int64</span>
<span class="sd">                  }</span>
<span class="sd">               )</span>
<span class="sd">            &gt;&gt;&gt; ds.to_tf(&quot;features&quot;, &quot;target&quot;)  # doctest: +SKIP</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=&#39;features&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">        Args:</span>
<span class="sd">            feature_columns: Columns that correspond to model inputs. If this is a</span>
<span class="sd">                string, the input data is a tensor. If this is a list, the input data</span>
<span class="sd">                is a ``dict`` that maps column names to their tensor representation.</span>
<span class="sd">            label_column: Columns that correspond to model targets. If this is a</span>
<span class="sd">                string, the target data is a tensor. If this is a list, the target data</span>
<span class="sd">                is a ``dict`` that maps column names to their tensor representation.</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool will be used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1. You can revert back to the old</span>
<span class="sd">                prefetching behavior that uses `prefetch_blocks` by setting</span>
<span class="sd">                `use_legacy_iter_batches` to True in the datasetContext.</span>
<span class="sd">            batch_size: Record batch size. Defaults to 1.</span>
<span class="sd">            drop_last: Set to True to drop the last incomplete batch,</span>
<span class="sd">                if the dataset size is not divisible by the batch size. If</span>
<span class="sd">                False and the size of the stream is not divisible by the batch</span>
<span class="sd">                size, then the last batch will be smaller. Defaults to False.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data will be randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer will be drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A ``tf.data.Dataset`` that yields inputs and targets.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~ray.data.Dataset.iter_tf_batches`</span>
<span class="sd">                Call this method if you need more flexibility.</span>

<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">to_tf</span><span class="p">(</span>
            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
            <span class="n">label_columns</span><span class="o">=</span><span class="n">label_columns</span><span class="p">,</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_dask"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_dask.html#ray.data.Dataset.to_dask">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_dask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">meta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pandas.Series&quot;</span><span class="p">,</span>
            <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
            <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
            <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;dask.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a Dask DataFrame.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>

<span class="sd">        Note that this function will set the Dask scheduler to Dask-on-Ray</span>
<span class="sd">        globally, via the config.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            meta: An empty pandas DataFrame or Series that matches the dtypes and column</span>
<span class="sd">                names of the stream. This metadata is necessary for many algorithms in</span>
<span class="sd">                dask dataframe to work. For ease of use, some alternative inputs are</span>
<span class="sd">                also available. Instead of a DataFrame, a dict of ``{name: dtype}`` or</span>
<span class="sd">                iterable of ``(name, dtype)`` can be provided (note that the order of</span>
<span class="sd">                the names should match the order of the columns). Instead of a series, a</span>
<span class="sd">                tuple of ``(name, dtype)`` can be used.</span>
<span class="sd">                By default, this will be inferred from the underlying Dataset schema,</span>
<span class="sd">                with this argument supplying an optional override.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Dask DataFrame created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">dask</span>
        <span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span>
        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">pa</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>
        <span class="kn">from</span> <span class="nn">ray.util.client.common</span> <span class="kn">import</span> <span class="n">ClientObjectRef</span>
        <span class="kn">from</span> <span class="nn">ray.util.dask</span> <span class="kn">import</span> <span class="n">ray_dask_get</span>

        <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">ray_dask_get</span><span class="p">)</span>

        <span class="nd">@dask</span><span class="o">.</span><span class="n">delayed</span>
        <span class="k">def</span> <span class="nf">block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">,</span> <span class="n">ClientObjectRef</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Dataset.to_dask() must be used with Dask-on-Ray, please &quot;</span>
                    <span class="s2">&quot;set the Dask scheduler to ray_dask_get (located in &quot;</span>
                    <span class="s2">&quot;ray.util.dask).&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">meta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">TensorDtype</span>

            <span class="c1"># Infer Dask metadata from Dataset schema.</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">):</span>
                <span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="n">col</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="p">(</span>
                                <span class="n">dtype</span>
                                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">TensorDtype</span><span class="p">)</span>
                                <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">object_</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">pa</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
                <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorType</span>

                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">type_</span><span class="p">,</span> <span class="n">ArrowTensorType</span><span class="p">)</span> <span class="k">for</span> <span class="n">type_</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
                    <span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="n">col</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="p">(</span>
                                    <span class="n">dtype</span><span class="o">.</span><span class="n">to_pandas_dtype</span><span class="p">()</span>
                                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ArrowTensorType</span><span class="p">)</span>
                                    <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">object_</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
                            <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">meta</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">empty_table</span><span class="p">()</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

        <span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">from_delayed</span><span class="p">(</span>
            <span class="p">[</span><span class="n">block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()],</span>
            <span class="n">meta</span><span class="o">=</span><span class="n">meta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">ddf</span></div>

<div class="viewcode-block" id="Dataset.to_mars"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_mars.html#ray.data.Dataset.to_mars">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_mars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;mars.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a MARS dataframe.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A MARS dataframe created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
        <span class="kn">from</span> <span class="nn">mars.dataframe.datasource.read_raydataset</span> <span class="kn">import</span> <span class="n">DataFrameReadRayDataset</span>
        <span class="kn">from</span> <span class="nn">mars.dataframe.utils</span> <span class="kn">import</span> <span class="n">parse_index</span>

        <span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>

        <span class="n">refs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_pandas_refs</span><span class="p">()</span>
        <span class="c1"># remove this when https://github.com/mars-project/mars/issues/2945 got fixed</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>  <span class="c1"># Backwards compat with non strict mode.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">):</span>
            <span class="n">dtypes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="n">dtypes</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">empty_table</span><span class="p">()</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">dtypes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported format of schema </span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">index_value</span> <span class="o">=</span> <span class="n">parse_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">RangeIndex</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">columns_value</span> <span class="o">=</span> <span class="n">parse_index</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">store_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">DataFrameReadRayDataset</span><span class="p">(</span><span class="n">refs</span><span class="o">=</span><span class="n">refs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">op</span><span class="p">(</span><span class="n">index_value</span><span class="o">=</span><span class="n">index_value</span><span class="p">,</span> <span class="n">columns_value</span><span class="o">=</span><span class="n">columns_value</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_modin"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_modin.html#ray.data.Dataset.to_modin">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_modin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;modin.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a Modin dataframe.</span>

<span class="sd">        This works by first converting this dataset into a distributed set of</span>
<span class="sd">        Pandas dataframes (using ``.to_pandas_refs()``). Please see caveats</span>
<span class="sd">        there. Then the individual dataframes are used to create the modin</span>
<span class="sd">        DataFrame using</span>
<span class="sd">        ``modin.distributed.dataframe.pandas.partitions.from_partitions()``.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using ``.to_arrow()`` or</span>
<span class="sd">        ``.get_internal_block_refs()``.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Modin dataframe created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="kn">from</span> <span class="nn">modin.distributed.dataframe.pandas.partitions</span> <span class="kn">import</span> <span class="n">from_partitions</span>

        <span class="n">pd_objs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_pandas_refs</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">from_partitions</span><span class="p">(</span><span class="n">pd_objs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_spark"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_spark.html#ray.data.Dataset.to_spark">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_spark</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spark</span><span class="p">:</span> <span class="s2">&quot;pyspark.sql.SparkSession&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pyspark.sql.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a Spark dataframe.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Spark dataframe created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">raydp</span>

        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>  <span class="c1"># Backwards compat with non strict mode.</span>
        <span class="k">return</span> <span class="n">raydp</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">ray_dataset_to_spark_dataframe</span><span class="p">(</span>
            <span class="n">spark</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_pandas"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_pandas.html#ray.data.Dataset.to_pandas">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_pandas</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a single Pandas DataFrame.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow or Pandas</span>
<span class="sd">        records. An error is raised if the number of records exceeds the</span>
<span class="sd">        provided limit. Note that you can use ``.limit()`` on the dataset</span>
<span class="sd">        beforehand to truncate the dataset manually.</span>

<span class="sd">        Time complexity: O(dataset size)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The maximum number of records to return. An error will be</span>
<span class="sd">                raised if the limit is exceeded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Pandas DataFrame created from this dataset, containing a limited</span>
<span class="sd">            number of records.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;the dataset has more than the given limit of </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;records: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">. If you are sure that a DataFrame with &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> rows will fit in local memory, use &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;ds.to_pandas(limit=</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>
        <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">DelegatingBlockBuilder</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">:</span>
            <span class="n">output</span><span class="o">.</span><span class="n">add_block</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="p">))</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_pandas_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_pandas_refs.html#ray.data.Dataset.to_pandas_refs">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_pandas_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a distributed set of Pandas dataframes.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using ``.to_arrow()`` or</span>
<span class="sd">        ``.get_internal_block_refs()``.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote Pandas dataframes created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">block_to_df</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_df</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">block_to_df</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()]</span></div>

<div class="viewcode-block" id="Dataset.to_numpy_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_numpy_refs.html#ray.data.Dataset.to_numpy_refs">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_numpy_refs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a distributed set of NumPy ndarrays.</span>

<span class="sd">        This is only supported for datasets convertible to NumPy ndarrays.</span>
<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using ``.to_arrow()`` or</span>
<span class="sd">        ``.get_internal_block_refs()``.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            column: The name of the column to convert to numpy, or None to specify the</span>
<span class="sd">            entire row. If not specified for Arrow or Pandas blocks, each returned</span>
<span class="sd">            future will represent a dict of column ndarrays.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote NumPy ndarrays created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">block_to_ndarray</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_ndarray</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">block_to_ndarray</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="p">]</span></div>

<div class="viewcode-block" id="Dataset.to_arrow_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_arrow_refs.html#ray.data.Dataset.to_arrow_refs">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_arrow_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a distributed set of Arrow tables.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        This function is zero-copy if the existing data is already in Arrow</span>
<span class="sd">        format. Otherwise, the data will be converted to Arrow format.</span>

<span class="sd">        Time complexity: O(1) unless conversion is required.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote Arrow tables created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="c1"># Schema is safe to call since we have already triggered execution with</span>
        <span class="c1"># get_internal_block_refs.</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>  <span class="c1"># Backwards compat with non strict mode.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="c1"># Zero-copy path.</span>
            <span class="k">return</span> <span class="n">blocks</span>

        <span class="n">block_to_arrow</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_arrow</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">block_to_arrow</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span></div>

<div class="viewcode-block" id="Dataset.to_random_access_dataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_random_access_dataset.html#ray.data.Dataset.to_random_access_dataset">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Args:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_random_access_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RandomAccessDataset</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a distributed RandomAccessDataset (EXPERIMENTAL).</span>

<span class="sd">        RandomAccessDataset partitions the dataset across the cluster by the given</span>
<span class="sd">        sort key, providing efficient random access to records via binary search. A</span>
<span class="sd">        number of worker actors are created, each of which has zero-copy access to the</span>
<span class="sd">        underlying sorted data blocks of the dataset.</span>

<span class="sd">        Note that the key must be unique in the dataset. If there are duplicate keys,</span>
<span class="sd">        an arbitrary value is returned.</span>

<span class="sd">        This is only supported for Arrow-format datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            key: The key column over which records can be queried.</span>
<span class="sd">            num_workers: The number of actors to use to serve random access queries.</span>
<span class="sd">                By default, this is determined by multiplying the number of Ray nodes</span>
<span class="sd">                in the cluster by four. As a rule of thumb, you can expect each worker</span>
<span class="sd">                to provide ~3000 records / second via ``get_async()``, and</span>
<span class="sd">                ~10000 records / second via ``multiget()``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_workers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">RandomAccessDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.repeat"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.repeat.html#ray.data.Dataset.repeat">[docs]</a>    <span class="nd">@Deprecated</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">times</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DatasetPipeline&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this into a DatasetPipeline by looping over this dataset.</span>

<span class="sd">        Transformations prior to the call to ``repeat()`` are evaluated once.</span>
<span class="sd">        Transformations done on the returned pipeline are evaluated on each</span>
<span class="sd">        loop of the pipeline over the base dataset.</span>

<span class="sd">        Note that every repeat of the dataset is considered an &quot;epoch&quot; for</span>
<span class="sd">        the purposes of ``DatasetPipeline.iter_epochs()``.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(5, parallelism=1)</span>
<span class="sd">            &gt;&gt;&gt; # Infinite pipeline of numbers [0, 5)</span>
<span class="sd">            &gt;&gt;&gt; ds.repeat().take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, ...])}</span>
<span class="sd">            &gt;&gt;&gt; # Can shuffle each epoch (dataset) in the pipeline.</span>
<span class="sd">            &gt;&gt;&gt; ds.repeat().random_shuffle().take_batch() # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 0, 4, 1, 4, 0, 2, 1, 3, ...])}</span>

<span class="sd">        Args:</span>
<span class="sd">            times: The number of times to loop over this dataset, or None</span>
<span class="sd">                to repeat indefinitely.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">_rewrite_read_stage</span>
        <span class="kn">from</span> <span class="nn">ray.data.dataset_pipeline</span> <span class="kn">import</span> <span class="n">DatasetPipeline</span>

        <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">is_read_stage_equivalent</span><span class="p">()</span> <span class="ow">and</span> <span class="n">ctx</span><span class="o">.</span><span class="n">optimize_fuse_read_stages</span><span class="p">:</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_get_source_blocks_and_stages</span><span class="p">()</span>
            <span class="n">blocks</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">outer_stats</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="n">_rewrite_read_stage</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">stages</span><span class="p">)</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
            <span class="n">outer_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">uuid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">()</span>
        <span class="n">outer_stats</span><span class="o">.</span><span class="n">dataset_uuid</span> <span class="o">=</span> <span class="n">uuid</span>

        <span class="k">if</span> <span class="n">times</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">times</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`times` must be &gt;= 1, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">times</span><span class="p">))</span>

        <span class="k">class</span> <span class="nc">Iterator</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">blocks</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span> <span class="o">=</span> <span class="n">blocks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_i</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">times</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_i</span> <span class="o">&gt;=</span> <span class="n">times</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">StopIteration</span>
                <span class="n">epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_i</span>
                <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_i</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">def</span> <span class="nf">gen</span><span class="p">():</span>
                    <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                        <span class="n">ExecutionPlan</span><span class="p">(</span>
                            <span class="n">blocks</span><span class="p">,</span>
                            <span class="n">outer_stats</span><span class="p">,</span>
                            <span class="n">dataset_uuid</span><span class="o">=</span><span class="n">uuid</span><span class="p">,</span>
                            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">epoch</span><span class="p">,</span>
                        <span class="n">lazy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">ds</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="n">uuid</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">ds</span>

                <span class="k">return</span> <span class="n">gen</span>

        <span class="k">class</span> <span class="nc">Iterable</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">blocks</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span> <span class="o">=</span> <span class="n">blocks</span>

            <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">Iterator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span><span class="p">)</span>

        <span class="n">pipe</span> <span class="o">=</span> <span class="n">DatasetPipeline</span><span class="p">(</span><span class="n">Iterable</span><span class="p">(</span><span class="n">blocks</span><span class="p">),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">times</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">read_stage</span><span class="p">:</span>
            <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">foreach_window</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">ds</span><span class="p">,</span> <span class="n">read_stage</span><span class="o">=</span><span class="n">read_stage</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">(</span>
                    <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">read_stage</span><span class="p">),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="kc">True</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">pipe</span></div>

<div class="viewcode-block" id="Dataset.window"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.window.html#ray.data.Dataset.window">[docs]</a>    <span class="nd">@Deprecated</span>
    <span class="k">def</span> <span class="nf">window</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">blocks_per_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bytes_per_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DatasetPipeline&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this into a DatasetPipeline by windowing over data blocks.</span>

<span class="sd">        Transformations prior to the call to ``window()`` are evaluated in</span>
<span class="sd">        bulk on the entire dataset. Transformations done on the returned</span>
<span class="sd">        pipeline are evaluated incrementally per window of blocks as data is</span>
<span class="sd">        read from the output of the pipeline.</span>

<span class="sd">        Windowing execution allows for output to be read sooner without</span>
<span class="sd">        waiting for all transformations to fully execute, and can also improve</span>
<span class="sd">        efficiency if transforms use different resources (e.g., GPUs).</span>

<span class="sd">        Without windowing::</span>

<span class="sd">            [preprocessing......]</span>
<span class="sd">                                  [inference.......]</span>
<span class="sd">                                                     [write........]</span>
<span class="sd">            Time -----------------------------------------------------------&gt;</span>

<span class="sd">        With windowing::</span>

<span class="sd">            [prep1] [prep2] [prep3]</span>
<span class="sd">                    [infer1] [infer2] [infer3]</span>
<span class="sd">                             [write1] [write2] [write3]</span>
<span class="sd">            Time -----------------------------------------------------------&gt;</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Create an inference pipeline.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_binary_files(dir) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; infer = ... # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; pipe = ds.window(blocks_per_window=10).map(infer) # doctest: +SKIP</span>
<span class="sd">            DatasetPipeline(num_windows=40, num_stages=2)</span>
<span class="sd">            &gt;&gt;&gt; # The higher the stage parallelism, the shorter the pipeline.</span>
<span class="sd">            &gt;&gt;&gt; pipe = ds.window(blocks_per_window=20).map(infer) # doctest: +SKIP</span>
<span class="sd">            DatasetPipeline(num_windows=20, num_stages=2)</span>
<span class="sd">            &gt;&gt;&gt; # Outputs can be incrementally read from the pipeline.</span>
<span class="sd">            &gt;&gt;&gt; for item in pipe.iter_rows(): # doctest: +SKIP</span>
<span class="sd">            ...    print(item) # doctest: +SKIP</span>

<span class="sd">        Args:</span>
<span class="sd">            blocks_per_window: The window size (parallelism) in blocks.</span>
<span class="sd">                Increasing window size increases pipeline throughput, but also</span>
<span class="sd">                increases the latency to initial output, since it decreases the</span>
<span class="sd">                length of the pipeline. Setting this to infinity effectively</span>
<span class="sd">                disables pipelining.</span>
<span class="sd">            bytes_per_window: Specify the window size in bytes instead of blocks.</span>
<span class="sd">                This will be treated as an upper bound for the window size, but each</span>
<span class="sd">                window will still include at least one block. This is mutually</span>
<span class="sd">                exclusive with ``blocks_per_window``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">_rewrite_read_stage</span>
        <span class="kn">from</span> <span class="nn">ray.data.dataset_pipeline</span> <span class="kn">import</span> <span class="n">DatasetPipeline</span>

        <span class="k">if</span> <span class="n">blocks_per_window</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">bytes_per_window</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only one windowing scheme can be specified.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">blocks_per_window</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">blocks_per_window</span> <span class="o">=</span> <span class="mi">10</span>

        <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">is_read_stage_equivalent</span><span class="p">()</span> <span class="ow">and</span> <span class="n">ctx</span><span class="o">.</span><span class="n">optimize_fuse_read_stages</span><span class="p">:</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_get_source_blocks_and_stages</span><span class="p">()</span>
            <span class="n">blocks</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">outer_stats</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="n">_rewrite_read_stage</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">stages</span><span class="p">)</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
            <span class="n">outer_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">class</span> <span class="nc">Iterator</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">splits</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span> <span class="o">=</span> <span class="n">splits</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

            <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">StopIteration</span>

                <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">gen</span><span class="p">():</span>
                    <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                        <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">outer_stats</span><span class="p">,</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                        <span class="n">lazy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">return</span> <span class="n">ds</span>

                <span class="k">return</span> <span class="n">gen</span>

        <span class="k">class</span> <span class="nc">Iterable</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">blocks</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">bytes_per_window</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">split_by_bytes</span><span class="p">(</span><span class="n">bytes_per_window</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">split_size</span><span class="o">=</span><span class="n">blocks_per_window</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">size_bytes</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">]</span>
                    <span class="n">num_blocks</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">]</span>
                    <span class="k">assert</span> <span class="p">[</span><span class="n">s</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">],</span> <span class="n">sizes</span>

                    <span class="k">def</span> <span class="nf">fmt</span><span class="p">(</span><span class="n">size_bytes</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">size_bytes</span> <span class="o">&gt;</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">:</span>
                            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">GiB&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                <span class="nb">round</span><span class="p">(</span><span class="n">size_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
                            <span class="p">)</span>
                        <span class="k">elif</span> <span class="n">size_bytes</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">:</span>
                            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">MiB&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">size_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">b&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">size_bytes</span><span class="p">)</span>

                    <span class="n">mean_bytes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sizes</span><span class="p">))</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Created DatasetPipeline with </span><span class="si">{}</span><span class="s2"> windows: &quot;</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> min, </span><span class="si">{}</span><span class="s2"> max, </span><span class="si">{}</span><span class="s2"> mean&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">),</span>
                            <span class="n">fmt</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">sizes</span><span class="p">)),</span>
                            <span class="n">fmt</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">sizes</span><span class="p">)),</span>
                            <span class="n">fmt</span><span class="p">(</span><span class="n">mean_bytes</span><span class="p">),</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">mean_num_blocks</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">))</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Blocks per window: &quot;</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> min, </span><span class="si">{}</span><span class="s2"> max, </span><span class="si">{}</span><span class="s2"> mean&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="nb">min</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">),</span>
                            <span class="nb">max</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">),</span>
                            <span class="n">mean_num_blocks</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="c1"># TODO(ekl) we should try automatically choosing the default</span>
                    <span class="c1"># windowing settings to meet these best-practice constraints.</span>
                    <span class="n">avail_parallelism</span> <span class="o">=</span> <span class="n">_estimate_available_parallelism</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">mean_num_blocks</span> <span class="o">&lt;</span> <span class="n">avail_parallelism</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s parallelism is limited &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;by its blocks per window to ~</span><span class="si">{</span><span class="n">mean_num_blocks</span><span class="si">}</span><span class="s2"> &quot;</span>
                            <span class="s2">&quot;concurrent tasks per window. To maximize &quot;</span>
                            <span class="s2">&quot;performance, increase the blocks per window to at least &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">avail_parallelism</span><span class="si">}</span><span class="s2">. This may require increasing the &quot;</span>
                            <span class="s2">&quot;base dataset&#39;s parallelism and/or adjusting the &quot;</span>
                            <span class="s2">&quot;windowing parameters.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">OK_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s per-window parallelism &quot;</span>
                            <span class="s2">&quot;is high enough to fully utilize the cluster.&quot;</span>
                        <span class="p">)</span>
                    <span class="n">obj_store_mem</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">cluster_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;object_store_memory&quot;</span><span class="p">,</span> <span class="mi">0</span>
                    <span class="p">)</span>
                    <span class="n">safe_mem_bytes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">obj_store_mem</span> <span class="o">*</span> <span class="n">ESTIMATED_SAFE_MEMORY_FRACTION</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">mean_bytes</span> <span class="o">&gt;</span> <span class="n">safe_mem_bytes</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s windows are &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;~</span><span class="si">{</span><span class="n">fmt</span><span class="p">(</span><span class="n">mean_bytes</span><span class="p">)</span><span class="si">}</span><span class="s2"> in size each and may not fit in &quot;</span>
                            <span class="s2">&quot;object store memory without spilling. To improve &quot;</span>
                            <span class="s2">&quot;performance, consider reducing the size of each window &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;to </span><span class="si">{</span><span class="n">fmt</span><span class="p">(</span><span class="n">safe_mem_bytes</span><span class="p">)</span><span class="si">}</span><span class="s2"> or less.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">OK_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s windows likely fit in &quot;</span>
                            <span class="s2">&quot;object store memory without spilling.&quot;</span>
                        <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Created DatasetPipeline with </span><span class="si">{}</span><span class="s2"> windows; &quot;</span>
                        <span class="s2">&quot;error getting sizes: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">),</span>
                            <span class="n">e</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

            <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">Iterator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">)</span>

        <span class="n">it</span> <span class="o">=</span> <span class="n">Iterable</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">)</span>
        <span class="n">pipe</span> <span class="o">=</span> <span class="n">DatasetPipeline</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">_splits</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">read_stage</span><span class="p">:</span>
            <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">foreach_window</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">ds</span><span class="p">,</span> <span class="n">read_stage</span><span class="o">=</span><span class="n">read_stage</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">(</span>
                    <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">read_stage</span><span class="p">),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="kc">True</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">pipe</span></div>

<div class="viewcode-block" id="Dataset.fully_executed"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.fully_executed.html#ray.data.Dataset.fully_executed">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Use `Dataset.materialize()` instead.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fully_executed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Deprecation warning: use Dataset.materialize() instead of &quot;</span>
            <span class="s2">&quot;fully_executed().&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">force_read</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Dataset.is_fully_executed"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.is_fully_executed.html#ray.data.Dataset.is_fully_executed">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Check `isinstance(Dataset, MaterializedDataset)` instead.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">is_fully_executed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Deprecation warning: Check &quot;</span>
            <span class="s2">&quot;`isinstance(Dataset, MaterializedDataset)` &quot;</span>
            <span class="s2">&quot;instead of using is_fully_executed().&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">has_computed_output</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.materialize"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.materialize.html#ray.data.Dataset.materialize">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;store memory.&quot;</span><span class="p">,</span> <span class="n">insert_after</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">materialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Execute and materialize this dataset into object store memory.</span>

<span class="sd">        This can be used to read all blocks into memory. By default, Dataset</span>
<span class="sd">        doesn&#39;t read blocks from the datasource until the first transform.</span>

<span class="sd">        Note that this does not mutate the original Dataset. Only the blocks of the</span>
<span class="sd">        returned MaterializedDataset class are pinned in memory.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A MaterializedDataset holding the materialized data blocks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">copy</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_deep_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_as</span><span class="o">=</span><span class="n">MaterializedDataset</span><span class="p">)</span>
        <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">force_read</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">blocks</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_snapshot_blocks</span>
        <span class="n">blocks_with_metadata</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">()</span> <span class="k">if</span> <span class="n">blocks</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="c1"># TODO(hchen): Here we generate the same number of blocks as</span>
        <span class="c1"># the original Dataset. Because the old code path does this, and</span>
        <span class="c1"># some unit tests implicily depend on this behavior.</span>
        <span class="c1"># After we remove the old code path, we should consider merging</span>
        <span class="c1"># some blocks for better perf.</span>
        <span class="n">ref_bundles</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">RefBundle</span><span class="p">(</span>
                <span class="n">blocks</span><span class="o">=</span><span class="p">[</span><span class="n">block_with_metadata</span><span class="p">],</span>
                <span class="n">owns_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">block_with_metadata</span> <span class="ow">in</span> <span class="n">blocks_with_metadata</span>
        <span class="p">]</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">blocks</span><span class="p">,</span>
                <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span>
                <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">copy</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="n">copy</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
            <span class="n">logical_plan</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">output</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>  <span class="c1"># No-op that marks the plan as fully executed.</span>
        <span class="n">output</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_in_stats</span><span class="o">.</span><span class="n">dataset_uuid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Dataset.stats"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.stats.html#ray.data.Dataset.stats">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;timing information.&quot;</span><span class="p">,</span> <span class="n">insert_after</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a string containing execution timing information.</span>

<span class="sd">        Note that this does not trigger execution, so if the dataset has not yet</span>
<span class="sd">        executed, an empty string will be returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_stats_summary</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_get_stats_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DatasetStatsSummary</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats_summary</span><span class="p">()</span>

<div class="viewcode-block" id="Dataset.get_internal_block_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.get_internal_block_refs.html#ray.data.Dataset.get_internal_block_refs">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">get_internal_block_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Get a list of references to the underlying blocks of this dataset.</span>

<span class="sd">        This function can be used for zero-copy access to the data. It blocks</span>
<span class="sd">        until the underlying blocks are computed.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of references to this dataset&#39;s blocks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_blocks</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">blocks</span></div>

<div class="viewcode-block" id="Dataset.lazy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.lazy.html#ray.data.Dataset.lazy">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span>
        <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Dataset is lazy by default, so this conversion call is no longer &quot;</span>
        <span class="s2">&quot;needed and this API will be removed in a future release&quot;</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">lazy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Enable lazy evaluation.</span>

<span class="sd">        Dataset is lazy by default, so this is only useful for datasets created</span>
<span class="sd">        from :func:`ray.data.from_items() &lt;ray.data.read_api.from_items&gt;`, which is</span>
<span class="sd">        eager.</span>

<span class="sd">        The returned dataset is a lazy dataset, where all subsequent operations</span>
<span class="sd">        on the stream won&#39;t be executed until the dataset is consumed</span>
<span class="sd">        (e.g. ``.take()``, ``.iter_batches()``, ``.to_torch()``, ``.to_tf()``, etc.)</span>
<span class="sd">        or execution is manually triggered via ``.materialize()``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="n">lazy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">logical_plan</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="p">)</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">ds</span></div>

<div class="viewcode-block" id="Dataset.has_serializable_lineage"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.has_serializable_lineage.html#ray.data.Dataset.has_serializable_lineage">[docs]</a>    <span class="k">def</span> <span class="nf">has_serializable_lineage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Whether this dataset&#39;s lineage is able to be serialized for storage and</span>
<span class="sd">        later deserialized, possibly on a different cluster.</span>

<span class="sd">        Only datasets that are created from data that we know will still exist at</span>
<span class="sd">        deserialization time, e.g. data external to this Ray cluster such as persistent</span>
<span class="sd">        cloud object stores, support lineage-based serialization. All of the</span>
<span class="sd">        ray.data.read_*() APIs support lineage-based serialization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">has_lazy_input</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.serialize_lineage"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.serialize_lineage.html#ray.data.Dataset.serialize_lineage">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">serialize_lineage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Serialize this dataset&#39;s lineage, not the actual data or the existing data</span>
<span class="sd">        futures, to bytes that can be stored and later deserialized, possibly on a</span>
<span class="sd">        different cluster.</span>

<span class="sd">        Note that this will drop all computed data, and that everything will be</span>
<span class="sd">        recomputed from scratch after deserialization.</span>

<span class="sd">        Use :py:meth:`Dataset.deserialize_lineage` to deserialize the serialized</span>
<span class="sd">        bytes returned from this method into a Dataset.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Unioned and zipped datasets, produced by :py:meth`Dataset.union` and</span>
<span class="sd">            :py:meth:`Dataset.zip`, are not lineage-serializable.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Serialized bytes containing the lineage of this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_serializable_lineage</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Lineage-based serialization is not supported for this stream, which &quot;</span>
                <span class="s2">&quot;means that it cannot be used as a tunable hyperparameter. &quot;</span>
                <span class="s2">&quot;Lineage-based serialization is explicitly NOT supported for unioned &quot;</span>
                <span class="s2">&quot;or zipped datasets (see docstrings for those methods), and is only &quot;</span>
                <span class="s2">&quot;supported for datasets created from data that we know will still &quot;</span>
                <span class="s2">&quot;exist at deserialization time, e.g. external data in persistent cloud &quot;</span>
                <span class="s2">&quot;object stores or in-memory data from long-lived clusters. Concretely, &quot;</span>
                <span class="s2">&quot;all ray.data.read_*() APIs should support lineage-based &quot;</span>
                <span class="s2">&quot;serialization, while all of the ray.data.from_*() APIs do not. To &quot;</span>
                <span class="s2">&quot;allow this stream to be serialized to storage, write the data to an &quot;</span>
                <span class="s2">&quot;external store (such as AWS S3, GCS, or Azure Blob Storage) using the &quot;</span>
                <span class="s2">&quot;Dataset.write_*() APIs, and serialize a new dataset reading &quot;</span>
                <span class="s2">&quot;from the external store using the ray.data.read_*() APIs.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Copy Dataset and clear the blocks from the execution plan so only the</span>
        <span class="c1"># Dataset&#39;s lineage is serialized.</span>
        <span class="n">plan_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">preserve_uuid</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan_copy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_epoch</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">)</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">clear_block_refs</span><span class="p">()</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">())</span>

        <span class="k">def</span> <span class="nf">_reduce_remote_fn</span><span class="p">(</span><span class="n">rf</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">):</span>
            <span class="c1"># Custom reducer for Ray remote function handles that allows for</span>
            <span class="c1"># cross-cluster serialization.</span>
            <span class="c1"># This manually unsets the last export session and job to force re-exporting</span>
            <span class="c1"># of the function when the handle is deserialized on a new cluster.</span>
            <span class="c1"># TODO(Clark): Fix this in core Ray, see issue:</span>
            <span class="c1"># https://github.com/ray-project/ray/issues/24152.</span>
            <span class="n">reconstructor</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">__reduce__</span><span class="p">()</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_last_export_session_and_job&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span> <span class="n">reconstructor</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span>

        <span class="n">context</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">global_worker</span><span class="o">.</span><span class="n">get_serialization_context</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">context</span><span class="o">.</span><span class="n">_register_cloudpickle_reducer</span><span class="p">(</span>
                <span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">,</span> <span class="n">_reduce_remote_fn</span>
            <span class="p">)</span>
            <span class="n">serialized</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">context</span><span class="o">.</span><span class="n">_unregister_cloudpickle_reducer</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">serialized</span></div>

<div class="viewcode-block" id="Dataset.deserialize_lineage"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.deserialize_lineage.html#ray.data.Dataset.deserialize_lineage">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">deserialize_lineage</span><span class="p">(</span><span class="n">serialized_ds</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Deserialize the provided lineage-serialized Dataset.</span>

<span class="sd">        This assumes that the provided serialized bytes were serialized using</span>
<span class="sd">        :py:meth:`Dataset.serialize_lineage`.</span>

<span class="sd">        Args:</span>
<span class="sd">            serialized_ds: The serialized Dataset that we wish to deserialize.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A deserialized ``Dataset`` instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">serialized_ds</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">context</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataContext</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the DataContext used to create this Dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_context</span>

    <span class="k">def</span> <span class="nf">_divide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">):</span>
        <span class="n">block_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">left</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">block_list</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">block_idx</span><span class="p">)</span>
        <span class="n">l_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">left</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
            <span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">r_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">right</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
            <span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">l_ds</span><span class="p">,</span> <span class="n">r_ds</span>

<div class="viewcode-block" id="Dataset.default_batch_format"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.default_batch_format.html#ray.data.Dataset.default_batch_format">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;The batch format is no longer exposed as a public API.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">default_batch_format</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">:</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">StrictModeError</span><span class="p">(</span><span class="s2">&quot;default_batch_format() is not allowed in Ray 2.5&quot;</span><span class="p">)</span>

        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">list</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="p">(</span><span class="n">PandasBlockSchema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">schema</span><span class="o">.</span><span class="n">names</span> <span class="o">==</span> <span class="p">[</span><span class="n">TENSOR_COLUMN_NAME</span><span class="p">]:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
            <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></div>

<div class="viewcode-block" id="Dataset.dataset_format"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.dataset_format.html#ray.data.Dataset.dataset_format">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;The dataset format is no longer exposed as a public API.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">dataset_format</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BlockFormat</span><span class="p">:</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">StrictModeError</span><span class="p">(</span><span class="s2">&quot;dataset_format() is not allowed in Ray 2.5&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">use_streaming_executor</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">DeprecationWarning</span><span class="p">(</span>
                <span class="s2">&quot;`dataset_format` is deprecated for streaming execution. To use &quot;</span>
                <span class="s2">&quot;`dataset_format`, you must explicitly enable bulk execution by &quot;</span>
                <span class="s2">&quot;setting `use_streaming_executor` to False in the `DataContext`&quot;</span>
            <span class="p">)</span>

        <span class="c1"># We need schema to properly validate, so synchronously</span>
        <span class="c1"># fetch it if necessary.</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Dataset is empty or cleared, can&#39;t determine the format of &quot;</span>
                <span class="s2">&quot;the dataset.&quot;</span>
            <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">BlockFormat</span><span class="o">.</span><span class="n">ARROW</span>
        <span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">BlockFormat</span><span class="o">.</span><span class="n">PANDAS</span>
        <span class="k">return</span> <span class="n">BlockFormat</span><span class="o">.</span><span class="n">SIMPLE</span></div>

    <span class="k">def</span> <span class="nf">_aggregate_on</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">agg_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper for aggregating on a particular subset of the dataset.</span>

<span class="sd">        This validates the `on` argument, and converts a list of column names</span>
<span class="sd">        or lambdas to a multi-aggregation. A null `on` results in a</span>
<span class="sd">        multi-aggregation on all columns for an Arrow Dataset, and a single</span>
<span class="sd">        aggregation on the entire row for a simple Dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">aggs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_multicolumn_aggs</span><span class="p">(</span><span class="n">agg_cls</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="o">*</span><span class="n">aggs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_multicolumn_aggs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">agg_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span>
        <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span>
        <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">skip_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Build set of aggregations for applying a single aggregation to</span>
<span class="sd">        multiple columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Expand None into an aggregation for each column.</span>
        <span class="k">if</span> <span class="n">on</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_cols</span><span class="p">:</span>
                    <span class="n">skip_cols</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">on</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">names</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">skip_cols</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">on</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">on</span> <span class="o">=</span> <span class="p">[</span><span class="n">on</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">agg_cls</span><span class="p">(</span><span class="n">on_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="o">=</span><span class="n">ignore_nulls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">on_</span> <span class="ow">in</span> <span class="n">on</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_aggregate_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">U</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># NOTE (kfstorm): We cannot call `result[0]` directly on</span>
                <span class="c1"># `PandasRow` because indexing a column with position is not</span>
                <span class="c1"># supported by pandas.</span>
                <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@repr_with_fallback</span><span class="p">([</span><span class="s2">&quot;ipywidgets&quot;</span><span class="p">,</span> <span class="s2">&quot;8&quot;</span><span class="p">])</span>
    <span class="k">def</span> <span class="nf">_repr_mimebundle_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a mimebundle with an ipywidget repr and a simple text repr.</span>

<span class="sd">        Depending on the frontend where the data is being displayed,</span>
<span class="sd">        different mimetypes will be used from this bundle.</span>
<span class="sd">        See https://ipython.readthedocs.io/en/stable/config/integrating.html</span>
<span class="sd">        for information about this method, and</span>
<span class="sd">        https://ipywidgets.readthedocs.io/en/latest/embedding.html</span>
<span class="sd">        for more information about the jupyter widget mimetype.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A mimebundle containing an ipywidget repr and a simple text repr.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">ipywidgets</span>

        <span class="n">title</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;h2&gt;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&lt;/h2&gt;&quot;</span><span class="p">)</span>
        <span class="n">tab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tab_repr_</span><span class="p">()</span>
        <span class="n">widget</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span><span class="n">title</span><span class="p">,</span> <span class="n">tab</span><span class="p">],</span> <span class="n">layout</span><span class="o">=</span><span class="n">ipywidgets</span><span class="o">.</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s2">&quot;100%&quot;</span><span class="p">))</span>

        <span class="c1"># Get the widget mime bundle, but replace the plaintext</span>
        <span class="c1"># with the Datastream repr</span>
        <span class="n">bundle</span> <span class="o">=</span> <span class="n">widget</span><span class="o">.</span><span class="n">_repr_mimebundle_</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">bundle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;text/plain&quot;</span><span class="p">:</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">bundle</span>

    <span class="k">def</span> <span class="nf">_tab_repr_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">Tab</span>

        <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;num_blocks&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">(),</span>
            <span class="s2">&quot;num_rows&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_meta_count</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="c1"># Show metadata if available, but don&#39;t trigger execution.</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;rendered_html_common.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="s2">&quot;&lt;h5&gt;Unknown schema&lt;/h5&gt;&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;rendered_html_common.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;&lt;h5&gt;Data type: &lt;code&gt;</span><span class="si">{</span><span class="n">html</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">schema</span><span class="p">))</span><span class="si">}</span><span class="s2">&lt;/code&gt;&lt;/h5&gt;&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">schema_data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">sname</span><span class="p">,</span> <span class="n">stype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
                <span class="n">schema_data</span><span class="p">[</span><span class="n">sname</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">stype</span><span class="p">,</span> <span class="s2">&quot;__name__&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">stype</span><span class="p">))</span>

            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;scrollableTable.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">table</span><span class="o">=</span><span class="n">tabulate</span><span class="p">(</span>
                    <span class="n">tabular_data</span><span class="o">=</span><span class="n">schema_data</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                    <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">,</span>
                    <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Name&quot;</span><span class="p">,</span> <span class="s2">&quot;Type&quot;</span><span class="p">],</span>
                <span class="p">),</span>
                <span class="n">max_height</span><span class="o">=</span><span class="s2">&quot;300px&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">children</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">HTML</span><span class="p">(</span>
                <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;scrollableTable.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                    <span class="n">table</span><span class="o">=</span><span class="n">tabulate</span><span class="p">(</span>
                        <span class="n">tabular_data</span><span class="o">=</span><span class="n">metadata</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                        <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">,</span>
                        <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Field&quot;</span><span class="p">,</span> <span class="s2">&quot;Value&quot;</span><span class="p">],</span>
                    <span class="p">),</span>
                    <span class="n">max_height</span><span class="o">=</span><span class="s2">&quot;300px&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">schema_repr</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Tab</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">titles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Metadata&quot;</span><span class="p">,</span> <span class="s2">&quot;Schema&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">get_plan_as_string</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__bool__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="c1"># Prevents `__len__` from being called to check if it is None</span>
        <span class="c1"># see: issue #25152</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="s2">&quot;Use `ds.count()` to compute the length of a distributed Dataset. &quot;</span>
            <span class="s2">&quot;This may be an expensive operation.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;`Dataset` objects aren&#39;t iterable. To iterate records, call &quot;</span>
            <span class="s2">&quot;`ds.iter_rows()` or `ds.iter_batches()`. For more information, read &quot;</span>
            <span class="s2">&quot;https://docs.ray.io/en/latest/data/consuming-datasets.html.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_block_num_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">get_num_rows</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_num_rows</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="n">get_num_rows</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()])</span>

    <span class="k">def</span> <span class="nf">_block_size_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">get_size_bytes</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_size_bytes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="p">[</span><span class="n">get_size_bytes</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_meta_count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">meta_count</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_uuid</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span>

    <span class="k">def</span> <span class="nf">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uuid</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">uuid</span>

    <span class="k">def</span> <span class="nf">_get_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span>

    <span class="k">def</span> <span class="nf">_set_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

    <span class="k">def</span> <span class="nf">_warn_slow</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">log_once</span><span class="p">(</span><span class="s2">&quot;dataset_slow_warned&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;The `map`, `flat_map`, and `filter` operations are unvectorized and &quot;</span>
                <span class="s2">&quot;can be very slow. If you&#39;re using a vectorized transformation, &quot;</span>
                <span class="s2">&quot;consider using `.map_batches()` instead.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_synchronize_progress_bar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Flush progress bar output by shutting down the current executor.</span>

<span class="sd">        This should be called at the end of all blocking APIs (e.g., `take`), but not</span>
<span class="sd">        async APIs (e.g., `iter_batches`).</span>

<span class="sd">        The streaming executor runs in a separate generator / thread, so it is</span>
<span class="sd">        possible the shutdown logic runs even after a call to retrieve rows from the</span>
<span class="sd">        stream has finished. Explicit shutdown avoids this, which can clobber console</span>
<span class="sd">        output (https://github.com/ray-project/ray/issues/32414).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Note: excludes _current_executor which is not serializable.</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;plan&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="p">,</span>
            <span class="s2">&quot;uuid&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="s2">&quot;lazy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
            <span class="s2">&quot;logical_plan&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;plan&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;uuid&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;lazy&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;logical_plan&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="ow">and</span> <span class="n">ray</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ray</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span></div>


<span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">MaterializedDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Generic</span><span class="p">[</span><span class="n">T</span><span class="p">]):</span>
    <span class="sd">&quot;&quot;&quot;A Dataset materialized in Ray memory, e.g., via `.materialize()`.</span>

<span class="sd">    The blocks of a MaterializedDataset object are materialized into Ray object store</span>
<span class="sd">    memory, which means that this class can be shared or iterated over by multiple Ray</span>
<span class="sd">    tasks without re-executing the underlying computations for producing the stream.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">pass</span>


<span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;beta&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Schema</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Dataset schema.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        names: List of column names of this Dataset.</span>
<span class="sd">        types: List of Arrow types of the Dataset. Note that the &quot;object&quot; type is</span>
<span class="sd">            not Arrow compatible and hence will be returned as `object`.</span>
<span class="sd">        base_schema: The underlying Arrow or Pandas schema.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_schema</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.lib.Schema&quot;</span><span class="p">,</span> <span class="s2">&quot;PandasBlockSchema&quot;</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span> <span class="o">=</span> <span class="n">base_schema</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Lists the columns of this Dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">names</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">types</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="nb">object</span><span class="p">],</span> <span class="s2">&quot;pyarrow.DataType&quot;</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Lists the types of this Dataset in Arrow format</span>

<span class="sd">        For non-Arrow compatible types, we return &quot;object&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorType</span><span class="p">,</span> <span class="n">TensorDtype</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>

        <span class="n">arrow_types</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">types</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">TensorDtype</span><span class="p">):</span>
                <span class="c1"># Manually convert our Pandas tensor extension type to Arrow.</span>
                <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">ArrowTensorType</span><span class="p">(</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">from_numpy_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">from_numpy_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">))</span>
                <span class="k">except</span> <span class="n">pa</span><span class="o">.</span><span class="n">ArrowNotImplementedError</span><span class="p">:</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error converting dtype </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> to Arrow.&quot;</span><span class="p">)</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">arrow_types</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Schema</span><span class="p">)</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">base_schema</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">column_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">)])</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="mi">2</span>

        <span class="n">output</span> <span class="o">=</span> <span class="s2">&quot;Column&quot;</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;Type</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Type&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="nb">type</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="n">name</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">def</span> <span class="nf">_get_size_bytes</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">size_bytes</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_block_to_ndarray</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_block_to_arrow</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_arrow</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_sliding_window</span><span class="p">(</span><span class="n">iterable</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates an iterator consisting of n-width sliding windows over</span>
<span class="sd">    iterable. The sliding windows are constructed lazily such that an</span>
<span class="sd">    element on the base iterator (iterable) isn&#39;t consumed until the</span>
<span class="sd">    first sliding window containing that element is reached.</span>

<span class="sd">    If n &gt; len(iterable), then a single len(iterable) window is</span>
<span class="sd">    returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        iterable: The iterable on which the sliding window will be</span>
<span class="sd">            created.</span>
<span class="sd">        n: The width of the sliding window.</span>

<span class="sd">    Returns:</span>
<span class="sd">        An iterator of n-width windows over iterable.</span>
<span class="sd">        If n &gt; len(iterable), then a single len(iterable) window is</span>
<span class="sd">        returned.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>
    <span class="n">window</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">islice</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">window</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">yield</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">window</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">it</span><span class="p">:</span>
        <span class="n">window</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span>
        <span class="k">yield</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">window</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_do_write</span><span class="p">(</span>
    <span class="n">ds</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="n">DataContext</span><span class="p">,</span>
    <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Block</span><span class="p">],</span>
    <span class="n">meta</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">BlockMetadata</span><span class="p">],</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">write_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">WriteResult</span><span class="p">]]:</span>
    <span class="n">write_args</span> <span class="o">=</span> <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">write_args</span><span class="p">)</span>
    <span class="n">DataContext</span><span class="o">.</span><span class="n">_set_current</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">do_write</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">meta</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span> <span class="o">**</span><span class="n">write_args</span><span class="p">)</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>