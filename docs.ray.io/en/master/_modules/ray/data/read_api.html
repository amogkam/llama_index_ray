
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.data.read_api &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/versionwarning.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../_static/js/docsearch.js"></script>
    <script src="../../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../_static/js/top-navigation.js"></script>
    <script src="../../../_static/js/tags.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/data/read_api.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "_modules/ray/data/read_api", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/data/read_api.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.data.read_api</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray._private.auto_init_hook</span> <span class="kn">import</span> <span class="n">wrap_auto_init</span>
<span class="kn">from</span> <span class="nn">ray.air.util.tensor_extensions.utils</span> <span class="kn">import</span> <span class="n">_create_possibly_ragged_ndarray</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.arrow_block</span> <span class="kn">import</span> <span class="n">ArrowBlockBuilder</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.block_list</span> <span class="kn">import</span> <span class="n">BlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.delegating_block_builder</span> <span class="kn">import</span> <span class="n">DelegatingBlockBuilder</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.lazy_block_list</span> <span class="kn">import</span> <span class="n">LazyBlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.from_operators</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">FromArrow</span><span class="p">,</span>
    <span class="n">FromItems</span><span class="p">,</span>
    <span class="n">FromNumpy</span><span class="p">,</span>
    <span class="n">FromPandas</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.read_operator</span> <span class="kn">import</span> <span class="n">Read</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.optimizers</span> <span class="kn">import</span> <span class="n">LogicalPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">ExecutionPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.remote_fn</span> <span class="kn">import</span> <span class="n">cached_remote_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.stats</span> <span class="kn">import</span> <span class="n">DatasetStats</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.util</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_autodetect_parallelism</span><span class="p">,</span>
    <span class="n">_is_local_scheme</span><span class="p">,</span>
    <span class="n">_lazy_import_pyarrow_dataset</span><span class="p">,</span>
    <span class="n">get_table_block_metadata</span><span class="p">,</span>
    <span class="n">ndarray_to_block</span><span class="p">,</span>
    <span class="n">pandas_df_to_arrow_block</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.block</span> <span class="kn">import</span> <span class="n">Block</span><span class="p">,</span> <span class="n">BlockAccessor</span><span class="p">,</span> <span class="n">BlockExecStats</span><span class="p">,</span> <span class="n">BlockMetadata</span>
<span class="kn">from</span> <span class="nn">ray.data.context</span> <span class="kn">import</span> <span class="n">WARN_PREFIX</span><span class="p">,</span> <span class="n">DataContext</span>
<span class="kn">from</span> <span class="nn">ray.data.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">MaterializedDataset</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BaseFileMetadataProvider</span><span class="p">,</span>
    <span class="n">BinaryDatasource</span><span class="p">,</span>
    <span class="n">Connection</span><span class="p">,</span>
    <span class="n">CSVDatasource</span><span class="p">,</span>
    <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">DefaultFileMetadataProvider</span><span class="p">,</span>
    <span class="n">DefaultParquetMetadataProvider</span><span class="p">,</span>
    <span class="n">FastFileMetadataProvider</span><span class="p">,</span>
    <span class="n">ImageDatasource</span><span class="p">,</span>
    <span class="n">JSONDatasource</span><span class="p">,</span>
    <span class="n">MongoDatasource</span><span class="p">,</span>
    <span class="n">NumpyDatasource</span><span class="p">,</span>
    <span class="n">ParquetBaseDatasource</span><span class="p">,</span>
    <span class="n">ParquetDatasource</span><span class="p">,</span>
    <span class="n">ParquetMetadataProvider</span><span class="p">,</span>
    <span class="n">PathPartitionFilter</span><span class="p">,</span>
    <span class="n">RangeDatasource</span><span class="p">,</span>
    <span class="n">ReadTask</span><span class="p">,</span>
    <span class="n">SQLDatasource</span><span class="p">,</span>
    <span class="n">TextDatasource</span><span class="p">,</span>
    <span class="n">TFRecordDatasource</span><span class="p">,</span>
    <span class="n">WebDatasetDatasource</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.file_based_datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">,</span>
    <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.image_datasource</span> <span class="kn">import</span> <span class="n">_ImageFileMetadataProvider</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.partitioning</span> <span class="kn">import</span> <span class="n">Partitioning</span>
<span class="kn">from</span> <span class="nn">ray.types</span> <span class="kn">import</span> <span class="n">ObjectRef</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">Deprecated</span><span class="p">,</span> <span class="n">DeveloperAPI</span><span class="p">,</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.util.placement_group</span> <span class="kn">import</span> <span class="n">PlacementGroup</span>
<span class="kn">from</span> <span class="nn">ray.util.scheduling_strategies</span> <span class="kn">import</span> <span class="n">NodeAffinitySchedulingStrategy</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dask</span>
    <span class="kn">import</span> <span class="nn">datasets</span>
    <span class="kn">import</span> <span class="nn">mars</span>
    <span class="kn">import</span> <span class="nn">modin</span>
    <span class="kn">import</span> <span class="nn">pandas</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span>
    <span class="kn">import</span> <span class="nn">pymongoarrow.api</span>
    <span class="kn">import</span> <span class="nn">pyspark</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">from</span> <span class="nn">tensorflow_metadata.proto.v0</span> <span class="kn">import</span> <span class="n">schema_pb2</span>


<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="from_items"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_items.html#ray.data.from_items">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_items</span><span class="p">(</span>
    <span class="n">items</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">output_arrow_format</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a list of local Python objects.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.from_items([1, 2, 3, 4, 5]) # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds # doctest: +SKIP</span>
<span class="sd">        MaterializedDataset(num_blocks=5, num_rows=5, schema={item: int64})</span>
<span class="sd">        &gt;&gt;&gt; ds.take_batch(2) # doctest: +SKIP</span>
<span class="sd">        {&quot;item&quot;: array([1, 2])}</span>

<span class="sd">    Args:</span>
<span class="sd">        items: List of local Python objects.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset.</span>
<span class="sd">            Parallelism may be limited by the number of items.</span>
<span class="sd">        output_arrow_format: If True, always return data in Arrow format, raising an</span>
<span class="sd">            error if this is not possible. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding the items.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
        <span class="n">output_arrow_format</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="kn">import</span> <span class="nn">builtins</span>

    <span class="k">if</span> <span class="n">parallelism</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;parallelism must be -1 or &gt; 0, got: </span><span class="si">{</span><span class="n">parallelism</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">detected_parallelism</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_autodetect_parallelism</span><span class="p">(</span>
        <span class="n">parallelism</span><span class="p">,</span>
        <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">get_current_placement_group</span><span class="p">(),</span>
        <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="c1"># Truncate parallelism to number of items to avoid empty blocks.</span>
    <span class="n">detected_parallelism</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">detected_parallelism</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">detected_parallelism</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">block_size</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">detected_parallelism</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">block_size</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="c1"># NOTE: We need to explicitly use the builtins range since we override range below,</span>
    <span class="c1"># with the definition of ray.data.range.</span>
    <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">BlockMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">builtins</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">detected_parallelism</span><span class="p">):</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">BlockExecStats</span><span class="o">.</span><span class="n">builder</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
            <span class="c1"># In strict mode, we will fallback from Arrow -&gt; Pandas automatically in</span>
            <span class="c1"># the delegating block builder, and never use simple blocks.</span>
            <span class="n">builder</span> <span class="o">=</span> <span class="n">DelegatingBlockBuilder</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">output_arrow_format</span><span class="p">:</span>
            <span class="n">builder</span> <span class="o">=</span> <span class="n">ArrowBlockBuilder</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">builder</span> <span class="o">=</span> <span class="n">DelegatingBlockBuilder</span><span class="p">()</span>
        <span class="c1"># Evenly distribute remainder across block slices while preserving record order.</span>
        <span class="n">block_start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
        <span class="n">block_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">builtins</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">block_start</span><span class="p">,</span> <span class="n">block_end</span><span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Mapping</span><span class="p">):</span>
                    <span class="n">item</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;item&quot;</span><span class="p">:</span> <span class="n">item</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">output_arrow_format</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Mapping</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;Arrow block format can only be used if all items are &quot;</span>
                        <span class="s2">&quot;either dicts or Numpy arrays. Received data of type: &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">items</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="si">}</span><span class="s2">. Set `output_arrow_format` to &quot;</span>
                        <span class="s2">&quot;False to not use Arrow blocks.&quot;</span>
                    <span class="p">)</span>
            <span class="n">builder</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">block</span><span class="p">))</span>
        <span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">(</span>
                <span class="n">input_files</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exec_stats</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">from_items_op</span> <span class="o">=</span> <span class="n">FromItems</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">from_items_op</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromItems&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="range"><a class="viewcode-back" href="../../../data/api/doc/ray.data.range.html#ray.data.range">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a range of integers [0..n).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range(10000) # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds # doctest: +SKIP</span>
<span class="sd">        Dataset(num_blocks=200, num_rows=10000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; ds.map(lambda x: {&quot;id&quot;: x[&quot;id&quot;] * 2}).take(4) # doctest: +SKIP</span>
<span class="sd">        [{&quot;id&quot;: 0}, {&quot;id&quot;: 2}, {&quot;id&quot;: 4}, {&quot;id&quot;: 6}]</span>

<span class="sd">    Args:</span>
<span class="sd">        n: The upper bound of the range of integers.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset.</span>
<span class="sd">            Parallelism may be limited by the number of items.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing the integers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
            <span class="n">RangeDatasource</span><span class="p">(),</span>
            <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
            <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
            <span class="n">block_format</span><span class="o">=</span><span class="s2">&quot;arrow&quot;</span><span class="p">,</span>
            <span class="n">column_name</span><span class="o">=</span><span class="s2">&quot;id&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">RangeDatasource</span><span class="p">(),</span> <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">block_format</span><span class="o">=</span><span class="s2">&quot;list&quot;</span>
    <span class="p">)</span></div>


<span class="nd">@Deprecated</span>
<span class="k">def</span> <span class="nf">range_table</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">DeprecationWarning</span><span class="p">(</span><span class="s2">&quot;In Ray 2.5, use range() instead of range_table().&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">RangeDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
        <span class="n">block_format</span><span class="o">=</span><span class="s2">&quot;arrow&quot;</span><span class="p">,</span>
        <span class="n">column_name</span><span class="o">=</span><span class="s2">&quot;value&quot;</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="range_tensor"><a class="viewcode-back" href="../../../data/api/doc/ray.data.range_tensor.html#ray.data.range_tensor">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">range_tensor</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a Tensor stream from a range of integers [0..n).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range_tensor(1000, shape=(2, 2))</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +ELLIPSIS</span>
<span class="sd">        Dataset(</span>
<span class="sd">           num_blocks=...,</span>
<span class="sd">           num_rows=1000,</span>
<span class="sd">           schema={data: numpy.ndarray(shape=(2, 2), dtype=int64)}</span>
<span class="sd">        )</span>
<span class="sd">        &gt;&gt;&gt; ds.map_batches(lambda arr: arr * 2).take(2) # doctest: +SKIP</span>
<span class="sd">        [array([[0, 0],</span>
<span class="sd">                [0, 0]]),</span>
<span class="sd">         array([[2, 2],</span>
<span class="sd">                [2, 2]])]</span>

<span class="sd">    This is similar to range_table(), but uses the ArrowTensorArray extension</span>
<span class="sd">    type. The dataset elements take the form {&quot;data&quot;: array(N, shape=shape)}.</span>

<span class="sd">    Args:</span>
<span class="sd">        n: The upper bound of the range of integer records.</span>
<span class="sd">        shape: The shape of each record.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset.</span>
<span class="sd">            Parallelism may be limited by the number of items.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing the integers as Arrow tensor records.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">RangeDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
        <span class="n">block_format</span><span class="o">=</span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span>
        <span class="n">column_name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span> <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span> <span class="k">else</span> <span class="s2">&quot;__value__&quot;</span><span class="p">,</span>
        <span class="n">tensor_shape</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_datasource"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_datasource.html#ray.data.read_datasource">[docs]</a><span class="nd">@PublicAPI</span>
<span class="nd">@wrap_auto_init</span>
<span class="k">def</span> <span class="nf">read_datasource</span><span class="p">(</span>
    <span class="n">datasource</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">read_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Read a stream from a custom data source.</span>

<span class="sd">    Args:</span>
<span class="sd">        datasource: The datasource to read data from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the available partitioning of the datasource. If set to -1,</span>
<span class="sd">            parallelism will be automatically chosen based on the available cluster</span>
<span class="sd">            resources and estimated in-memory data size.</span>
<span class="sd">        read_args: Additional kwargs to pass to the datasource impl.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset that reads data from the datasource.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">ray_remote_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ray_remote_args</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">local_uri</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="n">read_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;paths&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">paths</span> <span class="ow">and</span> <span class="n">_is_local_scheme</span><span class="p">(</span><span class="n">paths</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">ray</span><span class="o">.</span><span class="n">is_connected</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The local scheme paths </span><span class="si">{</span><span class="n">paths</span><span class="si">}</span><span class="s2"> are not supported in Ray Client.&quot;</span>
            <span class="p">)</span>
        <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span>
            <span class="n">soft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">local_uri</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="s2">&quot;scheduling_strategy&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ray_remote_args</span><span class="p">:</span>
        <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">scheduling_strategy</span>

    <span class="n">force_local</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">cur_pg</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">get_current_placement_group</span><span class="p">()</span>
    <span class="n">pa_ds</span> <span class="o">=</span> <span class="n">_lazy_import_pyarrow_dataset</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">pa_ds</span><span class="p">:</span>
        <span class="n">partitioning</span> <span class="o">=</span> <span class="n">read_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataset_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;partitioning&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">partitioning</span><span class="p">,</span> <span class="n">pa_ds</span><span class="o">.</span><span class="n">Partitioning</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Forcing local metadata resolution since the provided partitioning &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">partitioning</span><span class="si">}</span><span class="s2"> is not serializable.&quot;</span>
            <span class="p">)</span>
            <span class="n">force_local</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="n">force_local</span><span class="p">:</span>
        <span class="n">requested_parallelism</span><span class="p">,</span> <span class="n">min_safe_parallelism</span><span class="p">,</span> <span class="n">read_tasks</span> <span class="o">=</span> <span class="n">_get_read_tasks</span><span class="p">(</span>
            <span class="n">datasource</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">cur_pg</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">,</span> <span class="n">local_uri</span><span class="p">,</span> <span class="n">read_args</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Prepare read in a remote task at same node.</span>
        <span class="c1"># NOTE: in Ray client mode, this is expected to be run on head node.</span>
        <span class="c1"># So we aren&#39;t attempting metadata resolution from the client machine.</span>
        <span class="n">scheduling_strategy</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span>
            <span class="n">soft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">get_read_tasks</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span>
            <span class="n">_get_read_tasks</span><span class="p">,</span> <span class="n">retry_exceptions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_cpus</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">scheduling_strategy</span><span class="o">=</span><span class="n">scheduling_strategy</span><span class="p">)</span>

        <span class="n">requested_parallelism</span><span class="p">,</span> <span class="n">min_safe_parallelism</span><span class="p">,</span> <span class="n">read_tasks</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="n">get_read_tasks</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span>
                <span class="n">datasource</span><span class="p">,</span>
                <span class="n">ctx</span><span class="p">,</span>
                <span class="n">cur_pg</span><span class="p">,</span>
                <span class="n">parallelism</span><span class="p">,</span>
                <span class="n">local_uri</span><span class="p">,</span>
                <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">read_args</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">read_tasks</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_safe_parallelism</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">:</span>
        <span class="n">perc</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">round</span><span class="p">((</span><span class="n">min_safe_parallelism</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> The blocks of this dataset are estimated to be </span><span class="si">{</span><span class="n">perc</span><span class="si">}</span><span class="s2">x &quot;</span>
            <span class="s2">&quot;larger than the target block size &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;of </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">target_max_block_size</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span><span class="p">)</span><span class="si">}</span><span class="s2"> MiB. This may lead to &quot;</span>
            <span class="s2">&quot;out-of-memory errors during processing. Consider reducing the size of &quot;</span>
            <span class="s2">&quot;input files or using `.repartition(n)` to increase the number of &quot;</span>
            <span class="s2">&quot;dataset blocks.&quot;</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">requested_parallelism</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">ray</span><span class="o">.</span><span class="n">available_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> The number of blocks in this dataset &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;limits its parallelism to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span><span class="si">}</span><span class="s2"> concurrent tasks. &quot;</span>
            <span class="s2">&quot;This is much less than the number &quot;</span>
            <span class="s2">&quot;of available CPU slots in the cluster. Use `.repartition(n)` to &quot;</span>
            <span class="s2">&quot;increase the number of &quot;</span>
            <span class="s2">&quot;dataset blocks.&quot;</span>
        <span class="p">)</span>

    <span class="n">read_stage_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Read</span><span class="si">{</span><span class="n">datasource</span><span class="o">.</span><span class="n">get_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">available_cpu_slots</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">available_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">requested_parallelism</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">available_cpu_slots</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">5000</span>
    <span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> The requested parallelism of </span><span class="si">{</span><span class="n">requested_parallelism</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="s2">&quot;is more than 4x the number of available CPU slots in the cluster of &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">available_cpu_slots</span><span class="si">}</span><span class="s2">. This can &quot;</span>
            <span class="s2">&quot;lead to slowdowns during the data reading phase due to excessive &quot;</span>
            <span class="s2">&quot;task creation. Reduce the parallelism to match with the available &quot;</span>
            <span class="s2">&quot;CPU slots in the cluster, or set parallelism to -1 for Ray Data &quot;</span>
            <span class="s2">&quot;to automatically determine the parallelism. &quot;</span>
            <span class="s2">&quot;You can ignore this message if the cluster is expected to autoscale.&quot;</span>
        <span class="p">)</span>

    <span class="n">block_list</span> <span class="o">=</span> <span class="n">LazyBlockList</span><span class="p">(</span>
        <span class="n">read_tasks</span><span class="p">,</span>
        <span class="n">read_stage_name</span><span class="o">=</span><span class="n">read_stage_name</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># TODO(hchen): move _get_read_tasks and related code to the Read physical operator,</span>
    <span class="c1"># after removing LazyBlockList code path.</span>
    <span class="n">read_op</span> <span class="o">=</span> <span class="n">Read</span><span class="p">(</span><span class="n">datasource</span><span class="p">,</span> <span class="n">read_tasks</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="p">)</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">read_op</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
        <span class="n">plan</span><span class="o">=</span><span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">block_list</span><span class="p">,</span> <span class="n">block_list</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">lazy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="o">=</span><span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_mongo"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_mongo.html#ray.data.read_mongo">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_mongo</span><span class="p">(</span>
    <span class="n">uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">database</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">collection</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pymongoarrow.api.Schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">mongo_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create an Arrow dataset from MongoDB.</span>

<span class="sd">    The data to read from is specified via the ``uri``, ``database`` and ``collection``</span>
<span class="sd">    of the MongoDB. The dataset is created from the results of executing</span>
<span class="sd">    ``pipeline`` against the ``collection``. If ``pipeline`` is None, the entire</span>
<span class="sd">    ``collection`` will be read.</span>

<span class="sd">    You can check out more details here about these MongoDB concepts:</span>
<span class="sd">    - URI: https://www.mongodb.com/docs/manual/reference/connection-string/</span>
<span class="sd">    - Database and Collection: https://www.mongodb.com/docs/manual/core/databases-and-collections/</span>
<span class="sd">    - Pipeline: https://www.mongodb.com/docs/manual/core/aggregation-pipeline/</span>

<span class="sd">    To read the MongoDB in parallel, the execution of the pipeline is run on partitions</span>
<span class="sd">    of the collection, with a Ray read task to handle a partition. Partitions are</span>
<span class="sd">    created in an attempt to evenly distribute the documents into the specified number</span>
<span class="sd">    of partitions. The number of partitions is determined by ``parallelism`` which can</span>
<span class="sd">    be requested from this interface or automatically chosen if unspecified (see the</span>
<span class="sd">    ``parallelism`` arg below).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from pymongoarrow.api import Schema # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_mongo( # doctest: +SKIP</span>
<span class="sd">        ...     uri=&quot;mongodb://username:password@mongodb0.example.com:27017/?authSource=admin&quot;, # noqa: E501</span>
<span class="sd">        ...     database=&quot;my_db&quot;,</span>
<span class="sd">        ...     collection=&quot;my_collection&quot;,</span>
<span class="sd">        ...     pipeline=[{&quot;$match&quot;: {&quot;col2&quot;: {&quot;$gte&quot;: 0, &quot;$lt&quot;: 100}}}, {&quot;$sort&quot;: &quot;sort_field&quot;}], # noqa: E501</span>
<span class="sd">        ...     schema=Schema({&quot;col1&quot;: pa.string(), &quot;col2&quot;: pa.int64()}),</span>
<span class="sd">        ...     parallelism=10,</span>
<span class="sd">        ... )</span>

<span class="sd">    Args:</span>
<span class="sd">        uri: The URI of the source MongoDB where the dataset will be</span>
<span class="sd">            read from. For the URI format, see details in</span>
<span class="sd">            https://www.mongodb.com/docs/manual/reference/connection-string/.</span>
<span class="sd">        database: The name of the database hosted in the MongoDB. This database</span>
<span class="sd">            must exist otherwise ValueError will be raised.</span>
<span class="sd">        collection: The name of the collection in the database. This collection</span>
<span class="sd">            must exist otherwise ValueError will be raised.</span>
<span class="sd">        pipeline: A MongoDB pipeline, which will be executed on the given collection</span>
<span class="sd">            with results used to create Dataset. If None, the entire collection will</span>
<span class="sd">            be read.</span>
<span class="sd">        schema: The schema used to read the collection. If None, it&#39;ll be inferred from</span>
<span class="sd">            the results of pipeline.</span>
<span class="sd">        parallelism: The requested parallelism of the read. If -1, it will be</span>
<span class="sd">            automatically chosen based on the available cluster resources and estimated</span>
<span class="sd">            in-memory data size.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>
<span class="sd">        mongo_args: kwargs passed to aggregate_arrow_all() in pymongoarrow in producing</span>
<span class="sd">            Arrow-formatted results.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing Arrow records from the results of executing the pipeline</span>
<span class="sd">        on the specified MongoDB collection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">MongoDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">uri</span><span class="o">=</span><span class="n">uri</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">database</span><span class="p">,</span>
        <span class="n">collection</span><span class="o">=</span><span class="n">collection</span><span class="p">,</span>
        <span class="n">pipeline</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">mongo_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_parquet"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_parquet.html#ray.data.read_parquet">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_parquet</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tensor_column_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">ParquetMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultParquetMetadataProvider</span><span class="p">(),</span>
    <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create an Arrow dataset from parquet files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; # Read a directory of files in remote storage.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_parquet(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple local files.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_parquet([&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;]) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Specify a schema for the parquet file.</span>
<span class="sd">        &gt;&gt;&gt; import pyarrow as pa</span>
<span class="sd">        &gt;&gt;&gt; fields = [(&quot;sepal.length&quot;, pa.float64()),</span>
<span class="sd">        ...           (&quot;sepal.width&quot;, pa.float64()),</span>
<span class="sd">        ...           (&quot;petal.length&quot;, pa.float64()),</span>
<span class="sd">        ...           (&quot;petal.width&quot;, pa.float64()),</span>
<span class="sd">        ...           (&quot;variety&quot;, pa.string())]</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_parquet(&quot;example://iris.parquet&quot;,</span>
<span class="sd">        ...     schema=pa.schema(fields))</span>
<span class="sd">        Dataset(</span>
<span class="sd">           num_blocks=1,</span>
<span class="sd">           num_rows=150,</span>
<span class="sd">           schema={</span>
<span class="sd">              sepal.length: double,</span>
<span class="sd">              sepal.width: double,</span>
<span class="sd">              petal.length: double,</span>
<span class="sd">              petal.width: double,</span>
<span class="sd">              variety: string</span>
<span class="sd">           }</span>
<span class="sd">        )</span>

<span class="sd">        The Parquet reader also supports projection and filter pushdown, allowing column</span>
<span class="sd">        selection and row filtering to be pushed down to the file scan.</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import pyarrow as pa</span>

<span class="sd">            # Create a Dataset by reading a Parquet file, pushing column selection and</span>
<span class="sd">            # row filtering down to the file scan.</span>
<span class="sd">            ds = ray.data.read_parquet(</span>
<span class="sd">                &quot;example://iris.parquet&quot;,</span>
<span class="sd">                columns=[&quot;sepal.length&quot;, &quot;variety&quot;],</span>
<span class="sd">                filter=pa.dataset.field(&quot;sepal.length&quot;) &gt; 5.0,</span>
<span class="sd">            )</span>

<span class="sd">            ds.show(2)</span>

<span class="sd">        .. testoutput::</span>

<span class="sd">            {&#39;sepal.length&#39;: 5.1, &#39;variety&#39;: &#39;Setosa&#39;}</span>
<span class="sd">            {&#39;sepal.length&#39;: 5.4, &#39;variety&#39;: &#39;Setosa&#39;}</span>

<span class="sd">        For further arguments you can pass to pyarrow as a keyword argument, see</span>
<span class="sd">        https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Scanner.html#pyarrow.dataset.Scanner.from_fragment</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file path or directory, or a list of file paths. Multiple</span>
<span class="sd">            directories are not supported.</span>
<span class="sd">        filesystem: The filesystem implementation to read from. These are specified in</span>
<span class="sd">            https://arrow.apache.org/docs/python/api/filesystems.html#filesystem-implementations.</span>
<span class="sd">        columns: A list of column names to read.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the dataset.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>
<span class="sd">        tensor_column_schema: A dict of column name --&gt; tensor dtype and shape</span>
<span class="sd">            mappings for converting a Parquet column containing serialized</span>
<span class="sd">            tensors (ndarrays) as their elements to our tensor column extension</span>
<span class="sd">            type. This assumes that the tensors were serialized in the raw</span>
<span class="sd">            NumPy array format in C-contiguous order (e.g. via</span>
<span class="sd">            `arr.tobytes()`).</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        arrow_parquet_args: Other parquet read options to pass to pyarrow, see</span>
<span class="sd">            https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Scanner.html#pyarrow.dataset.Scanner.from_fragment</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing Arrow records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arrow_parquet_args</span> <span class="o">=</span> <span class="n">_resolve_parquet_args</span><span class="p">(</span>
        <span class="n">tensor_column_schema</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">ParquetDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_images"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_images.html#ray.data.read_images">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;beta&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_images</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">_ImageFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_file_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">PathPartitionFilter</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">ImageDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">(),</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">include_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Read images from the specified paths.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; path = &quot;s3://anonymous@air-example-data-2/movie-image-small-filesize-1GB&quot;</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_images(path)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">        Dataset(num_blocks=200, num_rows=41979, schema={image: numpy.ndarray(ndim=3, dtype=uint8)})</span>

<span class="sd">        If you need image file paths, set ``include_paths=True``.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_images(path, include_paths=True)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">        Dataset(num_blocks=200, num_rows=41979, schema={image: numpy.ndarray(ndim=3, dtype=uint8), path: string})</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)[0][&quot;path&quot;]  # doctest: +SKIP</span>
<span class="sd">        &#39;air-example-data-2/movie-image-small-filesize-1GB/0.jpg&#39;</span>

<span class="sd">        If your images are arranged like:</span>

<span class="sd">        .. code::</span>

<span class="sd">            root/dog/xxx.png</span>
<span class="sd">            root/dog/xxy.png</span>

<span class="sd">            root/cat/123.png</span>
<span class="sd">            root/cat/nsdf3.png</span>

<span class="sd">        Then you can include the labels by specifying a</span>
<span class="sd">        :class:`~ray.data.datasource.partitioning.Partitioning`.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from ray.data.datasource.partitioning import Partitioning</span>
<span class="sd">        &gt;&gt;&gt; root = &quot;example://tiny-imagenet-200/train&quot;</span>
<span class="sd">        &gt;&gt;&gt; partitioning = Partitioning(&quot;dir&quot;, field_names=[&quot;class&quot;], base_dir=root)</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_images(root, size=(224, 224), partitioning=partitioning)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">        Dataset(num_blocks=176, num_rows=94946, schema={image: TensorDtype(shape=(224, 224, 3), dtype=uint8), class: object})</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the dataset.</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>
<span class="sd">        arrow_open_file_args: kwargs passed to</span>
<span class="sd">            ``pyarrow.fs.FileSystem.open_input_file``.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match ``*.png``, ``*.jpg``, ``*.jpeg``, ``*.tiff``, ``*.bmp``, or ``*.gif``.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        size: The desired height and width of loaded images. If unspecified, images</span>
<span class="sd">            retain their original shape.</span>
<span class="sd">        mode: A `Pillow mode &lt;https://pillow.readthedocs.io/en/stable/handbook/concepts.html#modes&gt;`_</span>
<span class="sd">            describing the desired type and depth of pixels. If unspecified, image</span>
<span class="sd">            modes are inferred by</span>
<span class="sd">            `Pillow &lt;https://pillow.readthedocs.io/en/stable/index.html&gt;`_.</span>
<span class="sd">        include_paths: If ``True``, include the path to each image. File paths are</span>
<span class="sd">            stored in the ``&#39;path&#39;`` column.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file/directory paths in ``paths``</span>
<span class="sd">            that are not found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` producing tensors that represent the images at</span>
<span class="sd">        the specified paths. For information on working with tensors, read the</span>
<span class="sd">        :ref:`tensor data guide &lt;working_with_tensors&gt;`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if ``size`` contains non-positive numbers.</span>
<span class="sd">        ValueError: if ``mode`` is unsupported.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">ImageDatasource</span><span class="p">(),</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_file_args</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
        <span class="n">include_paths</span><span class="o">=</span><span class="n">include_paths</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_parquet_bulk"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_parquet_bulk.html#ray.data.read_parquet_bulk">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_parquet_bulk</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_file_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tensor_column_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">FastFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">ParquetBaseDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">()</span>
    <span class="p">),</span>
    <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create an Arrow dataset from a large number (such as &gt;1K) of parquet files</span>
<span class="sd">    quickly.</span>

<span class="sd">    By default, ONLY file paths should be provided as input (i.e. no directory paths),</span>
<span class="sd">    and an OSError will be raised if one or more paths point to directories. If your</span>
<span class="sd">    use-case requires directory paths, then the metadata provider should be changed to</span>
<span class="sd">    one that supports directory expansion (e.g. ``DefaultFileMetadataProvider``).</span>

<span class="sd">    Offers improved performance vs. :func:`read_parquet` due to not using PyArrow&#39;s</span>
<span class="sd">    ``ParquetDataset`` abstraction, whose latency scales linearly with the number of</span>
<span class="sd">    input files due to collecting all file metadata on a single node.</span>

<span class="sd">    Also supports a wider variety of input Parquet file types than :func:`read_parquet`</span>
<span class="sd">    due to not trying to merge and resolve a unified schema for all files.</span>

<span class="sd">    However, unlike :func:`read_parquet`, this does not offer file metadata resolution</span>
<span class="sd">    by default, so a custom metadata provider should be provided if your use-case</span>
<span class="sd">    requires a unified schema, block sizes, row counts, etc.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Read multiple local files. You should always provide only input file</span>
<span class="sd">        &gt;&gt;&gt; # paths (i.e. no directory paths) when known to minimize read latency.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_parquet_bulk( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;])</span>

<span class="sd">        &gt;&gt;&gt; # Read a directory of files in remote storage. Caution should be taken</span>
<span class="sd">        &gt;&gt;&gt; # when providing directory paths, since the time to both check each path</span>
<span class="sd">        &gt;&gt;&gt; # type and expand its contents may result in greatly increased latency</span>
<span class="sd">        &gt;&gt;&gt; # and/or request rate throttling from cloud storage service providers.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_parquet_bulk( # doctest: +SKIP</span>
<span class="sd">        ...     &quot;s3://bucket/path&quot;,</span>
<span class="sd">        ...     meta_provider=DefaultFileMetadataProvider())</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file path or a list of file paths. If one or more directories</span>
<span class="sd">            are provided, then ``meta_provider`` should also be set to an implementation</span>
<span class="sd">            that supports directory expansion (e.g. ``DefaultFileMetadataProvider``).</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        columns: A list of column names to read.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the dataset.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>
<span class="sd">        arrow_open_file_args: kwargs passed to</span>
<span class="sd">            ``pyarrow.fs.FileSystem.open_input_file``.</span>
<span class="sd">        tensor_column_schema: A dict of column name --&gt; tensor dtype and shape</span>
<span class="sd">            mappings for converting a Parquet column containing serialized</span>
<span class="sd">            tensors (ndarrays) as their elements to our tensor column extension</span>
<span class="sd">            type. This assumes that the tensors were serialized in the raw</span>
<span class="sd">            NumPy array format in C-contiguous order (e.g. via</span>
<span class="sd">            ``arr.tobytes()``).</span>
<span class="sd">        meta_provider: File metadata provider. Defaults to a fast file metadata</span>
<span class="sd">            provider that skips file size collection and requires all input paths to be</span>
<span class="sd">            files. Change to ``DefaultFileMetadataProvider`` or a custom metadata</span>
<span class="sd">            provider if directory expansion and/or file metadata resolution is required.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match &quot;*.parquet*&quot;.</span>
<span class="sd">        arrow_parquet_args: Other parquet read options to pass to pyarrow.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing Arrow records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arrow_parquet_args</span> <span class="o">=</span> <span class="n">_resolve_parquet_args</span><span class="p">(</span>
        <span class="n">tensor_column_schema</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">ParquetBaseDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_file_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_json"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_json.html#ray.data.read_json">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_json</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">PathPartitionFilter</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">JSONDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">(),</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="n">Partitioning</span><span class="p">(</span><span class="s2">&quot;hive&quot;</span><span class="p">),</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">arrow_json_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create an Arrow dataset from json files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; # Read a directory of files in remote storage.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_json(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple local files.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_json([&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;]) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple directories.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_json( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;s3://bucket/path1&quot;, &quot;s3://bucket/path2&quot;])</span>

<span class="sd">        By default, ``read_json`` parses</span>
<span class="sd">        `Hive-style partitions &lt;https://athena.guide/articles/hive-style-partitioning/&gt;`_</span>
<span class="sd">        from file paths. If your data adheres to a different partitioning scheme, set</span>
<span class="sd">        the ``partitioning`` parameter.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_json(&quot;example://year=2022/month=09/sales.json&quot;)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)  # doctest: +SKIP</span>
<span class="sd">        [{&#39;order_number&#39;: 10107, &#39;quantity&#39;: 30, &#39;year&#39;: &#39;2022&#39;, &#39;month&#39;: &#39;09&#39;}</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the dataset.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            pyarrow.fs.FileSystem.open_input_stream</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match &quot;*.json*&quot;.</span>
<span class="sd">        arrow_json_args: Other json read options to pass to pyarrow.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. By default, this function parses</span>
<span class="sd">            `Hive-style partitions &lt;https://athena.guide/articles/hive-style-partitioning/&gt;`_.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing Arrow records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">JSONDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_json_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_csv"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_csv.html#ray.data.read_csv">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_csv</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="n">Partitioning</span><span class="p">(</span><span class="s2">&quot;hive&quot;</span><span class="p">),</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Create an Arrow dataset from csv files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; # Read a directory of files in remote storage.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_csv(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple local files.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_csv([&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;]) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple directories.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_csv( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;s3://bucket/path1&quot;, &quot;s3://bucket/path2&quot;])</span>

<span class="sd">        &gt;&gt;&gt; # Read files that use a different delimiter. For more uses of ParseOptions see</span>
<span class="sd">        &gt;&gt;&gt; # https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html  # noqa: #501</span>
<span class="sd">        &gt;&gt;&gt; from pyarrow import csv</span>
<span class="sd">        &gt;&gt;&gt; parse_options = csv.ParseOptions(delimiter=&quot;\t&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_csv( # doctest: +SKIP</span>
<span class="sd">        ...     &quot;example://iris.tsv&quot;,</span>
<span class="sd">        ...     parse_options=parse_options)</span>

<span class="sd">        &gt;&gt;&gt; # Convert a date column with a custom format from a CSV file.</span>
<span class="sd">        &gt;&gt;&gt; # For more uses of ConvertOptions see</span>
<span class="sd">        &gt;&gt;&gt; # https://arrow.apache.org/docs/python/generated/pyarrow.csv.ConvertOptions.html  # noqa: #501</span>
<span class="sd">        &gt;&gt;&gt; from pyarrow import csv</span>
<span class="sd">        &gt;&gt;&gt; convert_options = csv.ConvertOptions(</span>
<span class="sd">        ...     timestamp_parsers=[&quot;%m/%d/%Y&quot;])</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_csv( # doctest: +SKIP</span>
<span class="sd">        ...     &quot;example://dow_jones_index.csv&quot;,</span>
<span class="sd">        ...     convert_options=convert_options)</span>

<span class="sd">        By default, ``read_csv`` parses</span>
<span class="sd">        `Hive-style partitions &lt;https://athena.guide/articles/hive-style-partitioning/&gt;`_</span>
<span class="sd">        from file paths. If your data adheres to a different partitioning scheme, set</span>
<span class="sd">        the ``partitioning`` parameter.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_csv(&quot;example://year=2022/month=09/sales.csv&quot;)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)  # doctest: +SKIP</span>
<span class="sd">        [{&#39;order_number&#39;: 10107, &#39;quantity&#39;: 30, &#39;year&#39;: &#39;2022&#39;, &#39;month&#39;: &#39;09&#39;}]</span>

<span class="sd">        By default, ``read_csv`` reads all files from file paths. If you want to filter</span>
<span class="sd">        files by file extensions, set the ``partition_filter`` parameter.</span>

<span class="sd">        &gt;&gt;&gt; # Read only *.csv files from multiple directories.</span>
<span class="sd">        &gt;&gt;&gt; from ray.data.datasource import FileExtensionFilter</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_csv( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;s3://bucket/path1&quot;, &quot;s3://bucket/path2&quot;],</span>
<span class="sd">        ...     partition_filter=FileExtensionFilter(&quot;csv&quot;))</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the dataset.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            pyarrow.fs.FileSystem.open_input_stream</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this does not filter out any files.</span>
<span class="sd">            If wishing to filter out all file paths except those whose file extension</span>
<span class="sd">            matches e.g. &quot;*.csv*&quot;, a ``FileExtensionFilter(&quot;csv&quot;)`` can be provided.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. By default, this function parses</span>
<span class="sd">            `Hive-style partitions &lt;https://athena.guide/articles/hive-style-partitioning/&gt;`_.</span>
<span class="sd">        arrow_csv_args: Other csv read options to pass to pyarrow.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing Arrow records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">CSVDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_text"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_text.html#ray.data.read_text">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_text</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">encoding</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">,</span>
    <span class="n">errors</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
    <span class="n">drop_empty_lines</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from lines stored in text files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; # Read a directory of files in remote storage.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_text(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple local files.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_text([&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;]) # doctest: +SKIP</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file path or a list of file paths (or directories).</span>
<span class="sd">        encoding: The encoding of the files (e.g., &quot;utf-8&quot; or &quot;ascii&quot;).</span>
<span class="sd">        errors: What to do with errors on decoding. Specify either &quot;strict&quot;,</span>
<span class="sd">            &quot;ignore&quot;, or &quot;replace&quot;. Defaults to &quot;ignore&quot;.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the stream.</span>
<span class="sd">        ray_remote_args: Kwargs passed to ray.remote in the read tasks and</span>
<span class="sd">            in the subsequent text decoding map task.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            pyarrow.fs.FileSystem.open_input_stream</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a stream.</span>
<span class="sd">            By default, this does not filter out any files.</span>
<span class="sd">            If wishing to filter out all file paths except those whose file extension</span>
<span class="sd">            matches e.g. &quot;*.txt*&quot;, a ``FileXtensionFilter(&quot;txt&quot;)`` can be provided.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing lines of text read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">TextDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">drop_empty_lines</span><span class="o">=</span><span class="n">drop_empty_lines</span><span class="p">,</span>
        <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_numpy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_numpy.html#ray.data.read_numpy">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_numpy</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">PathPartitionFilter</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">NumpyDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">(),</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">numpy_load_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create an Arrow dataset from numpy files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; # Read a directory of files in remote storage.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_numpy(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple local files.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_numpy([&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;]) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple directories.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_numpy( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;s3://bucket/path1&quot;, &quot;s3://bucket/path2&quot;])</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the dataset.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            pyarrow.fs.FileSystem.open_input_stream</span>
<span class="sd">        numpy_load_args: Other options to pass to np.load.</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match &quot;*.npy*&quot;.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset holding Tensor records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">NumpyDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="o">**</span><span class="n">numpy_load_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_tfrecords"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_tfrecords.html#ray.data.read_tfrecords">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_tfrecords</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">tf_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;schema_pb2.Schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from TFRecord files that contain</span>
<span class="sd">    `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/Example&gt;`_</span>
<span class="sd">    messages.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This function exclusively supports ``tf.train.Example`` messages. If a file</span>
<span class="sd">        contains a message that isn&#39;t of type ``tf.train.Example``, then this function</span>
<span class="sd">        errors.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import os</span>
<span class="sd">        &gt;&gt;&gt; import tempfile</span>
<span class="sd">        &gt;&gt;&gt; import tensorflow as tf</span>
<span class="sd">        &gt;&gt;&gt; features = tf.train.Features(</span>
<span class="sd">        ...     feature={</span>
<span class="sd">        ...         &quot;length&quot;: tf.train.Feature(float_list=tf.train.FloatList(value=[5.1])),</span>
<span class="sd">        ...         &quot;width&quot;: tf.train.Feature(float_list=tf.train.FloatList(value=[3.5])),</span>
<span class="sd">        ...         &quot;species&quot;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[b&quot;setosa&quot;])),</span>
<span class="sd">        ...     }</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; example = tf.train.Example(features=features)</span>
<span class="sd">        &gt;&gt;&gt; path = os.path.join(tempfile.gettempdir(), &quot;data.tfrecords&quot;)</span>
<span class="sd">        &gt;&gt;&gt; with tf.io.TFRecordWriter(path=path) as writer:</span>
<span class="sd">        ...     writer.write(example.SerializeToString())</span>

<span class="sd">        This function reads ``tf.train.Example`` messages into a tabular</span>
<span class="sd">        :class:`~ray.data.Dataset`.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_tfrecords(path)</span>
<span class="sd">        &gt;&gt;&gt; ds.to_pandas()  # doctest: +SKIP</span>
<span class="sd">           length  width    species</span>
<span class="sd">        0     5.1    3.5  b&#39;setosa&#39;</span>

<span class="sd">        We can also read compressed TFRecord files which uses one of the</span>
<span class="sd">        `compression type supported by Arrow &lt;https://arrow.apache.org/docs/python/generated/pyarrow.CompressedInputStream.html&gt;`_:</span>

<span class="sd">        &gt;&gt;&gt; compressed_path = os.path.join(tempfile.gettempdir(), &quot;data_compressed.tfrecords&quot;)</span>
<span class="sd">        &gt;&gt;&gt; options = tf.io.TFRecordOptions(compression_type=&quot;GZIP&quot;) # &quot;ZLIB&quot; also supported by TensorFlow</span>
<span class="sd">        &gt;&gt;&gt; with tf.io.TFRecordWriter(path=compressed_path, options=options) as writer:</span>
<span class="sd">        ...     writer.write(example.SerializeToString())</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_tfrecords(</span>
<span class="sd">        ...     [compressed_path],</span>
<span class="sd">        ...     arrow_open_stream_args={&quot;compression&quot;: &quot;gzip&quot;},</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; ds.to_pandas()  # doctest: +SKIP</span>
<span class="sd">           length  width    species</span>
<span class="sd">        0     5.1    3.5  b&#39;setosa&#39;</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files in the dataset.</span>
<span class="sd">        arrow_open_stream_args: Key-word arguments passed to</span>
<span class="sd">            ``pyarrow.fs.FileSystem.open_input_stream``. To read a compressed TFRecord file,</span>
<span class="sd">            pass the corresponding compression type (e.g. for ``GZIP`` or ``ZLIB``, use</span>
<span class="sd">            ``arrow_open_stream_args={&#39;compression_type&#39;: &#39;gzip&#39;}``).</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match ``&quot;*.tfrecords*&quot;``.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>
<span class="sd">        tf_schema: Optional TensorFlow Schema which is used to explicitly set the schema</span>
<span class="sd">            of the underlying Dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` that contains the example features.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If a file contains a message that isn&#39;t a ``tf.train.Example``.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">TFRecordDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="n">tf_schema</span><span class="o">=</span><span class="n">tf_schema</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_webdataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_webdataset.html#ray.data.read_webdataset">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_webdataset</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">decoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">callable</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">fileselect</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">filerename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">suffixes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose_open</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from WebDataset files.</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files in the dataset.</span>
<span class="sd">        arrow_open_stream_args: Key-word arguments passed to</span>
<span class="sd">            ``pyarrow.fs.FileSystem.open_input_stream``. To read a compressed TFRecord file,</span>
<span class="sd">            pass the corresponding compression type (e.g. for ``GZIP`` or ``ZLIB``, use</span>
<span class="sd">            ``arrow_open_stream_args={&#39;compression_type&#39;: &#39;gzip&#39;}``).</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">        decoder: A function or list of functions to decode the data.</span>
<span class="sd">        fileselect: A callable or list of glob patterns to select files.</span>
<span class="sd">        filerename: A function or list of tuples to rename files prior to grouping.</span>
<span class="sd">        suffixes: A function or list of suffixes to select for creating samples.</span>
<span class="sd">        verbose_open: Whether to print the file names as they are opened.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` that contains the example features.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If a file contains a message that isn&#39;t a ``tf.train.Example``.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">WebDatasetDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
        <span class="n">fileselect</span><span class="o">=</span><span class="n">fileselect</span><span class="p">,</span>
        <span class="n">filerename</span><span class="o">=</span><span class="n">filerename</span><span class="p">,</span>
        <span class="n">suffixes</span><span class="o">=</span><span class="n">suffixes</span><span class="p">,</span>
        <span class="n">verbose_open</span><span class="o">=</span><span class="n">verbose_open</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_binary_files"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_binary_files.html#ray.data.read_binary_files">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_binary_files</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">include_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">BaseFileMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultFileMetadataProvider</span><span class="p">(),</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">output_arrow_format</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from binary files of arbitrary contents.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; # Read a directory of files in remote storage.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_binary_files(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        &gt;&gt;&gt; # Read multiple local files.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_binary_files( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;])</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file path or a list of file paths (or directories).</span>
<span class="sd">        include_paths: Whether to include the full path of the file in the</span>
<span class="sd">            dataset records. When specified, the stream records will be a</span>
<span class="sd">            tuple of the file path and the file contents.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        ray_remote_args: kwargs passed to ray.remote in the read tasks.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the stream.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            pyarrow.fs.FileSystem.open_input_stream</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this does not filter out any files.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>
<span class="sd">        output_arrow_format: If True, returns data in Arrow format, instead of Python</span>
<span class="sd">            list format. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset producing records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">strict_mode</span><span class="p">:</span>
        <span class="n">output_arrow_format</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">output_arrow_format</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;read_binary_files() returns Dataset in Python list format as of Ray &quot;</span>
            <span class="s2">&quot;v2.4. Use read_binary_files(output_arrow_format=True) to return &quot;</span>
            <span class="s2">&quot;Dataset in Arrow format.&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">BinaryDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">include_paths</span><span class="o">=</span><span class="n">include_paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="n">output_arrow_format</span><span class="o">=</span><span class="n">output_arrow_format</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_sql"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_sql.html#ray.data.read_sql">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_sql</span><span class="p">(</span>
    <span class="n">sql</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">connection_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Connection</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Read from a database that provides a</span>
<span class="sd">    `Python DB API2-compliant &lt;https://peps.python.org/pep-0249/&gt;`_ connector.</span>

<span class="sd">    .. note::</span>

<span class="sd">        By default, ``read_sql`` launches multiple read tasks, and each task executes a</span>
<span class="sd">        ``LIMIT`` and ``OFFSET`` to fetch a subset of the rows. However, for many</span>
<span class="sd">        databases, ``OFFSET`` is slow.</span>

<span class="sd">        As a workaround, set ``parallelism=1`` to directly fetch all rows in a single</span>
<span class="sd">        task. Note that this approach requires all result rows to fit in the memory of</span>
<span class="sd">        single task. If the rows don&#39;t fit, your program may raise an out of memory</span>
<span class="sd">        error.</span>

<span class="sd">    Examples:</span>

<span class="sd">        For examples of reading from larger databases like MySQL and PostgreSQL, see</span>
<span class="sd">        :ref:`Reading from SQL Databases &lt;reading_sql&gt;`.</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import sqlite3</span>

<span class="sd">            import ray</span>

<span class="sd">            # Create a simple database</span>
<span class="sd">            connection = sqlite3.connect(&quot;example.db&quot;)</span>
<span class="sd">            connection.execute(&quot;CREATE TABLE movie(title, year, score)&quot;)</span>
<span class="sd">            connection.execute(</span>
<span class="sd">                \&quot;\&quot;\&quot;</span>
<span class="sd">                INSERT INTO movie VALUES</span>
<span class="sd">                    (&#39;Monty Python and the Holy Grail&#39;, 1975, 8.2),</span>
<span class="sd">                    (&quot;Monty Python Live at the Hollywood Bowl&quot;, 1982, 7.9),</span>
<span class="sd">                    (&quot;Monty Python&#39;s Life of Brian&quot;, 1979, 8.0),</span>
<span class="sd">                    (&quot;Rocky II&quot;, 1979, 7.3)</span>
<span class="sd">                \&quot;\&quot;\&quot;</span>
<span class="sd">            )</span>
<span class="sd">            connection.commit()</span>
<span class="sd">            connection.close()</span>

<span class="sd">            def create_connection():</span>
<span class="sd">                return sqlite3.connect(&quot;example.db&quot;)</span>

<span class="sd">            # Get all movies</span>
<span class="sd">            ds = ray.data.read_sql(&quot;SELECT * FROM movie&quot;, create_connection)</span>
<span class="sd">            # Get movies after the year 1980</span>
<span class="sd">            ds = ray.data.read_sql(</span>
<span class="sd">                &quot;SELECT title, score FROM movie WHERE year &gt;= 1980&quot;, create_connection</span>
<span class="sd">            )</span>
<span class="sd">            # Get the number of movies per year</span>
<span class="sd">            ds = ray.data.read_sql(</span>
<span class="sd">                &quot;SELECT year, COUNT(*) FROM movie GROUP BY year&quot;, create_connection</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        sql: The SQL query to execute.</span>
<span class="sd">        connection_factory: A function that takes no arguments and returns a</span>
<span class="sd">            Python DB API2</span>
<span class="sd">            `Connection object &lt;https://peps.python.org/pep-0249/#connection-objects&gt;`_.</span>
<span class="sd">        parallelism: The requested parallelism of the read.</span>
<span class="sd">        ray_remote_args: Keyword arguments passed to :func:`ray.remote` in read tasks.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`Dataset` containing the queried data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">datasource</span> <span class="o">=</span> <span class="n">SQLDatasource</span><span class="p">(</span><span class="n">connection_factory</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">datasource</span><span class="p">,</span>
        <span class="n">sql</span><span class="o">=</span><span class="n">sql</span><span class="p">,</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_dask"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_dask.html#ray.data.from_dask">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_dask</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="s2">&quot;dask.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a Dask DataFrame.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: A Dask DataFrame.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records read from the DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">dask</span>

    <span class="kn">from</span> <span class="nn">ray.util.dask</span> <span class="kn">import</span> <span class="n">ray_dask_get</span>

    <span class="n">partitions</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_delayed</span><span class="p">()</span>
    <span class="n">persisted_partitions</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="o">*</span><span class="n">partitions</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">ray_dask_get</span><span class="p">)</span>

    <span class="kn">import</span> <span class="nn">pandas</span>

    <span class="k">def</span> <span class="nf">to_ref</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">df</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected a Ray object ref or a Pandas DataFrame, &quot;</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="n">ds</span> <span class="o">=</span> <span class="n">from_pandas_refs</span><span class="p">(</span>
        <span class="p">[</span><span class="n">to_ref</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">part</span><span class="o">.</span><span class="n">dask</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span> <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">persisted_partitions</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span></div>


<div class="viewcode-block" id="from_mars"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_mars.html#ray.data.from_mars">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_mars</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="s2">&quot;mars.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a MARS dataframe.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: A MARS dataframe, which must be executed by MARS-on-Ray.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records read from the dataframe.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">mars.dataframe</span> <span class="k">as</span> <span class="nn">md</span>

    <span class="n">ds</span><span class="p">:</span> <span class="n">Dataset</span> <span class="o">=</span> <span class="n">md</span><span class="o">.</span><span class="n">to_ray_dataset</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span></div>


<div class="viewcode-block" id="from_modin"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_modin.html#ray.data.from_modin">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_modin</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="s2">&quot;modin.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a Modin dataframe.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: A Modin dataframe, which must be using the Ray backend.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records read from the dataframe.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">modin.distributed.dataframe.pandas.partitions</span> <span class="kn">import</span> <span class="n">unwrap_partitions</span>

    <span class="n">parts</span> <span class="o">=</span> <span class="n">unwrap_partitions</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">from_pandas_refs</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span></div>


<div class="viewcode-block" id="from_pandas"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_pandas.html#ray.data.from_pandas">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_pandas</span><span class="p">(</span>
    <span class="n">dfs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">]]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a list of Pandas dataframes.</span>

<span class="sd">    Args:</span>
<span class="sd">        dfs: A Pandas dataframe or a list of Pandas dataframes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records read from the dataframes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dfs</span><span class="p">]</span>

    <span class="kn">from</span> <span class="nn">ray.air.util.data_batch_conversion</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">_cast_ndarray_columns_to_tensor_extension</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">enable_tensor_extension_casting</span><span class="p">:</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">_cast_ndarray_columns_to_tensor_extension</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">from_pandas_refs</span><span class="p">([</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">])</span></div>


<div class="viewcode-block" id="from_pandas_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_pandas_refs.html#ray.data.from_pandas_refs">[docs]</a><span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">from_pandas_refs</span><span class="p">(</span>
    <span class="n">dfs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a list of Ray object references to Pandas</span>
<span class="sd">    dataframes.</span>

<span class="sd">    Args:</span>
<span class="sd">        dfs: A Ray object references to pandas dataframe, or a list of</span>
<span class="sd">             Ray object references to pandas dataframes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records read from the dataframes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dfs</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected list of Ray object refs, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got list containing </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Expected Ray object ref or list of Ray object refs, &quot;</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">enable_pandas_block</span><span class="p">:</span>
        <span class="n">get_metadata</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">get_table_block_metadata</span><span class="p">)</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="n">get_metadata</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">])</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromPandas</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">BlockList</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromPandas&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="mi">0</span><span class="p">,</span>
            <span class="kc">True</span><span class="p">,</span>
            <span class="n">logical_plan</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">df_to_block</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">pandas_df_to_arrow_block</span><span class="p">,</span> <span class="n">num_returns</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">df_to_block</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">]</span>
    <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">))</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromPandas</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromPandas&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_numpy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_numpy.html#ray.data.from_numpy">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_numpy</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a list of NumPy ndarrays.</span>

<span class="sd">    Args:</span>
<span class="sd">        ndarrays: A NumPy ndarray or a list of NumPy ndarrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding the given ndarrays.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">ndarrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">ndarrays</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">from_numpy_refs</span><span class="p">([</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">ndarray</span> <span class="ow">in</span> <span class="n">ndarrays</span><span class="p">])</span></div>


<div class="viewcode-block" id="from_numpy_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_numpy_refs.html#ray.data.from_numpy_refs">[docs]</a><span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">from_numpy_refs</span><span class="p">(</span>
    <span class="n">ndarrays</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a list of NumPy ndarray futures.</span>

<span class="sd">    Args:</span>
<span class="sd">        ndarrays: A Ray object reference to a NumPy ndarray or a list of Ray object</span>
<span class="sd">            references to NumPy ndarrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding the given ndarrays.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
        <span class="n">ndarrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">ndarrays</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ndarray</span> <span class="ow">in</span> <span class="n">ndarrays</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected list of Ray object refs, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got list containing </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Expected Ray object ref or list of Ray object refs, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="n">ndarray_to_block_remote</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">ndarray_to_block</span><span class="p">,</span> <span class="n">num_returns</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">ndarray_to_block_remote</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span> <span class="k">for</span> <span class="n">ndarray</span> <span class="ow">in</span> <span class="n">ndarrays</span><span class="p">]</span>
    <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">))</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span>

    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromNumpy</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromNumpy&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_arrow"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_arrow.html#ray.data.from_arrow">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_arrow</span><span class="p">(</span>
    <span class="n">tables</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a list of Arrow tables.</span>

<span class="sd">    Args:</span>
<span class="sd">        tables: An Arrow table, or a list of Arrow tables,</span>
<span class="sd">                or its streaming format in bytes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records from the tables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)):</span>
        <span class="n">tables</span> <span class="o">=</span> <span class="p">[</span><span class="n">tables</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">from_arrow_refs</span><span class="p">([</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">])</span></div>


<div class="viewcode-block" id="from_arrow_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_arrow_refs.html#ray.data.from_arrow_refs">[docs]</a><span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">from_arrow_refs</span><span class="p">(</span>
    <span class="n">tables</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">ObjectRef</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]],</span>
        <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]],</span>
    <span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a set of Arrow tables.</span>

<span class="sd">    Args:</span>
<span class="sd">        tables: A Ray object reference to Arrow table, or list of Ray object</span>
<span class="sd">                references to Arrow tables, or its streaming format in bytes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records from the tables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
        <span class="n">tables</span> <span class="o">=</span> <span class="p">[</span><span class="n">tables</span><span class="p">]</span>

    <span class="n">get_metadata</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">get_table_block_metadata</span><span class="p">)</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="n">get_metadata</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">])</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromArrow</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromArrow&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_spark"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_spark.html#ray.data.from_spark">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_spark</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="s2">&quot;pyspark.sql.DataFrame&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a Spark dataframe.</span>

<span class="sd">    Args:</span>
<span class="sd">        spark: A SparkSession, which must be created by RayDP (Spark-on-Ray).</span>
<span class="sd">        df: A Spark dataframe, which must be created by RayDP (Spark-on-Ray).</span>
<span class="sd">            parallelism: The amount of parallelism to use for the dataset.</span>
<span class="sd">            If not provided, it will be equal to the number of partitions of</span>
<span class="sd">            the original Spark dataframe.</span>

<span class="sd">    Returns:</span>
<span class="sd">        MaterializedDataset holding Arrow records read from the dataframe.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">raydp</span>

    <span class="k">return</span> <span class="n">raydp</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">spark_dataframe_to_ray_dataset</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">)</span></div>


<div class="viewcode-block" id="from_huggingface"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_huggingface.html#ray.data.from_huggingface">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_huggingface</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;datasets.Dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;datasets.DatasetDict&quot;</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">MaterializedDataset</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">MaterializedDataset</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a Hugging Face Datasets Dataset.</span>

<span class="sd">    This function is not parallelized, and is intended to be used</span>
<span class="sd">    with Hugging Face Datasets that are loaded into memory (as opposed</span>
<span class="sd">    to memory-mapped).</span>

<span class="sd">    Example:</span>

<span class="sd">    .. doctest::</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; import datasets</span>
<span class="sd">        &gt;&gt;&gt; hf_dataset = datasets.load_dataset(&quot;tweet_eval&quot;, &quot;emotion&quot;)</span>
<span class="sd">        Downloading ...</span>
<span class="sd">        &gt;&gt;&gt; ray_ds = ray.data.from_huggingface(hf_dataset)</span>
<span class="sd">        &gt;&gt;&gt; ray_ds</span>
<span class="sd">        {&#39;train&#39;: MaterializedDataset(</span>
<span class="sd">           num_blocks=1,</span>
<span class="sd">           num_rows=3257,</span>
<span class="sd">           schema={text: string, label: int64}</span>
<span class="sd">        ), &#39;test&#39;: MaterializedDataset(</span>
<span class="sd">           num_blocks=1,</span>
<span class="sd">           num_rows=1421,</span>
<span class="sd">           schema={text: string, label: int64}</span>
<span class="sd">        ), &#39;validation&#39;: MaterializedDataset(</span>
<span class="sd">           num_blocks=1,</span>
<span class="sd">           num_rows=374,</span>
<span class="sd">           schema={text: string, label: int64}</span>
<span class="sd">        )}</span>
<span class="sd">        &gt;&gt;&gt; ray_ds = ray.data.from_huggingface(hf_dataset[&quot;train&quot;])</span>
<span class="sd">        &gt;&gt;&gt; ray_ds</span>
<span class="sd">        MaterializedDataset(</span>
<span class="sd">           num_blocks=1,</span>
<span class="sd">           num_rows=3257,</span>
<span class="sd">           schema={text: string, label: int64}</span>
<span class="sd">        )</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: A Hugging Face Dataset, or DatasetDict. IterableDataset is not</span>
<span class="sd">            supported. ``IterableDataset`` is not supported.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset holding Arrow records from the Hugging Face Dataset, or a dict of</span>
<span class="sd">            datasets in case dataset is a DatasetDict.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">datasets</span>

    <span class="k">def</span> <span class="nf">convert</span><span class="p">(</span><span class="n">ds</span><span class="p">:</span> <span class="s2">&quot;datasets.Dataset&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
        <span class="c1"># To get the resulting Arrow table from a Hugging Face Dataset after</span>
        <span class="c1"># applying transformations (e.g. train_test_split(), shard(), select()),</span>
        <span class="c1"># we create a copy of the Arrow table, which applies the indices</span>
        <span class="c1"># mapping from the transformations.</span>
        <span class="n">hf_ds_arrow</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)</span>
        <span class="n">ray_ds</span> <span class="o">=</span> <span class="n">from_arrow</span><span class="p">(</span><span class="n">hf_ds_arrow</span><span class="p">[:])</span>
        <span class="k">return</span> <span class="n">ray_ds</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">DatasetDict</span><span class="p">):</span>
        <span class="n">available_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;You provided a Huggingface DatasetDict which contains multiple &quot;</span>
            <span class="s2">&quot;datasets. The output of `from_huggingface` is a dictionary of Ray &quot;</span>
            <span class="s2">&quot;Datasets. To convert just a single Huggingface Dataset to a &quot;</span>
            <span class="s2">&quot;Ray Dataset, specify a split. For example, &quot;</span>
            <span class="s2">&quot;`ray.data.from_huggingface(my_dataset_dictionary&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;[&#39;</span><span class="si">{</span><span class="n">available_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;])`. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Available splits are </span><span class="si">{</span><span class="n">available_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">convert</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">convert</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;`dataset` must be a `datasets.Dataset` or `datasets.DatasetDict`.&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="from_tf"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_tf.html#ray.data.from_tf">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_tf</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="s2">&quot;tf.data.Dataset&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a TensorFlow dataset.</span>

<span class="sd">    This function is inefficient. Use it to read small datasets or prototype.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        If your dataset is large, this function may execute slowly or raise an</span>
<span class="sd">        out-of-memory error. To avoid issues, read the underyling data with a function</span>
<span class="sd">        like :meth:`~ray.data.read_images`.</span>

<span class="sd">    .. note::</span>
<span class="sd">        This function isn&#39;t paralellized. It loads the entire dataset into the local</span>
<span class="sd">        node&#39;s memory before moving the data to the distributed object store.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; import tensorflow_datasets as tfds</span>
<span class="sd">        &gt;&gt;&gt; dataset, _ = tfds.load(&#39;cifar10&#39;, split=[&quot;train&quot;, &quot;test&quot;])  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.from_tf(dataset)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">        Dataset(num_blocks=200, num_rows=50000, schema={id: binary, image: numpy.ndarray(shape=(32, 32, 3), dtype=uint8), label: int64})</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)  # doctest: +SKIP</span>
<span class="sd">        [{&#39;id&#39;: b&#39;train_16399&#39;, &#39;image&#39;: array([[[143,  96,  70],</span>
<span class="sd">        [141,  96,  72],</span>
<span class="sd">        [135,  93,  72],</span>
<span class="sd">        ...,</span>
<span class="sd">        [ 96,  37,  19],</span>
<span class="sd">        [105,  42,  18],</span>
<span class="sd">        [104,  38,  20]],</span>

<span class="sd">       ...,</span>

<span class="sd">       [[195, 161, 126],</span>
<span class="sd">        [187, 153, 123],</span>
<span class="sd">        [186, 151, 128],</span>
<span class="sd">        ...,</span>
<span class="sd">        [212, 177, 147],</span>
<span class="sd">        [219, 185, 155],</span>
<span class="sd">        [221, 187, 157]]], dtype=uint8), &#39;label&#39;: 7}]</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: A TensorFlow dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`MaterializedDataset` that contains the samples stored in the</span>
<span class="sd">        TensorFlow dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="c1"># FIXME: `as_numpy_iterator` errors if `dataset` contains ragged tensors.</span>
    <span class="k">return</span> <span class="n">from_items</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">()))</span></div>


<div class="viewcode-block" id="from_torch"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_torch.html#ray.data.from_torch">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_torch</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="s2">&quot;torch.utils.data.Dataset&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a dataset from a Torch dataset.</span>

<span class="sd">    This function is inefficient. Use it to read small datasets or prototype.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        If your dataset is large, this function may execute slowly or raise an</span>
<span class="sd">        out-of-memory error. To avoid issues, read the underyling data with a function</span>
<span class="sd">        like :meth:`~ray.data.read_images`.</span>

<span class="sd">    .. note::</span>
<span class="sd">        This function isn&#39;t paralellized. It loads the entire dataset into the head</span>
<span class="sd">        node&#39;s memory before moving the data to the distributed object store.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from torchvision import datasets</span>
<span class="sd">        &gt;&gt;&gt; dataset = datasets.MNIST(&quot;data&quot;, download=True)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.from_torch(dataset)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">        Dataset(num_blocks=200, num_rows=60000, schema={item: object})</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)  # doctest: +SKIP</span>
<span class="sd">        {&quot;item&quot;: (&lt;PIL.Image.Image image mode=L size=28x28 at 0x...&gt;, 5)}</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: A Torch dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`MaterializedDataset` containing the Torch dataset samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">from_items</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span></div>


<span class="k">def</span> <span class="nf">_get_read_tasks</span><span class="p">(</span>
    <span class="n">ds</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="n">DataContext</span><span class="p">,</span>
    <span class="n">cur_pg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PlacementGroup</span><span class="p">],</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">local_uri</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ReadTask</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;Generates read tasks.</span>

<span class="sd">    Args:</span>
<span class="sd">        ds: Datasource to read from.</span>
<span class="sd">        ctx: Dataset config to use.</span>
<span class="sd">        cur_pg: The current placement group, if any.</span>
<span class="sd">        parallelism: The user-requested parallelism, or -1 for autodetection.</span>
<span class="sd">        kwargs: Additional kwargs to pass to the reader.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Request parallelism from the datasource, the min safe parallelism to avoid</span>
<span class="sd">        OOM, and the list of read tasks generated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">local_uri</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;local_uri&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_uri</span>
    <span class="n">DataContext</span><span class="o">.</span><span class="n">_set_current</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">create_reader</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">requested_parallelism</span><span class="p">,</span> <span class="n">min_safe_parallelism</span> <span class="o">=</span> <span class="n">_autodetect_parallelism</span><span class="p">(</span>
        <span class="n">parallelism</span><span class="p">,</span> <span class="n">cur_pg</span><span class="p">,</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">(),</span> <span class="n">reader</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">requested_parallelism</span><span class="p">,</span>
        <span class="n">min_safe_parallelism</span><span class="p">,</span>
        <span class="n">reader</span><span class="o">.</span><span class="n">get_read_tasks</span><span class="p">(</span><span class="n">requested_parallelism</span><span class="p">),</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_resolve_parquet_args</span><span class="p">(</span>
    <span class="n">tensor_column_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">tensor_column_schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">existing_block_udf</span> <span class="o">=</span> <span class="n">arrow_parquet_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_block_udf&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_block_udf</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorArray</span>

            <span class="k">for</span> <span class="n">tensor_col_name</span><span class="p">,</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tensor_column_schema</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># NOTE(Clark): We use NumPy to consolidate these potentially</span>
                <span class="c1"># non-contiguous buffers, and to do buffer bookkeeping in</span>
                <span class="c1"># general.</span>
                <span class="n">np_col</span> <span class="o">=</span> <span class="n">_create_possibly_ragged_ndarray</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">buffer</span><span class="o">=</span><span class="n">buf</span><span class="o">.</span><span class="n">as_buffer</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="n">tensor_col_name</span><span class="p">)</span>
                    <span class="p">]</span>
                <span class="p">)</span>

                <span class="n">block</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">set_column</span><span class="p">(</span>
                    <span class="n">block</span><span class="o">.</span><span class="n">_ensure_integer_index</span><span class="p">(</span><span class="n">tensor_col_name</span><span class="p">),</span>
                    <span class="n">tensor_col_name</span><span class="p">,</span>
                    <span class="n">ArrowTensorArray</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_col</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">existing_block_udf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Apply UDF after casting the tensor columns.</span>
                <span class="n">block</span> <span class="o">=</span> <span class="n">existing_block_udf</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">block</span>

        <span class="n">arrow_parquet_args</span><span class="p">[</span><span class="s2">&quot;_block_udf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_block_udf</span>
    <span class="k">return</span> <span class="n">arrow_parquet_args</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>