
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.train.lightning.lightning_trainer &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/versionwarning.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../../_static/js/docsearch.js"></script>
    <script src="../../../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../../_static/js/top-navigation.js"></script>
    <script src="../../../../_static/js/tags.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/train/lightning/lightning_trainer.html" />
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "_modules/ray/train/lightning/lightning_trainer", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/train/lightning/lightning_trainer.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.train.lightning.lightning_trainer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="kn">from</span> <span class="nn">inspect</span> <span class="kn">import</span> <span class="n">isclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.plugins.environments</span> <span class="kn">import</span> <span class="n">ClusterEnvironment</span>

<span class="kn">from</span> <span class="nn">ray.air</span> <span class="kn">import</span> <span class="n">session</span>
<span class="kn">from</span> <span class="nn">ray.air.config</span> <span class="kn">import</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">DatasetConfig</span><span class="p">,</span> <span class="n">RunConfig</span><span class="p">,</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.air.constants</span> <span class="kn">import</span> <span class="n">MODEL_KEY</span>
<span class="kn">from</span> <span class="nn">ray.air.checkpoint</span> <span class="kn">import</span> <span class="n">Checkpoint</span>
<span class="kn">from</span> <span class="nn">ray.data.preprocessor</span> <span class="kn">import</span> <span class="n">Preprocessor</span>
<span class="kn">from</span> <span class="nn">ray.train.trainer</span> <span class="kn">import</span> <span class="n">GenDataset</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="kn">from</span> <span class="nn">ray.train.torch.config</span> <span class="kn">import</span> <span class="n">TorchConfig</span>
<span class="kn">from</span> <span class="nn">ray.util</span> <span class="kn">import</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.train.lightning._lightning_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">RayDDPStrategy</span><span class="p">,</span>
    <span class="n">RayFSDPStrategy</span><span class="p">,</span>
    <span class="n">RayDeepSpeedStrategy</span><span class="p">,</span>
    <span class="n">RayEnvironment</span><span class="p">,</span>
    <span class="n">RayDataModule</span><span class="p">,</span>
    <span class="n">RayModelCheckpoint</span><span class="p">,</span>
    <span class="n">get_worker_root_device</span><span class="p">,</span>
<span class="p">)</span>


<span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="LightningConfigBuilder"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.html#ray.train.lightning.LightningConfigBuilder">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LightningConfigBuilder</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configuration Class to pass into LightningTrainer.</span>

<span class="sd">    Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            import torch</span>
<span class="sd">            import torch.nn as nn</span>
<span class="sd">            from ray.train.lightning import LightningConfigBuilder</span>

<span class="sd">            class LinearModule(pl.LightningModule):</span>
<span class="sd">                def __init__(self, input_dim, output_dim) -&gt; None:</span>
<span class="sd">                    super().__init__()</span>
<span class="sd">                    self.linear = nn.Linear(input_dim, output_dim)</span>

<span class="sd">                def forward(self, input):</span>
<span class="sd">                    return self.linear(input)</span>

<span class="sd">                def training_step(self, batch):</span>
<span class="sd">                    output = self.forward(batch)</span>
<span class="sd">                    loss = torch.sum(output)</span>
<span class="sd">                    self.log(&quot;loss&quot;, loss)</span>
<span class="sd">                    return loss</span>

<span class="sd">                def predict_step(self, batch, batch_idx):</span>
<span class="sd">                    return self.forward(batch)</span>

<span class="sd">                def configure_optimizers(self):</span>
<span class="sd">                    return torch.optim.SGD(self.parameters(), lr=0.1)</span>

<span class="sd">            lightning_config = (</span>
<span class="sd">                LightningConfigBuilder()</span>
<span class="sd">                .module(</span>
<span class="sd">                    cls=LinearModule,</span>
<span class="sd">                    input_dim=32,</span>
<span class="sd">                    output_dim=4,</span>
<span class="sd">                )</span>
<span class="sd">                .trainer(max_epochs=5, accelerator=&quot;gpu&quot;)</span>
<span class="sd">                .fit_params(datamodule=datamodule)</span>
<span class="sd">                .checkpointing(monitor=&quot;loss&quot;, save_top_k=2, mode=&quot;min&quot;)</span>
<span class="sd">                .build()</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LightningConfigBuilder.__init__"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.__init__.html#ray.train.lightning.LightningConfigBuilder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Initialize the configurations with default values.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_class</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_init_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainer_init_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainer_fit_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_strategy_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_checkpoint_config</span> <span class="o">=</span> <span class="p">{}</span></div>

<div class="viewcode-block" id="LightningConfigBuilder.module"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.module.html#ray.train.lightning.LightningConfigBuilder.module">[docs]</a>    <span class="k">def</span> <span class="nf">module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="bp">cls</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LightningConfigBuilder&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Set up the Pytorch Lightning module class.</span>

<span class="sd">        Args:</span>
<span class="sd">            cls: A subclass of ``pytorch_lightning.LightningModule``</span>
<span class="sd">                that defines your model and training logic. Note that this is a</span>
<span class="sd">                class definition instead of a class instance.</span>
<span class="sd">            **kwargs: The initialization argument list of your lightning module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_class</span> <span class="o">=</span> <span class="bp">cls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_init_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LightningConfigBuilder.trainer"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.trainer.html#ray.train.lightning.LightningConfigBuilder.trainer">[docs]</a>    <span class="k">def</span> <span class="nf">trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LightningConfigBuilder&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Set up the configurations of ``pytorch_lightning.Trainer``.</span>

<span class="sd">        Note that you don&#39;t have to specify the `strategy` argument here since the</span>
<span class="sd">        ``LightningTrainer`` creates a PyTorch Lightning Strategy object with the</span>
<span class="sd">        configurations specified in the `.strategy()` method. If no configuration</span>
<span class="sd">        is specified, it creates a DDPStrategy by default.</span>

<span class="sd">        Args:</span>
<span class="sd">            kwargs: The initialization arguments for ``pytorch_lightning.Trainer``</span>
<span class="sd">                For valid arguments to pass, please refer to:</span>
<span class="sd">                https://lightning.ai/docs/pytorch/stable/common/trainer.html#init.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainer_init_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LightningConfigBuilder.fit_params"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.fit_params.html#ray.train.lightning.LightningConfigBuilder.fit_params">[docs]</a>    <span class="k">def</span> <span class="nf">fit_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LightningConfigBuilder&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The parameter lists for ``pytorch_lightning.Trainer.fit()``</span>

<span class="sd">        ``LightningTrainer`` creates a model instance with the parameters provided</span>
<span class="sd">        in `.module()` and feeds it into the ``pl.Trainer.fit()`` method.</span>
<span class="sd">        Therefore, you do not need to provide a model instance here.</span>

<span class="sd">        Args:</span>
<span class="sd">            kwargs: The parameter lists for ``pytorch_lightning.Trainer.fit()``</span>
<span class="sd">                For valid arguments to pass, please refer to:</span>
<span class="sd">                https://lightning.ai/docs/pytorch/stable/common/trainer.html#fit.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;You don&#39;t have to provide `model` argument in &quot;</span>
                <span class="s2">&quot;`LightningConfigBuilder.fit_params()`. LightningTrainer will create &quot;</span>
                <span class="s2">&quot;a model instance based on the parameters you provide in &quot;</span>
                <span class="s2">&quot;`LightningConfigBuilder..module()`.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_trainer_fit_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LightningConfigBuilder.strategy"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.strategy.html#ray.train.lightning.LightningConfigBuilder.strategy">[docs]</a>    <span class="k">def</span> <span class="nf">strategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ddp&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LightningConfigBuilder&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Set up the configurations of ``pytorch_lightning.strategies.Strategy``.</span>

<span class="sd">        Args:</span>
<span class="sd">            name: The name of your distributed strategy. You can choose</span>
<span class="sd">                from &quot;ddp&quot;, &quot;fsdp&quot;, and &quot;deepspeed&quot;. Default: &quot;ddp&quot;.</span>
<span class="sd">            kwargs: For valid arguments to pass, please refer to:</span>
<span class="sd">                https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.strategies.DDPStrategy.html</span>
<span class="sd">                ,</span>
<span class="sd">                https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.strategies.FSDPStrategy.html</span>
<span class="sd">                and</span>
<span class="sd">                https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.strategies.DeepSpeedStrategy.html</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;ddp&quot;</span><span class="p">,</span> <span class="s2">&quot;fsdp&quot;</span><span class="p">,</span> <span class="s2">&quot;deepspeed&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;LightningTrainer currently supports &#39;ddp&#39;, &#39;fsdp&#39;, and &#39;deepspeed&#39;&quot;</span>
                <span class="s2">&quot; strategy. Please choose one of them.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_strategy_config</span><span class="p">[</span><span class="s2">&quot;_strategy_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_strategy_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LightningConfigBuilder.checkpointing"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.checkpointing.html#ray.train.lightning.LightningConfigBuilder.checkpointing">[docs]</a>    <span class="k">def</span> <span class="nf">checkpointing</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LightningConfigBuilder&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Set up the configurations of ``pytorch_lightning.callbacks.ModelCheckpoint``.</span>

<span class="sd">        LightningTrainer creates a subclass instance of the `ModelCheckpoint` callback</span>
<span class="sd">        with the kwargs. It handles checkpointing and metrics logging logics.</span>

<span class="sd">        Specifically, the callback periodically reports the latest metrics</span>
<span class="sd">        and checkpoint to the AIR session via</span>
<span class="sd">        :meth:`session.report() &lt;ray.air.session.report&gt;`.</span>
<span class="sd">        The report frequency matches the checkpointing frequency here.</span>
<span class="sd">        You have to make sure that the target metrics (e.g. metrics defined in</span>
<span class="sd">        :class:`TuneConfig &lt;ray.tune.TuneConfig&gt;` or</span>
<span class="sd">        :class:`CheckpointConfig &lt;ray.air.config.CheckpointConfig&gt;`)</span>
<span class="sd">        are ready when a new checkpoint is being saved.</span>

<span class="sd">        Note that this method is not a replacement for the</span>
<span class="sd">        ``ray.air.configs.CheckpointConfig``. You still need to specify your</span>
<span class="sd">        AIR checkpointing strategy in ``CheckpointConfig``. Otherwise, AIR stores</span>
<span class="sd">        all the reported checkpoints by default.</span>

<span class="sd">        Args:</span>
<span class="sd">            kwargs: For valid arguments to pass, please refer to:</span>
<span class="sd">                https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_checkpoint_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LightningConfigBuilder.build"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningConfigBuilder.build.html#ray.train.lightning.LightningConfigBuilder.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="s2">&quot;str&quot;</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Build and return a config dictionary to pass into LightningTrainer.&quot;&quot;&quot;</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_class</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">isclass</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module_class</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;&#39;module_class&#39; must be a class, not a class instance.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module_class</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;&#39;module_class&#39; must be a subclass of &#39;pl.LightningModule&#39;!&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Avoid default key-value pair to adapt with Ray Tune scheduler.</span>
            <span class="n">config_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_module_class&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">config_dict</span></div></div>


<div class="viewcode-block" id="LightningTrainer"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningTrainer.html#ray.train.lightning.LightningTrainer">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LightningTrainer</span><span class="p">(</span><span class="n">TorchTrainer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A Trainer for data parallel PyTorch Lightning training.</span>

<span class="sd">    This Trainer runs the ``pytorch_lightning.Trainer.fit()`` method on multiple</span>
<span class="sd">    Ray Actors. The training is carried out in a distributed fashion through PyTorch</span>
<span class="sd">    DDP. These actors already have the necessary Torch process group configured for</span>
<span class="sd">    distributed data parallel training. We will support more distributed training</span>
<span class="sd">    strategies in the future.</span>

<span class="sd">    The training function ran on every Actor will first initialize an instance</span>
<span class="sd">    of the user-provided ``lightning_module`` class, which is a subclass of</span>
<span class="sd">    ``pytorch_lightning.LightningModule`` using the arguments provided in</span>
<span class="sd">    ``LightningConfigBuilder.module()``.</span>

<span class="sd">    For data ingestion, the LightningTrainer will then either convert the Dataset</span>
<span class="sd">    shards to a ``pytorch_lightning.LightningDataModule``, or directly use the</span>
<span class="sd">    datamodule or dataloaders if provided by users.</span>

<span class="sd">    The trainer also creates a ModelCheckpoint callback based on the configuration</span>
<span class="sd">    provided in ``LightningConfigBuilder.checkpointing()``. In addition to</span>
<span class="sd">    checkpointing, this callback also calls ``session.report()`` to report the</span>
<span class="sd">    latest metrics along with the checkpoint to the AIR session.</span>

<span class="sd">    For logging, users can continue to use Lightning&#39;s native loggers, such as</span>
<span class="sd">    WandbLogger, TensorboardLogger, etc. LightningTrainer will also log the latest</span>
<span class="sd">    metrics to the training results directory whenever a new checkpoint is saved.</span>

<span class="sd">    Then, the training function will initialize an instance of ``pl.Trainer``</span>
<span class="sd">    using the arguments provided in ``LightningConfigBuilder.fit_params()`` and then</span>
<span class="sd">    run ``pytorch_lightning.Trainer.fit``.</span>

<span class="sd">    Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            import torch</span>
<span class="sd">            import torch.nn.functional as F</span>
<span class="sd">            from torchmetrics import Accuracy</span>
<span class="sd">            from torch.utils.data import DataLoader, Subset</span>
<span class="sd">            from torchvision.datasets import MNIST</span>
<span class="sd">            from torchvision import transforms</span>
<span class="sd">            import pytorch_lightning as pl</span>
<span class="sd">            from ray.air.config import ScalingConfig</span>
<span class="sd">            from ray.train.lightning import LightningTrainer, LightningConfigBuilder</span>


<span class="sd">            class MNISTClassifier(pl.LightningModule):</span>
<span class="sd">                def __init__(self, lr, feature_dim):</span>
<span class="sd">                    super(MNISTClassifier, self).__init__()</span>
<span class="sd">                    self.fc1 = torch.nn.Linear(28 * 28, feature_dim)</span>
<span class="sd">                    self.fc2 = torch.nn.Linear(feature_dim, 10)</span>
<span class="sd">                    self.lr = lr</span>
<span class="sd">                    self.accuracy = Accuracy()</span>

<span class="sd">                def forward(self, x):</span>
<span class="sd">                    x = x.view(-1, 28 * 28)</span>
<span class="sd">                    x = torch.relu(self.fc1(x))</span>
<span class="sd">                    x = self.fc2(x)</span>
<span class="sd">                    return x</span>

<span class="sd">                def training_step(self, batch, batch_idx):</span>
<span class="sd">                    x, y = batch</span>
<span class="sd">                    y_hat = self(x)</span>
<span class="sd">                    loss = torch.nn.functional.cross_entropy(y_hat, y)</span>
<span class="sd">                    self.log(&quot;train_loss&quot;, loss)</span>
<span class="sd">                    return loss</span>

<span class="sd">                def validation_step(self, val_batch, batch_idx):</span>
<span class="sd">                    x, y = val_batch</span>
<span class="sd">                    logits = self.forward(x)</span>
<span class="sd">                    loss = F.nll_loss(logits, y)</span>
<span class="sd">                    acc = self.accuracy(logits, y)</span>
<span class="sd">                    return {&quot;val_loss&quot;: loss, &quot;val_accuracy&quot;: acc}</span>

<span class="sd">                def validation_epoch_end(self, outputs):</span>
<span class="sd">                    avg_loss = torch.stack([x[&quot;val_loss&quot;] for x in outputs]).mean()</span>
<span class="sd">                    avg_acc = torch.stack([x[&quot;val_accuracy&quot;] for x in outputs]).mean()</span>
<span class="sd">                    self.log(&quot;ptl/val_loss&quot;, avg_loss)</span>
<span class="sd">                    self.log(&quot;ptl/val_accuracy&quot;, avg_acc)</span>

<span class="sd">                def configure_optimizers(self):</span>
<span class="sd">                    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)</span>
<span class="sd">                    return optimizer</span>

<span class="sd">            # Prepare MNIST Datasets</span>
<span class="sd">            transform = transforms.Compose(</span>
<span class="sd">                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]</span>
<span class="sd">            )</span>
<span class="sd">            mnist_train = MNIST(</span>
<span class="sd">                &#39;./data&#39;, train=True, download=True, transform=transform</span>
<span class="sd">            )</span>
<span class="sd">            mnist_val = MNIST(</span>
<span class="sd">                &#39;./data&#39;, train=False, download=True, transform=transform</span>
<span class="sd">            )</span>

<span class="sd">            # Take small subsets for smoke test</span>
<span class="sd">            # Please remove these two lines if you want to train the full dataset</span>
<span class="sd">            mnist_train = Subset(mnist_train, range(1000))</span>
<span class="sd">            mnist_train = Subset(mnist_train, range(500))</span>

<span class="sd">            train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)</span>
<span class="sd">            val_loader = DataLoader(mnist_val, batch_size=128, shuffle=False)</span>

<span class="sd">            lightning_config = (</span>
<span class="sd">                LightningConfigBuilder()</span>
<span class="sd">                .module(cls=MNISTClassifier, lr=1e-3, feature_dim=128)</span>
<span class="sd">                .trainer(max_epochs=3, accelerator=&quot;cpu&quot;)</span>
<span class="sd">                .fit_params(train_dataloaders=train_loader, val_dataloaders=val_loader)</span>
<span class="sd">                .build()</span>
<span class="sd">            )</span>

<span class="sd">            scaling_config = ScalingConfig(</span>
<span class="sd">                num_workers=4, use_gpu=False, resources_per_worker={&quot;CPU&quot;: 1}</span>
<span class="sd">            )</span>
<span class="sd">            trainer = LightningTrainer(</span>
<span class="sd">                lightning_config=lightning_config,</span>
<span class="sd">                scaling_config=scaling_config,</span>
<span class="sd">            )</span>
<span class="sd">            result = trainer.fit()</span>
<span class="sd">            result</span>

<span class="sd">    Args:</span>
<span class="sd">        lightning_config: Configuration for setting up the Pytorch Lightning Trainer.</span>
<span class="sd">            You can setup the configurations with ``LightningConfigBuilder``, and</span>
<span class="sd">            generate this config dictionary through ``LightningBuilder.build()``.</span>
<span class="sd">        torch_config: Configuration for setting up the PyTorch backend. If set to</span>
<span class="sd">            None, use the default configuration. This replaces the ``backend_config``</span>
<span class="sd">            arg of ``DataParallelTrainer``. Same as in ``TorchTrainer``.</span>
<span class="sd">        scaling_config: Configuration for how to scale data parallel training.</span>
<span class="sd">        dataset_config: Configuration for dataset ingest.</span>
<span class="sd">        run_config: Configuration for the execution of the training run.</span>
<span class="sd">        datasets: A dictionary of Datasets to use for training.</span>
<span class="sd">            Use the key &quot;train&quot; to denote which dataset is the training</span>
<span class="sd">            dataset and (optionally) key &quot;val&quot; to denote the validation</span>
<span class="sd">            dataset. If a ``preprocessor`` is provided and has not already</span>
<span class="sd">            been fit, it will be fit on the training dataset. All datasets will be</span>
<span class="sd">            transformed by the ``preprocessor`` if one is provided.</span>
<span class="sd">        datasets_iter_config: Configurations for iterating over input Datasets.</span>
<span class="sd">            This configuration is only valid when `datasets` argument is provided to</span>
<span class="sd">            the LightningTrainer. Otherwise, LightningTrainer will use datamodule</span>
<span class="sd">            or dataloaders specified in ``LightningConfig.trainer_init_config``.</span>
<span class="sd">            For valid arguments to pass, please refer to:</span>
<span class="sd">            :py:meth:`Dataset.iter_torch_batches</span>
<span class="sd">            &lt;ray.data.Dataset.iter_torch_batches&gt;`</span>
<span class="sd">        preprocessor: A ray.data.Preprocessor to preprocess the</span>
<span class="sd">            provided datasets.</span>
<span class="sd">        resume_from_checkpoint: A checkpoint to resume training from.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lightning_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">torch_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TorchConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">scaling_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ScalingConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataset_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DatasetConfig</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">run_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RunConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">GenDataset</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">datasets_iter_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">preprocessor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Preprocessor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resume_from_checkpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Checkpoint</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">run_config</span> <span class="o">=</span> <span class="n">run_config</span> <span class="ow">or</span> <span class="n">RunConfig</span><span class="p">()</span>
        <span class="n">lightning_config</span> <span class="o">=</span> <span class="n">lightning_config</span> <span class="ow">or</span> <span class="n">LightningConfigBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_checkpoint_configs</span><span class="p">(</span>
            <span class="n">ptl_ckpt_config</span><span class="o">=</span><span class="n">lightning_config</span><span class="p">[</span><span class="s2">&quot;_model_checkpoint_config&quot;</span><span class="p">],</span>
            <span class="n">air_ckpt_config</span><span class="o">=</span><span class="n">run_config</span><span class="o">.</span><span class="n">checkpoint_config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Disable strict checking to prevent validation errors against metrics that</span>
        <span class="c1"># are reported at different frequencies. This works here because the Trainer</span>
        <span class="c1"># is always constructed on the same host as the Tuner.</span>
        <span class="c1"># TODO(yunxuanxiao): find a long term solution that doesn&#39;t involve setting a</span>
        <span class="c1"># environment variable globally.</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TUNE_DISABLE_STRICT_METRIC_CHECKING&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

        <span class="n">train_loop_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;lightning_config&quot;</span><span class="p">:</span> <span class="n">lightning_config</span><span class="p">,</span>
            <span class="s2">&quot;datasets_iter_config&quot;</span><span class="p">:</span> <span class="n">datasets_iter_config</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">LightningTrainer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">_lightning_train_loop_per_worker</span><span class="p">,</span>
            <span class="n">train_loop_config</span><span class="o">=</span><span class="n">train_loop_config</span><span class="p">,</span>
            <span class="n">torch_config</span><span class="o">=</span><span class="n">torch_config</span><span class="p">,</span>
            <span class="n">scaling_config</span><span class="o">=</span><span class="n">scaling_config</span><span class="p">,</span>
            <span class="n">dataset_config</span><span class="o">=</span><span class="n">dataset_config</span><span class="p">,</span>
            <span class="n">run_config</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span>
            <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
            <span class="n">preprocessor</span><span class="o">=</span><span class="n">preprocessor</span><span class="p">,</span>
            <span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="n">resume_from_checkpoint</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_checkpoint_configs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">ptl_ckpt_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">air_ckpt_config</span><span class="p">:</span> <span class="n">CheckpointConfig</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check if configs are set correctly&quot;&quot;&quot;</span>
        <span class="n">ptl_ckpt_metric</span> <span class="o">=</span> <span class="n">ptl_ckpt_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;monitor&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">air_ckpt_metric</span> <span class="o">=</span> <span class="n">air_ckpt_config</span><span class="o">.</span><span class="n">checkpoint_score_attribute</span>

        <span class="k">if</span> <span class="n">ptl_ckpt_metric</span> <span class="ow">and</span> <span class="n">air_ckpt_metric</span> <span class="ow">and</span> <span class="n">ptl_ckpt_metric</span> <span class="o">!=</span> <span class="n">air_ckpt_metric</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;You have specified different metrics to track in AIR &quot;</span>
                <span class="s2">&quot;`CheckpointConfig` and Lightning ModelCheckpoint. &quot;</span>
                <span class="s2">&quot;Make sure that you have logged both metrics before &quot;</span>
                <span class="s2">&quot;a checkpoint is created.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">air_ckpt_config</span><span class="o">.</span><span class="n">checkpoint_frequency</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="ow">or</span> <span class="n">air_ckpt_config</span><span class="o">.</span><span class="n">checkpoint_at_end</span>
        <span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Attrributes `checkpoint_frequency` and `checkpoint_at_end` will not &quot;</span>
                <span class="s2">&quot;be used in `LightningTrainer`! Please set up checkpoint frequency &quot;</span>
                <span class="s2">&quot;through `LightningConfigBuilder.checkpointing()`.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="LightningTrainer.restore"><a class="viewcode-back" href="../../../../train/api/doc/ray.train.lightning.LightningTrainer.restore.html#ray.train.lightning.LightningTrainer.restore">[docs]</a>    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">restore</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="s2">&quot;LightningTrainer&quot;</span><span class="p">],</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">datasets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">GenDataset</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">preprocessor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Preprocessor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">scaling_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ScalingConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LightningTrainer&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Restores a LightningTrainer from a previously interrupted/failed run.</span>

<span class="sd">        See :meth:`BaseTrainer.restore() &lt;ray.train.trainer.BaseTrainer.restore&gt;`</span>
<span class="sd">        for descriptions of the arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            LightningTrainer: A restored instance of `LightningTrainer`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">LightningTrainer</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
            <span class="n">preprocessor</span><span class="o">=</span><span class="n">preprocessor</span><span class="p">,</span>
            <span class="n">scaling_config</span><span class="o">=</span><span class="n">scaling_config</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">_lightning_train_loop_per_worker</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Per-worker training loop for a Lightning Trainer.&quot;&quot;&quot;</span>
    <span class="c1"># Change the working directory for all workers to the same directory.</span>
    <span class="c1"># This aligns with Lightning&#39;s settings and avoids inconsistency. Otherwise,</span>
    <span class="c1"># each worker will have a different log and checkpoint directory if they are</span>
    <span class="c1"># using relative paths.</span>
    <span class="n">working_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">session</span><span class="o">.</span><span class="n">get_trial_dir</span><span class="p">(),</span> <span class="s2">&quot;rank_all&quot;</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">working_dir</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lightning_config&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;&#39;lightning_config&#39; not specified in LightningTrainer!&quot;</span><span class="p">)</span>

    <span class="c1"># Unpack all configs</span>
    <span class="n">ptl_config</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lightning_config&quot;</span><span class="p">]</span>
    <span class="n">datasets_iter_config</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;datasets_iter_config&quot;</span><span class="p">]</span>
    <span class="n">trainer_config</span> <span class="o">=</span> <span class="n">ptl_config</span><span class="p">[</span><span class="s2">&quot;_trainer_init_config&quot;</span><span class="p">]</span>
    <span class="n">trainer_fit_params</span> <span class="o">=</span> <span class="n">ptl_config</span><span class="p">[</span><span class="s2">&quot;_trainer_fit_params&quot;</span><span class="p">]</span>
    <span class="n">module_class</span> <span class="o">=</span> <span class="n">ptl_config</span><span class="p">[</span><span class="s2">&quot;_module_class&quot;</span><span class="p">]</span>
    <span class="n">module_init_config</span> <span class="o">=</span> <span class="n">ptl_config</span><span class="p">[</span><span class="s2">&quot;_module_init_config&quot;</span><span class="p">]</span>
    <span class="n">strategy_config</span> <span class="o">=</span> <span class="n">ptl_config</span><span class="p">[</span><span class="s2">&quot;_strategy_config&quot;</span><span class="p">]</span>
    <span class="n">strategy_name</span> <span class="o">=</span> <span class="n">strategy_config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_strategy_name&quot;</span><span class="p">,</span> <span class="s2">&quot;ddp&quot;</span><span class="p">)</span>
    <span class="n">model_checkpoint_config</span> <span class="o">=</span> <span class="n">ptl_config</span><span class="p">[</span><span class="s2">&quot;_model_checkpoint_config&quot;</span><span class="p">]</span>

    <span class="c1"># Prepare data</span>
    <span class="n">datamodule</span> <span class="o">=</span> <span class="n">trainer_fit_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;datamodule&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">train_dataloaders</span> <span class="o">=</span> <span class="n">trainer_fit_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_dataloaders&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">train_ray_dataset</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">val_ray_dataset</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">train_dataloaders</span> <span class="ow">or</span> <span class="n">datamodule</span> <span class="ow">or</span> <span class="n">train_ray_dataset</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;Please provide at least one of the following data inputs: &quot;</span>
            <span class="s2">&quot;train_dataloaders, datamodule, or Datasets with key &#39;train&#39;.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">train_ray_dataset</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">datamodule</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Using Datasets as primary input. The &#39;datamodule&#39; defined in &quot;</span>
                <span class="s2">&quot;&#39;LightningConfig.trainer_fit_params&#39; is ignored!&quot;</span>
            <span class="p">)</span>

        <span class="n">trainer_fit_params</span><span class="p">[</span><span class="s2">&quot;datamodule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">RayDataModule</span><span class="p">(</span>
            <span class="n">dataset_iter_config</span><span class="o">=</span><span class="n">datasets_iter_config</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_ray_dataset</span><span class="p">,</span>
            <span class="n">val_dataset</span><span class="o">=</span><span class="n">val_ray_dataset</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Prepare Lightning Module</span>
    <span class="n">lightning_module</span> <span class="o">=</span> <span class="n">module_class</span><span class="p">(</span><span class="o">**</span><span class="n">module_init_config</span><span class="p">)</span>

    <span class="c1"># Prepare Lightning Trainer</span>
    <span class="c1"># Setup trainer&#39;s parallel devices</span>
    <span class="k">if</span> <span class="n">trainer_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;accelerator&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;gpu&quot;</span><span class="p">:</span>
        <span class="n">current_device</span> <span class="o">=</span> <span class="n">get_worker_root_device</span><span class="p">()</span>
        <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;devices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">current_device</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>

    <span class="c1"># Setup ray cluster environment info</span>
    <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;plugins&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">plugin</span>
        <span class="k">for</span> <span class="n">plugin</span> <span class="ow">in</span> <span class="n">trainer_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;plugins&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">plugin</span><span class="p">,</span> <span class="n">ClusterEnvironment</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;plugins&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">RayEnvironment</span><span class="p">())</span>

    <span class="c1"># Setup ddp strategy for ray orchestration</span>
    <span class="k">if</span> <span class="s2">&quot;strategy&quot;</span> <span class="ow">in</span> <span class="n">trainer_config</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;`strategy` specified in `LightningConfig.trainer_init_config` &quot;</span>
            <span class="s2">&quot;will be ignored. LightningTrainer will create a strategy based on &quot;</span>
            <span class="s2">&quot;the settings passed into `LightningConfigBuilder.strategy()`.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">strategy_name</span> <span class="o">==</span> <span class="s2">&quot;ddp&quot;</span><span class="p">:</span>
        <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">RayDDPStrategy</span><span class="p">(</span><span class="o">**</span><span class="n">strategy_config</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">strategy_name</span> <span class="o">==</span> <span class="s2">&quot;fsdp&quot;</span><span class="p">:</span>
        <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">RayFSDPStrategy</span><span class="p">(</span><span class="o">**</span><span class="n">strategy_config</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">strategy_name</span> <span class="o">==</span> <span class="s2">&quot;deepspeed&quot;</span><span class="p">:</span>
        <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">RayDeepSpeedStrategy</span><span class="p">(</span><span class="o">**</span><span class="n">strategy_config</span><span class="p">)</span>

    <span class="c1"># LightningTrainer always requires checkpointing</span>
    <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;enable_checkpointing&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">model_checkpoint_config</span><span class="p">[</span><span class="s2">&quot;save_last&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">trainer_config</span><span class="p">[</span><span class="s2">&quot;callbacks&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainer_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;callbacks&quot;</span><span class="p">,</span> <span class="p">[])</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">RayModelCheckpoint</span><span class="p">(</span><span class="o">**</span><span class="n">model_checkpoint_config</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="o">**</span><span class="n">trainer_config</span><span class="p">)</span>

    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_checkpoint</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">checkpoint</span><span class="p">:</span>
        <span class="n">checkpoint_log_message</span> <span class="o">=</span> <span class="s2">&quot;Resuming training from an AIR checkpoint.&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;ckpt_path&quot;</span> <span class="ow">in</span> <span class="n">trainer_fit_params</span><span class="p">:</span>
            <span class="n">checkpoint_log_message</span> <span class="o">+=</span> <span class="s2">&quot; `ckpt_path` will be ignored.&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">checkpoint_log_message</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
            <span class="n">trainer_fit_params</span><span class="p">[</span><span class="s2">&quot;ckpt_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ckpt_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">MODEL_KEY</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">lightning_module</span><span class="p">,</span> <span class="o">**</span><span class="n">trainer_fit_params</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">lightning_module</span><span class="p">,</span> <span class="o">**</span><span class="n">trainer_fit_params</span><span class="p">)</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>