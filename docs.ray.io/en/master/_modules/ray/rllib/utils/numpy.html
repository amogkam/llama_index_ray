
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.rllib.utils.numpy &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/versionwarning.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../../_static/js/docsearch.js"></script>
    <script src="../../../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../../_static/js/top-navigation.js"></script>
    <script src="../../../../_static/js/tags.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/rllib/utils/numpy.html" />
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "_modules/ray/rllib/utils/numpy", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/rllib/utils/numpy.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.rllib.utils.numpy</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">gymnasium.spaces</span> <span class="kn">import</span> <span class="n">Discrete</span><span class="p">,</span> <span class="n">MultiDiscrete</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tree</span>  <span class="c1"># pip install dm_tree</span>
<span class="kn">from</span> <span class="nn">types</span> <span class="kn">import</span> <span class="n">MappingProxyType</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span>


<span class="kn">from</span> <span class="nn">ray.rllib.utils.annotations</span> <span class="kn">import</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.deprecation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
    <span class="n">deprecation_warning</span><span class="p">,</span>
    <span class="n">Deprecated</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.framework</span> <span class="kn">import</span> <span class="n">try_import_tf</span><span class="p">,</span> <span class="n">try_import_torch</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.typing</span> <span class="kn">import</span> <span class="n">SpaceStruct</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorStructType</span><span class="p">,</span> <span class="n">Union</span>

<span class="n">tf1</span><span class="p">,</span> <span class="n">tf</span><span class="p">,</span> <span class="n">tfv</span> <span class="o">=</span> <span class="n">try_import_tf</span><span class="p">()</span>
<span class="n">torch</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">try_import_torch</span><span class="p">()</span>

<span class="n">SMALL_NUMBER</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="c1"># Some large int number. May be increased here, if needed.</span>
<span class="n">LARGE_INTEGER</span> <span class="o">=</span> <span class="mi">100000000</span>
<span class="c1"># Min and Max outputs (clipped) from an NN-output layer interpreted as the</span>
<span class="c1"># log(x) of some x (e.g. a stddev of a normal</span>
<span class="c1"># distribution).</span>
<span class="n">MIN_LOG_NN_OUTPUT</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span>
<span class="n">MAX_LOG_NN_OUTPUT</span> <span class="o">=</span> <span class="mi">2</span>


<span class="nd">@PublicAPI</span>
<span class="nd">@Deprecated</span><span class="p">(</span>
    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;RLlib itself has no use for this anymore.&quot;</span><span class="p">,</span>
    <span class="n">error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">aligned_array</span><span class="p">(</span><span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Returns an array of a given size that is 64-byte aligned.</span>

<span class="sd">    The returned array can be efficiently copied into GPU memory by TensorFlow.</span>

<span class="sd">    Args:</span>
<span class="sd">        size: The size (total number of items) of the array. For example,</span>
<span class="sd">            array([[0.0, 1.0], [2.0, 3.0]]) would have size=4.</span>
<span class="sd">        dtype: The numpy dtype of the array.</span>
<span class="sd">        align: The alignment to use.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A np.ndarray with the given specifications.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">size</span> <span class="o">*</span> <span class="n">dtype</span><span class="o">.</span><span class="n">itemsize</span>
    <span class="n">empty</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="p">(</span><span class="n">align</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="n">data_align</span> <span class="o">=</span> <span class="n">empty</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">data</span> <span class="o">%</span> <span class="n">align</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">data_align</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="n">align</span> <span class="o">-</span> <span class="n">data_align</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># stop np from optimising out empty slice reference</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">empty</span><span class="p">[</span><span class="n">offset</span> <span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">empty</span><span class="p">[</span><span class="n">offset</span> <span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">==</span> <span class="n">size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">data</span> <span class="o">%</span> <span class="n">align</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">data</span>
    <span class="k">return</span> <span class="n">output</span>


<span class="nd">@PublicAPI</span>
<span class="nd">@Deprecated</span><span class="p">(</span>
    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;RLlib itself has no use for this anymore.&quot;</span><span class="p">,</span>
    <span class="n">error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">concat_aligned</span><span class="p">(</span>
    <span class="n">items</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">time_major</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Concatenate arrays, ensuring the output is 64-byte aligned.</span>

<span class="sd">    We only align float arrays; other arrays are concatenated as normal.</span>

<span class="sd">    This should be used instead of np.concatenate() to improve performance</span>
<span class="sd">    when the output array is likely to be fed into TensorFlow.</span>

<span class="sd">    Args:</span>
<span class="sd">        items: The list of items to concatenate and align.</span>
<span class="sd">        time_major: Whether the data in items is time-major, in which</span>
<span class="sd">            case, we will concatenate along axis=1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The concat&#39;d and aligned array.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># we assume the input is aligned. In any case, it doesn&#39;t help</span>
        <span class="c1"># performance to force align it since that incurs a needless copy.</span>
        <span class="k">return</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
    <span class="p">]:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">flat</span> <span class="o">=</span> <span class="n">aligned_array</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">size</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">items</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">time_major</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">time_major</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">batch_dim</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">items</span><span class="p">)</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_dim</span><span class="p">,)</span> <span class="o">+</span> <span class="n">items</span><span class="p">[</span>
                    <span class="mi">0</span>
                <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_dim</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">items</span><span class="p">)</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span> <span class="o">+</span> <span class="n">items</span><span class="p">[</span>
                    <span class="mi">0</span>
                <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_dim</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">items</span><span class="p">)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_dim</span><span class="p">,)</span> <span class="o">+</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">flat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">data</span> <span class="o">%</span> <span class="mi">64</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">data</span>
        <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">time_major</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">time_major</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>


<div class="viewcode-block" id="convert_to_numpy"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.convert_to_numpy.html#ray.rllib.utils.numpy.convert_to_numpy">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">convert_to_numpy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">TensorStructType</span><span class="p">,</span> <span class="n">reduce_type</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">reduce_floats</span><span class="o">=</span><span class="n">DEPRECATED_VALUE</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts values in `stats` to non-Tensor numpy or python types.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: Any (possibly nested) struct, the values in which will be</span>
<span class="sd">            converted and returned as a new struct with all torch/tf tensors</span>
<span class="sd">            being converted to numpy types.</span>
<span class="sd">        reduce_type: Whether to automatically reduce all float64 and int64 data</span>
<span class="sd">            into float32 and int32 data, respectively.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A new struct with the same structure as `x`, but with all</span>
<span class="sd">        values converted to numpy arrays (on CPU).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">reduce_floats</span> <span class="o">!=</span> <span class="n">DEPRECATED_VALUE</span><span class="p">:</span>
        <span class="n">deprecation_warning</span><span class="p">(</span><span class="n">old</span><span class="o">=</span><span class="s2">&quot;reduce_floats&quot;</span><span class="p">,</span> <span class="n">new</span><span class="o">=</span><span class="s2">&quot;reduce_types&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">reduce_type</span> <span class="o">=</span> <span class="n">reduce_floats</span>

    <span class="c1"># The mapping function used to numpyize torch/tf Tensors (and move them</span>
    <span class="c1"># to the CPU beforehand).</span>
    <span class="k">def</span> <span class="nf">mapping</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">torch</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">item</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="k">else</span> <span class="n">item</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="n">tf</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s2">&quot;numpy&quot;</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">assert</span> <span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">()</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="n">item</span>
        <span class="k">if</span> <span class="n">reduce_type</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">ret</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">):</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">ret</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">return</span> <span class="n">tree</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">mapping</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="fc"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.fc.html#ray.rllib.utils.numpy.fc">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">fc</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">biases</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">framework</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Calculates FC (dense) layer outputs given weights/biases and input.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input to the dense layer.</span>
<span class="sd">        weights: The weights matrix.</span>
<span class="sd">        biases: The biases vector. All 0s if None.</span>
<span class="sd">        framework: An optional framework hint (to figure out,</span>
<span class="sd">            e.g. whether to transpose torch weight matrices).</span>

<span class="sd">    Returns:</span>
<span class="sd">        The dense layer&#39;s output.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">map_</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">tf</span> <span class="ow">and</span> <span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">transpose</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">map_</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Torch stores matrices in transpose (faster for backprop).</span>
    <span class="n">transpose</span> <span class="o">=</span> <span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">map_</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="n">transpose</span><span class="p">)</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="n">map_</span><span class="p">(</span><span class="n">biases</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.0</span> <span class="k">if</span> <span class="n">biases</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">biases</span><span class="p">)</span></div>


<div class="viewcode-block" id="flatten_inputs_to_1d_tensor"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor.html#ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">flatten_inputs_to_1d_tensor</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorStructType</span><span class="p">,</span>
    <span class="n">spaces_struct</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SpaceStruct</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">time_axis</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Flattens arbitrary input structs according to the given spaces struct.</span>

<span class="sd">    Returns a single 1D tensor resulting from the different input</span>
<span class="sd">    components&#39; values.</span>

<span class="sd">    Thereby:</span>
<span class="sd">    - Boxes (any shape) get flattened to (B, [T]?, -1). Note that image boxes</span>
<span class="sd">    are not treated differently from other types of Boxes and get</span>
<span class="sd">    flattened as well.</span>
<span class="sd">    - Discrete (int) values are one-hot&#39;d, e.g. a batch of [1, 0, 3] (B=3 with</span>
<span class="sd">    Discrete(4) space) results in [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1]].</span>
<span class="sd">    - MultiDiscrete values are multi-one-hot&#39;d, e.g. a batch of</span>
<span class="sd">    [[0, 2], [1, 4]] (B=2 with MultiDiscrete([2, 5]) space) results in</span>
<span class="sd">    [[1, 0,  0, 0, 1, 0, 0], [0, 1,  0, 0, 0, 0, 1]].</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: The inputs to be flattened.</span>
<span class="sd">        spaces_struct: The structure of the spaces that behind the input</span>
<span class="sd">        time_axis: Whether all inputs have a time-axis (after the batch axis).</span>
<span class="sd">            If True, will keep not only the batch axis (0th), but the time axis</span>
<span class="sd">            (1st) as-is and flatten everything from the 2nd axis up.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A single 1D tensor resulting from concatenating all</span>
<span class="sd">        flattened/one-hot&#39;d input components. Depending on the time_axis flag,</span>
<span class="sd">        the shape is (B, n) or (B, T, n).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # B=2</span>
<span class="sd">        &gt;&gt;&gt; from ray.rllib.utils.tf_utils import flatten_inputs_to_1d_tensor</span>
<span class="sd">        &gt;&gt;&gt; from gymnasium.spaces import Discrete, Box</span>
<span class="sd">        &gt;&gt;&gt; out = flatten_inputs_to_1d_tensor( # doctest: +SKIP</span>
<span class="sd">        ...     {&quot;a&quot;: [1, 0], &quot;b&quot;: [[[0.0], [0.1]], [1.0], [1.1]]},</span>
<span class="sd">        ...     spaces_struct=dict(a=Discrete(2), b=Box(shape=(2, 1)))</span>
<span class="sd">        ... ) # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; print(out) # doctest: +SKIP</span>
<span class="sd">        [[0.0, 1.0,  0.0, 0.1], [1.0, 0.0,  1.0, 1.1]]  # B=2 n=4</span>

<span class="sd">        &gt;&gt;&gt; # B=2; T=2</span>
<span class="sd">        &gt;&gt;&gt; out = flatten_inputs_to_1d_tensor( # doctest: +SKIP</span>
<span class="sd">        ...     ([[1, 0], [0, 1]],</span>
<span class="sd">        ...      [[[0.0, 0.1], [1.0, 1.1]], [[2.0, 2.1], [3.0, 3.1]]]),</span>
<span class="sd">        ...     spaces_struct=tuple([Discrete(2), Box(shape=(2, ))]),</span>
<span class="sd">        ...     time_axis=True</span>
<span class="sd">        ... ) # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; print(out) # doctest: +SKIP</span>
<span class="sd">        [[[0.0, 1.0, 0.0, 0.1], [1.0, 0.0, 1.0, 1.1]],\</span>
<span class="sd">        [[1.0, 0.0, 2.0, 2.1], [0.0, 1.0, 3.0, 3.1]]]  # B=2 T=2 n=4</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">flat_inputs</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">flat_spaces</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tree</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">spaces_struct</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">spaces_struct</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">flat_inputs</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">B</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">T</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">input_</span><span class="p">,</span> <span class="n">space</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">flat_inputs</span><span class="p">,</span> <span class="n">flat_spaces</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>

        <span class="c1"># Store batch and (if applicable) time dimension.</span>
        <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">B</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">time_axis</span><span class="p">:</span>
                <span class="n">T</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># One-hot encoding.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">Discrete</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">time_axis</span><span class="p">:</span>
                <span class="n">input_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="p">[</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">])</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_hot</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">space</span><span class="o">.</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="c1"># Multi one-hot encoding.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">space</span><span class="p">,</span> <span class="n">MultiDiscrete</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">time_axis</span><span class="p">:</span>
                <span class="n">input_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="p">[</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">one_hot</span><span class="p">(</span><span class="n">input_</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">depth</span><span class="o">=</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">space</span><span class="o">.</span><span class="n">nvec</span><span class="p">)</span>
                    <span class="p">],</span>
                    <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="c1"># Box: Flatten.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">time_axis</span><span class="p">:</span>
                <span class="n">input_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="p">[</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="p">[</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="n">merged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Restore the time-dimension, if applicable.</span>
    <span class="k">if</span> <span class="n">time_axis</span><span class="p">:</span>
        <span class="n">merged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">merged</span><span class="p">,</span> <span class="p">[</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">merged</span></div>


<div class="viewcode-block" id="make_action_immutable"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.make_action_immutable.html#ray.rllib.utils.numpy.make_action_immutable">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">make_action_immutable</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Flags actions immutable to notify users when trying to change them.</span>

<span class="sd">    Can also be used with any tree-like structure containing either</span>
<span class="sd">    dictionaries, numpy arrays or already immutable objects per se.</span>
<span class="sd">    Note, however that `tree.map_structure()` will in general not</span>
<span class="sd">    include the shallow object containing all others and therefore</span>
<span class="sd">    immutability will hold only for all objects contained in it.</span>
<span class="sd">    Use `tree.traverse(fun, action, top_down=False)` to include</span>
<span class="sd">    also the containing object.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj: The object to be made immutable.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The immutable object.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import tree</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from ray.rllib.utils.numpy import make_action_immutable</span>
<span class="sd">        &gt;&gt;&gt; arr = np.arange(1,10)</span>
<span class="sd">        &gt;&gt;&gt; d = dict(a = 1, b = (arr, arr))</span>
<span class="sd">        &gt;&gt;&gt; tree.traverse(make_action_immutable, d, top_down=False) # doctest: +SKIP</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">setflags</span><span class="p">(</span><span class="n">write</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obj</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MappingProxyType</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MappingProxyType</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">obj</span></div>


<div class="viewcode-block" id="huber_loss"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.huber_loss.html#ray.rllib.utils.numpy.huber_loss">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">huber_loss</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">delta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Reference: https://en.wikipedia.org/wiki/Huber_loss.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">delta</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">delta</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="l2_loss"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.l2_loss.html#ray.rllib.utils.numpy.l2_loss">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">l2_loss</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Computes half the L2 norm of a tensor (w/o the sqrt): sum(x**2) / 2.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The l2-loss output according to the above formula given `x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.0</span></div>


<div class="viewcode-block" id="lstm"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.lstm.html#ray.rllib.utils.numpy.lstm">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">lstm</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">biases</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_internal_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">time_major</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">forget_bias</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates LSTM layer output given weights/biases, states, and input.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The inputs to the LSTM layer including time-rank</span>
<span class="sd">            (0th if time-major, else 1st) and the batch-rank</span>
<span class="sd">            (1st if time-major, else 0th).</span>
<span class="sd">        weights: The weights matrix.</span>
<span class="sd">        biases: The biases vector. All 0s if None.</span>
<span class="sd">        initial_internal_states: The initial internal</span>
<span class="sd">            states to pass into the layer. All 0s if None.</span>
<span class="sd">        time_major: Whether to use time-major or not. Default: False.</span>
<span class="sd">        forget_bias: Gets added to first sigmoid (forget gate) output.</span>
<span class="sd">            Default: 1.0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple consisting of 1) The LSTM layer&#39;s output and</span>
<span class="sd">        2) Tuple: Last (c-state, h-state).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">time_major</span> <span class="k">else</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">time_major</span> <span class="k">else</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">units</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span>  <span class="c1"># 4 internal layers (3x sigmoid, 1x tanh)</span>

    <span class="k">if</span> <span class="n">initial_internal_states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">c_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">units</span><span class="p">))</span>
        <span class="n">h_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">units</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">c_states</span> <span class="o">=</span> <span class="n">initial_internal_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">h_states</span> <span class="o">=</span> <span class="n">initial_internal_states</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Create a placeholder for all n-time step outputs.</span>
    <span class="k">if</span> <span class="n">time_major</span><span class="p">:</span>
        <span class="n">unrolled_outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">units</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">unrolled_outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">units</span><span class="p">))</span>

    <span class="c1"># Push the batch 4 times through the LSTM cell and capture the outputs plus</span>
    <span class="c1"># the final h- and c-states.</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">input_matrix</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="k">if</span> <span class="n">time_major</span> <span class="k">else</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">input_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">input_matrix</span><span class="p">,</span> <span class="n">h_states</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">input_matmul_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_matrix</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
        <span class="c1"># Forget gate (3rd slot in tf output matrix). Add static forget bias.</span>
        <span class="n">sigmoid_1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">input_matmul_matrix</span><span class="p">[:,</span> <span class="n">units</span> <span class="o">*</span> <span class="mi">2</span> <span class="p">:</span> <span class="n">units</span> <span class="o">*</span> <span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="n">forget_bias</span><span class="p">)</span>
        <span class="n">c_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">c_states</span><span class="p">,</span> <span class="n">sigmoid_1</span><span class="p">)</span>
        <span class="c1"># Add gate (1st and 2nd slots in tf output matrix).</span>
        <span class="n">sigmoid_2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">input_matmul_matrix</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">units</span><span class="p">])</span>
        <span class="n">tanh_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">input_matmul_matrix</span><span class="p">[:,</span> <span class="n">units</span> <span class="p">:</span> <span class="n">units</span> <span class="o">*</span> <span class="mi">2</span><span class="p">])</span>
        <span class="n">c_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">c_states</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">sigmoid_2</span><span class="p">,</span> <span class="n">tanh_3</span><span class="p">))</span>
        <span class="c1"># Output gate (last slot in tf output matrix).</span>
        <span class="n">sigmoid_4</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">input_matmul_matrix</span><span class="p">[:,</span> <span class="n">units</span> <span class="o">*</span> <span class="mi">3</span> <span class="p">:</span> <span class="n">units</span> <span class="o">*</span> <span class="mi">4</span><span class="p">])</span>
        <span class="n">h_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">sigmoid_4</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">c_states</span><span class="p">))</span>

        <span class="c1"># Store this output time-slice.</span>
        <span class="k">if</span> <span class="n">time_major</span><span class="p">:</span>
            <span class="n">unrolled_outputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">h_states</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">unrolled_outputs</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">h_states</span>

    <span class="k">return</span> <span class="n">unrolled_outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">c_states</span><span class="p">,</span> <span class="n">h_states</span><span class="p">)</span></div>


<div class="viewcode-block" id="one_hot"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.one_hot.html#ray.rllib.utils.numpy.one_hot">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">on_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">off_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;One-hot utility function for numpy.</span>

<span class="sd">    Thanks to qianyizhang:</span>
<span class="sd">    https://gist.github.com/qianyizhang/07ee1c15cad08afb03f5de69349efc30.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input to be one-hot encoded.</span>
<span class="sd">        depth: The max. number to be one-hot encoded (size of last rank).</span>
<span class="sd">        on_value: The value to use for on. Default: 1.0.</span>
<span class="sd">        off_value: The value to use for off. Default: 0.0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The one-hot encoded equivalent of the input array.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Handle simple ints properly.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="c1"># Handle torch arrays properly.</span>
    <span class="k">elif</span> <span class="n">torch</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="c1"># Handle bool arrays correctly.</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">)</span>
        <span class="n">depth</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="c1"># If depth is not given, try to infer it from the values in the array.</span>
    <span class="k">if</span> <span class="n">depth</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">depth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">depth</span>
    <span class="p">),</span> <span class="s2">&quot;ERROR: The max. index of `x` (</span><span class="si">{}</span><span class="s2">) is larger than depth (</span><span class="si">{}</span><span class="s2">)!&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">depth</span>
    <span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># Python 2.7 compatibility, (*shape, depth) is not allowed.</span>
    <span class="n">shape_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">[:])</span>
    <span class="n">shape_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">depth</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape_list</span><span class="p">)</span> <span class="o">*</span> <span class="n">off_value</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">tiles</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span>
        <span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tiles</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">tiles</span><span class="p">)</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
    <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">indices</span><span class="p">)]</span> <span class="o">=</span> <span class="n">on_value</span>
    <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="relu"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.relu.html#ray.rllib.utils.numpy.relu">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Implementation of the leaky ReLU function.</span>

<span class="sd">    y = x * alpha if x &lt; 0 else x</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input values.</span>
<span class="sd">        alpha: A scaling (&quot;leak&quot;) factor to use for negative x.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The leaky ReLU output for x.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="sigmoid"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.sigmoid.html#ray.rllib.utils.numpy.sigmoid">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">derivative</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the sigmoid function applied to x.</span>
<span class="sd">    Alternatively, can return the derivative or the sigmoid function.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input to the sigmoid function.</span>
<span class="sd">        derivative: Whether to return the derivative or not.</span>
<span class="sd">            Default: False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The sigmoid function (or its derivative) applied to x.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">derivative</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span></div>


<div class="viewcode-block" id="softmax"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.softmax.html#ray.rllib.utils.numpy.softmax">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">],</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Returns the softmax values for x.</span>

<span class="sd">    The exact formula used is:</span>
<span class="sd">    S(xi) = e^xi / SUMj(e^xj), where j goes over all elements in x.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input to the softmax function.</span>
<span class="sd">        axis: The axis along which to softmax.</span>
<span class="sd">        epsilon: Optional epsilon as a minimum value. If None, use</span>
<span class="sd">            `SMALL_NUMBER`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The softmax over x.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="ow">or</span> <span class="n">SMALL_NUMBER</span>
    <span class="c1"># x_exp = np.maximum(np.exp(x), SMALL_NUMBER)</span>
    <span class="n">x_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># return x_exp /</span>
    <span class="c1">#   np.maximum(np.sum(x_exp, axis, keepdims=True), SMALL_NUMBER)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">x_exp</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x_exp</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">epsilon</span><span class="p">)</span></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>