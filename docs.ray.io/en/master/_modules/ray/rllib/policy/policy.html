
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.rllib.policy.policy &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/versionwarning.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../../_static/js/docsearch.js"></script>
    <script src="../../../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../../_static/js/top-navigation.js"></script>
    <script src="../../../../_static/js/tags.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/rllib/policy/policy.html" />
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "_modules/ray/rllib/policy/policy", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/rllib/policy/policy.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.rllib.policy.policy</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Container</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Mapping</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tree</span>  <span class="c1"># pip install dm_tree</span>
<span class="kn">from</span> <span class="nn">gymnasium.spaces</span> <span class="kn">import</span> <span class="n">Box</span>
<span class="kn">from</span> <span class="nn">packaging</span> <span class="kn">import</span> <span class="n">version</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.cloudpickle</span> <span class="k">as</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">ray.actor</span> <span class="kn">import</span> <span class="n">ActorHandle</span>
<span class="kn">from</span> <span class="nn">ray.air.checkpoint</span> <span class="kn">import</span> <span class="n">Checkpoint</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models.action_dist</span> <span class="kn">import</span> <span class="n">ActionDistribution</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models.catalog</span> <span class="kn">import</span> <span class="n">ModelCatalog</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models.modelv2</span> <span class="kn">import</span> <span class="n">ModelV2</span>
<span class="kn">from</span> <span class="nn">ray.rllib.policy.sample_batch</span> <span class="kn">import</span> <span class="n">SampleBatch</span>
<span class="kn">from</span> <span class="nn">ray.rllib.policy.view_requirement</span> <span class="kn">import</span> <span class="n">ViewRequirement</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.annotations</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DeveloperAPI</span><span class="p">,</span>
    <span class="n">ExperimentalAPI</span><span class="p">,</span>
    <span class="n">OverrideToImplementCustomLogic</span><span class="p">,</span>
    <span class="n">OverrideToImplementCustomLogic_CallToSuperRecommended</span><span class="p">,</span>
    <span class="n">is_overridden</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.checkpoints</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CHECKPOINT_VERSION</span><span class="p">,</span>
    <span class="n">get_checkpoint_info</span><span class="p">,</span>
    <span class="n">try_import_msgpack</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.deprecation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Deprecated</span><span class="p">,</span>
    <span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
    <span class="n">deprecation_warning</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.exploration.exploration</span> <span class="kn">import</span> <span class="n">Exploration</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.framework</span> <span class="kn">import</span> <span class="n">try_import_tf</span><span class="p">,</span> <span class="n">try_import_torch</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.from_config</span> <span class="kn">import</span> <span class="n">from_config</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.nested_dict</span> <span class="kn">import</span> <span class="n">NestedDict</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.numpy</span> <span class="kn">import</span> <span class="n">convert_to_numpy</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.serialization</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">deserialize_type</span><span class="p">,</span>
    <span class="n">space_from_dict</span><span class="p">,</span>
    <span class="n">space_to_dict</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.spaces.space_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_base_struct_from_space</span><span class="p">,</span>
    <span class="n">get_dummy_batch_for_space</span><span class="p">,</span>
    <span class="n">unbatch</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.tf_utils</span> <span class="kn">import</span> <span class="n">get_tf_eager_cls_if_necessary</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AgentID</span><span class="p">,</span>
    <span class="n">AlgorithmConfigDict</span><span class="p">,</span>
    <span class="n">ModelGradients</span><span class="p">,</span>
    <span class="n">ModelWeights</span><span class="p">,</span>
    <span class="n">PolicyID</span><span class="p">,</span>
    <span class="n">PolicyState</span><span class="p">,</span>
    <span class="n">T</span><span class="p">,</span>
    <span class="n">TensorStructType</span><span class="p">,</span>
    <span class="n">TensorType</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">PublicAPI</span>

<span class="n">tf1</span><span class="p">,</span> <span class="n">tf</span><span class="p">,</span> <span class="n">tfv</span> <span class="o">=</span> <span class="n">try_import_tf</span><span class="p">()</span>
<span class="n">torch</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">try_import_torch</span><span class="p">()</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">ray.rllib.evaluation</span> <span class="kn">import</span> <span class="n">Episode</span>
    <span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module</span> <span class="kn">import</span> <span class="n">RLModule</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">PolicySpec</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A policy spec used in the &quot;config.multiagent.policies&quot; specification dict.</span>

<span class="sd">    As values (keys are the policy IDs (str)). E.g.:</span>
<span class="sd">    config:</span>
<span class="sd">        multiagent:</span>
<span class="sd">            policies: {</span>
<span class="sd">                &quot;pol1&quot;: PolicySpec(None, Box, Discrete(2), {&quot;lr&quot;: 0.0001}),</span>
<span class="sd">                &quot;pol2&quot;: PolicySpec(config={&quot;lr&quot;: 0.001}),</span>
<span class="sd">            }</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">policy_class</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observation_space</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="c1"># If None, use the Algorithm&#39;s default policy class stored under</span>
        <span class="c1"># `Algorithm._policy_class`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_class</span> <span class="o">=</span> <span class="n">policy_class</span>
        <span class="c1"># If None, use the env&#39;s observation space. If None and there is no Env</span>
        <span class="c1"># (e.g. offline RL), an error is thrown.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">observation_space</span>
        <span class="c1"># If None, use the env&#39;s action space. If None and there is no Env</span>
        <span class="c1"># (e.g. offline RL), an error is thrown.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="c1"># Overrides defined keys in the main Algorithm config.</span>
        <span class="c1"># If None, use {}.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;PolicySpec&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_class</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">policy_class</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">observation_space</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">action_space</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">config</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">serialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">ray.rllib.algorithms.registry</span> <span class="kn">import</span> <span class="n">get_policy_class_name</span>

        <span class="c1"># Try to figure out a durable name for this policy.</span>
        <span class="bp">cls</span> <span class="o">=</span> <span class="n">get_policy_class_name</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_class</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">cls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Can not figure out a durable policy name for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_class</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;You are probably trying to checkpoint a custom policy. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Raw policy class may cause problems when the checkpoint needs to &quot;</span>
                <span class="s2">&quot;be loaded in the future. To fix this, make sure you add your &quot;</span>
                <span class="s2">&quot;custom policy in rllib.algorithms.registry.POLICIES.&quot;</span>
            <span class="p">)</span>
            <span class="bp">cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_class</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;policy_class&quot;</span><span class="p">:</span> <span class="bp">cls</span><span class="p">,</span>
            <span class="s2">&quot;observation_space&quot;</span><span class="p">:</span> <span class="n">space_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">),</span>
            <span class="s2">&quot;action_space&quot;</span><span class="p">:</span> <span class="n">space_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">),</span>
            <span class="c1"># TODO(jungong) : try making the config dict durable by maybe</span>
            <span class="c1">#  getting rid of all the fields that are not JSON serializable.</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">deserialize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PolicySpec&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="s2">&quot;policy_class&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
            <span class="c1"># Try to recover the actual policy class from durable name.</span>
            <span class="kn">from</span> <span class="nn">ray.rllib.algorithms.registry</span> <span class="kn">import</span> <span class="n">get_policy_class</span>

            <span class="n">policy_class</span> <span class="o">=</span> <span class="n">get_policy_class</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="s2">&quot;policy_class&quot;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="s2">&quot;policy_class&quot;</span><span class="p">],</span> <span class="nb">type</span><span class="p">):</span>
            <span class="c1"># Policy spec is already a class type. Simply use it.</span>
            <span class="n">policy_class</span> <span class="o">=</span> <span class="n">spec</span><span class="p">[</span><span class="s2">&quot;policy_class&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown policy class spec </span><span class="si">{</span><span class="n">spec</span><span class="p">[</span><span class="s1">&#39;policy_class&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">policy_class</span><span class="o">=</span><span class="n">policy_class</span><span class="p">,</span>
            <span class="n">observation_space</span><span class="o">=</span><span class="n">space_from_dict</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="s2">&quot;observation_space&quot;</span><span class="p">]),</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">space_from_dict</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="s2">&quot;action_space&quot;</span><span class="p">]),</span>
            <span class="n">config</span><span class="o">=</span><span class="n">spec</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">],</span>
        <span class="p">)</span>


<div class="viewcode-block" id="Policy"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.html#ray.rllib.Policy">[docs]</a><span class="nd">@DeveloperAPI</span>
<span class="k">class</span> <span class="nc">Policy</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;RLlib&#39;s base class for all Policy implementations.</span>

<span class="sd">    Policy is the abstract superclass for all DL-framework specific sub-classes</span>
<span class="sd">    (e.g. TFPolicy or TorchPolicy). It exposes APIs to</span>

<span class="sd">    1. Compute actions from observation (and possibly other) inputs.</span>

<span class="sd">    2. Manage the Policy&#39;s NN model(s), like exporting and loading their weights.</span>

<span class="sd">    3. Postprocess a given trajectory from the environment or other input via the</span>
<span class="sd">        `postprocess_trajectory` method.</span>

<span class="sd">    4. Compute losses from a train batch.</span>

<span class="sd">    5. Perform updates from a train batch on the NN-models (this normally includes loss</span>
<span class="sd">        calculations) either:</span>

<span class="sd">        a. in one monolithic step (`learn_on_batch`)</span>

<span class="sd">        b. via batch pre-loading, then n steps of actual loss computations  and updates</span>
<span class="sd">            (`load_batch_into_buffer` + `learn_on_loaded_batch`).</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Policy.__init__"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.__init__.html#ray.rllib.Policy.__init__">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">observation_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">AlgorithmConfigDict</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initializes a Policy instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            observation_space: Observation space of the policy.</span>
<span class="sd">            action_space: Action space of the policy.</span>
<span class="sd">            config: A complete Algorithm/Policy config dict. For the default</span>
<span class="sd">                config keys and values, see rllib/trainer/trainer.py.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span> <span class="o">=</span> <span class="n">observation_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="c1"># the policy id in the global context.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__policy_id</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;__policy_id&quot;</span><span class="p">)</span>
        <span class="c1"># The base struct of the observation/action spaces.</span>
        <span class="c1"># E.g. action-space = gym.spaces.Dict({&quot;a&quot;: Discrete(2)}) -&gt;</span>
        <span class="c1"># action_space_struct = {&quot;a&quot;: Discrete(2)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space_struct</span> <span class="o">=</span> <span class="n">get_base_struct_from_space</span><span class="p">(</span><span class="n">observation_space</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space_struct</span> <span class="o">=</span> <span class="n">get_base_struct_from_space</span><span class="p">(</span><span class="n">action_space</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> <span class="n">AlgorithmConfigDict</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;framework&quot;</span><span class="p">)</span>

        <span class="c1"># Create the callbacks object to use for handling custom callbacks.</span>
        <span class="kn">from</span> <span class="nn">ray.rllib.algorithms.callbacks</span> <span class="kn">import</span> <span class="n">DefaultCallbacks</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;callbacks&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">DefaultCallbacks</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">type</span><span class="p">)):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span> <span class="s2">&quot;DefaultCallbacks&quot;</span> <span class="o">=</span> <span class="n">deserialize_type</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;callbacks&quot;</span><span class="p">)</span>
                <span class="p">)()</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">pass</span>  <span class="c1"># TEST</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span> <span class="s2">&quot;DefaultCallbacks&quot;</span> <span class="o">=</span> <span class="n">DefaultCallbacks</span><span class="p">()</span>

        <span class="c1"># The global timestep, broadcast down from time to time from the</span>
        <span class="c1"># local worker to all remote workers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># The number of gradient updates this policy has undergone.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_grad_updates</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># The action distribution class to use for action sampling, if any.</span>
        <span class="c1"># Child classes may set this.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Initialize view requirements.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_view_requirements</span><span class="p">()</span>

        <span class="c1"># Whether the Model&#39;s initial state (method) has been added</span>
        <span class="c1"># automatically based on the given view requirements of the model.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_init_state_automatically_added</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Connectors.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_connectors</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Policy.from_checkpoint"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.from_checkpoint.html#ray.rllib.Policy.from_checkpoint">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_checkpoint</span><span class="p">(</span>
        <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Checkpoint</span><span class="p">],</span>
        <span class="n">policy_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Container</span><span class="p">[</span><span class="n">PolicyID</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;Policy&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">PolicyID</span><span class="p">,</span> <span class="s2">&quot;Policy&quot;</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Creates new Policy instance(s) from a given Policy or Algorithm checkpoint.</span>

<span class="sd">        Note: This method must remain backward compatible from 2.1.0 on, wrt.</span>
<span class="sd">        checkpoints created with Ray 2.0.0 or later.</span>

<span class="sd">        Args:</span>
<span class="sd">            checkpoint: The path (str) to a Policy or Algorithm checkpoint directory</span>
<span class="sd">                or an AIR Checkpoint (Policy or Algorithm) instance to restore</span>
<span class="sd">                from.</span>
<span class="sd">                If checkpoint is a Policy checkpoint, `policy_ids` must be None</span>
<span class="sd">                and only the Policy in that checkpoint is restored and returned.</span>
<span class="sd">                If checkpoint is an Algorithm checkpoint and `policy_ids` is None,</span>
<span class="sd">                will return a list of all Policy objects found in</span>
<span class="sd">                the checkpoint, otherwise a list of those policies in `policy_ids`.</span>
<span class="sd">            policy_ids: List of policy IDs to extract from a given Algorithm checkpoint.</span>
<span class="sd">                If None and an Algorithm checkpoint is provided, will restore all</span>
<span class="sd">                policies found in that checkpoint. If a Policy checkpoint is given,</span>
<span class="sd">                this arg must be None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An instantiated Policy, if `checkpoint` is a Policy checkpoint. A dict</span>
<span class="sd">            mapping PolicyID to Policies, if `checkpoint` is an Algorithm checkpoint.</span>
<span class="sd">            In the latter case, returns all policies within the Algorithm if</span>
<span class="sd">            `policy_ids` is None, else a dict of only those Policies that are in</span>
<span class="sd">            `policy_ids`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">checkpoint_info</span> <span class="o">=</span> <span class="n">get_checkpoint_info</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

        <span class="c1"># Algorithm checkpoint: Extract one or more policies from it and return them</span>
        <span class="c1"># in a dict (mapping PolicyID to Policy instances).</span>
        <span class="k">if</span> <span class="n">checkpoint_info</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Algorithm&quot;</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.rllib.algorithms.algorithm</span> <span class="kn">import</span> <span class="n">Algorithm</span>

            <span class="n">policies</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># Old Algorithm checkpoints: State must be completely retrieved from:</span>
            <span class="c1"># algo state file -&gt; worker -&gt; &quot;state&quot;.</span>
            <span class="k">if</span> <span class="n">checkpoint_info</span><span class="p">[</span><span class="s2">&quot;checkpoint_version&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">version</span><span class="o">.</span><span class="n">Version</span><span class="p">(</span><span class="s2">&quot;1.0&quot;</span><span class="p">):</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">checkpoint_info</span><span class="p">[</span><span class="s2">&quot;state_file&quot;</span><span class="p">],</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="c1"># In older checkpoint versions, the policy states are stored under</span>
                <span class="c1"># &quot;state&quot; within the worker state (which is pickled in itself).</span>
                <span class="n">worker_state</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;worker&quot;</span><span class="p">])</span>
                <span class="n">policy_states</span> <span class="o">=</span> <span class="n">worker_state</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">pid</span><span class="p">,</span> <span class="n">policy_state</span> <span class="ow">in</span> <span class="n">policy_states</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="c1"># Get spec and config, merge config with</span>
                    <span class="n">serialized_policy_spec</span> <span class="o">=</span> <span class="n">worker_state</span><span class="p">[</span><span class="s2">&quot;policy_specs&quot;</span><span class="p">][</span><span class="n">pid</span><span class="p">]</span>
                    <span class="n">policy_config</span> <span class="o">=</span> <span class="n">Algorithm</span><span class="o">.</span><span class="n">merge_trainer_configs</span><span class="p">(</span>
                        <span class="n">worker_state</span><span class="p">[</span><span class="s2">&quot;policy_config&quot;</span><span class="p">],</span> <span class="n">serialized_policy_spec</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="n">serialized_policy_spec</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="n">policy_config</span><span class="p">})</span>
                    <span class="n">policy_state</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;policy_spec&quot;</span><span class="p">:</span> <span class="n">serialized_policy_spec</span><span class="p">})</span>
                    <span class="n">policies</span><span class="p">[</span><span class="n">pid</span><span class="p">]</span> <span class="o">=</span> <span class="n">Policy</span><span class="o">.</span><span class="n">from_state</span><span class="p">(</span><span class="n">policy_state</span><span class="p">)</span>
            <span class="c1"># Newer versions: Get policy states from &quot;policies/&quot; sub-dirs.</span>
            <span class="k">elif</span> <span class="n">checkpoint_info</span><span class="p">[</span><span class="s2">&quot;policy_ids&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">policy_id</span> <span class="ow">in</span> <span class="n">checkpoint_info</span><span class="p">[</span><span class="s2">&quot;policy_ids&quot;</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="n">policy_ids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">policy_id</span> <span class="ow">in</span> <span class="n">policy_ids</span><span class="p">:</span>
                        <span class="n">policy_checkpoint_info</span> <span class="o">=</span> <span class="n">get_checkpoint_info</span><span class="p">(</span>
                            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                                <span class="n">checkpoint_info</span><span class="p">[</span><span class="s2">&quot;checkpoint_dir&quot;</span><span class="p">],</span>
                                <span class="s2">&quot;policies&quot;</span><span class="p">,</span>
                                <span class="n">policy_id</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">assert</span> <span class="n">policy_checkpoint_info</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Policy&quot;</span>
                        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">policy_checkpoint_info</span><span class="p">[</span><span class="s2">&quot;state_file&quot;</span><span class="p">],</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                            <span class="n">policy_state</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                        <span class="n">policies</span><span class="p">[</span><span class="n">policy_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">Policy</span><span class="o">.</span><span class="n">from_state</span><span class="p">(</span><span class="n">policy_state</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">policies</span>

        <span class="c1"># Policy checkpoint: Return a single Policy instance.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">checkpoint_info</span><span class="p">[</span><span class="s2">&quot;state_file&quot;</span><span class="p">],</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Policy</span><span class="o">.</span><span class="n">from_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></div>

<div class="viewcode-block" id="Policy.from_state"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.from_state.html#ray.rllib.Policy.from_state">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_state</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">PolicyState</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Policy&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Recovers a Policy from a state object.</span>

<span class="sd">        The `state` of an instantiated Policy can be retrieved by calling its</span>
<span class="sd">        `get_state` method. This only works for the V2 Policy classes (EagerTFPolicyV2,</span>
<span class="sd">        SynamicTFPolicyV2, and TorchPolicyV2). It contains all information necessary</span>
<span class="sd">        to create the Policy. No access to the original code (e.g. configs, knowledge of</span>
<span class="sd">        the policy&#39;s class, etc..) is needed.</span>

<span class="sd">        Args:</span>
<span class="sd">            state: The state to recover a new Policy instance from.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new Policy instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">serialized_pol_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;policy_spec&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">serialized_pol_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No `policy_spec` key was found in given `state`! &quot;</span>
                <span class="s2">&quot;Cannot create new Policy.&quot;</span>
            <span class="p">)</span>
        <span class="n">pol_spec</span> <span class="o">=</span> <span class="n">PolicySpec</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span><span class="n">serialized_pol_spec</span><span class="p">)</span>
        <span class="n">actual_class</span> <span class="o">=</span> <span class="n">get_tf_eager_cls_if_necessary</span><span class="p">(</span>
            <span class="n">pol_spec</span><span class="o">.</span><span class="n">policy_class</span><span class="p">,</span>
            <span class="n">pol_spec</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">pol_spec</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;framework&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.rllib.policy.tf_policy</span> <span class="kn">import</span> <span class="n">TFPolicy</span>

            <span class="k">return</span> <span class="n">TFPolicy</span><span class="o">.</span><span class="n">_tf1_from_state_helper</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="c1"># Create the new policy.</span>
        <span class="n">new_policy</span> <span class="o">=</span> <span class="n">actual_class</span><span class="p">(</span>
            <span class="c1"># Note(jungong) : we are intentionally not using keyward arguments here</span>
            <span class="c1"># because some policies name the observation space parameter obs_space,</span>
            <span class="c1"># and some others name it observation_space.</span>
            <span class="n">pol_spec</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
            <span class="n">pol_spec</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">pol_spec</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Set the new policy&#39;s state (weights, optimizer vars, exploration state,</span>
        <span class="c1"># etc..).</span>
        <span class="n">new_policy</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="c1"># Return the new policy.</span>
        <span class="k">return</span> <span class="n">new_policy</span></div>

<div class="viewcode-block" id="Policy.make_rl_module"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.make_rl_module.html#ray.rllib.Policy.make_rl_module">[docs]</a>    <span class="nd">@ExperimentalAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">make_rl_module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;RLModule&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the RL Module (only for when RLModule API is enabled.)</span>

<span class="sd">        If RLModule API is enabled (self.config.rl_module(_enable_rl_module_api=True),</span>
<span class="sd">        this method should be implemented and should return the RLModule instance to</span>
<span class="sd">        use for this Policy. Otherwise, RLlib will error out.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if imported on top it creates circular dependency</span>
        <span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">SingleAgentRLModuleSpec</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__policy_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;When using RLModule API, `policy_id` within the policies must be &quot;</span>
                <span class="s2">&quot;set. This should have happened automatically. If you see this &quot;</span>
                <span class="s2">&quot;bug, please file a github issue.&quot;</span>
            <span class="p">)</span>

        <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;__marl_module_spec&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">SingleAgentRLModuleSpec</span><span class="p">):</span>
            <span class="n">module</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># filter the module_spec to only contain the policy_id of this policy</span>
            <span class="n">marl_spec</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">spec</span><span class="p">)(</span>
                <span class="n">marl_module_class</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">marl_module_class</span><span class="p">,</span>
                <span class="n">module_specs</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__policy_id</span><span class="p">:</span> <span class="n">spec</span><span class="o">.</span><span class="n">module_specs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">__policy_id</span><span class="p">]},</span>
            <span class="p">)</span>
            <span class="n">marl_module</span> <span class="o">=</span> <span class="n">marl_spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
            <span class="n">module</span> <span class="o">=</span> <span class="n">marl_module</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">__policy_id</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">module</span></div>

<div class="viewcode-block" id="Policy.init_view_requirements"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.init_view_requirements.html#ray.rllib.Policy.init_view_requirements">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">init_view_requirements</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Maximal view requirements dict for `learn_on_batch()` and</span>
<span class="sd">        `compute_actions` calls.</span>
<span class="sd">        Specific policies can override this function to provide custom</span>
<span class="sd">        list of view requirements.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Maximal view requirements dict for `learn_on_batch()` and</span>
        <span class="c1"># `compute_actions` calls.</span>
        <span class="c1"># View requirements will be automatically filtered out later based</span>
        <span class="c1"># on the postprocessing and loss functions to ensure optimal data</span>
        <span class="c1"># collection and transfer performance.</span>
        <span class="n">view_reqs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_default_view_requirements</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;view_requirements&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span> <span class="o">=</span> <span class="n">view_reqs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">view_reqs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span></div>

<div class="viewcode-block" id="Policy.get_connector_metrics"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_connector_metrics.html#ray.rllib.Policy.get_connector_metrics">[docs]</a>    <span class="k">def</span> <span class="nf">get_connector_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get metrics on timing from connectors.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;agent_connectors&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_ms&quot;</span><span class="p">:</span> <span class="mi">1000</span> <span class="o">*</span> <span class="n">timer</span><span class="o">.</span><span class="n">mean</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">timer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span><span class="o">.</span><span class="n">timers</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">},</span>
            <span class="s2">&quot;action_connectors&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_ms&quot;</span><span class="p">:</span> <span class="mi">1000</span> <span class="o">*</span> <span class="n">timer</span><span class="o">.</span><span class="n">mean</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">timer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span><span class="o">.</span><span class="n">timers</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">},</span>
        <span class="p">}</span></div>

<div class="viewcode-block" id="Policy.reset_connectors"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.reset_connectors.html#ray.rllib.Policy.reset_connectors">[docs]</a>    <span class="k">def</span> <span class="nf">reset_connectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_id</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Reset action- and agent-connectors for this policy.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="n">env_id</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_connectors</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="n">env_id</span><span class="p">)</span></div>

<div class="viewcode-block" id="Policy.compute_single_action"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_single_action.html#ray.rllib.Policy.compute_single_action">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">compute_single_action</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prev_action</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prev_reward</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SampleBatch</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">episode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Kwars placeholder for future compatibility.</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Computes and returns a single (B=1) action value.</span>

<span class="sd">        Takes an input dict (usually a SampleBatch) as its main data input.</span>
<span class="sd">        This allows for using this method in case a more complex input pattern</span>
<span class="sd">        (view requirements) is needed, for example when the Model requires the</span>
<span class="sd">        last n observations, the last m actions/rewards, or a combination</span>
<span class="sd">        of any of these.</span>
<span class="sd">        Alternatively, in case no complex inputs are required, takes a single</span>
<span class="sd">        `obs` values (and possibly single state values, prev-action/reward</span>
<span class="sd">        values, etc..).</span>

<span class="sd">        Args:</span>
<span class="sd">            obs: Single observation.</span>
<span class="sd">            state: List of RNN state inputs, if any.</span>
<span class="sd">            prev_action: Previous action value, if any.</span>
<span class="sd">            prev_reward: Previous reward, if any.</span>
<span class="sd">            info: Info object, if any.</span>
<span class="sd">            input_dict: A SampleBatch or input dict containing the</span>
<span class="sd">                single (unbatched) Tensors to compute actions. If given, it&#39;ll</span>
<span class="sd">                be used instead of `obs`, `state`, `prev_action|reward`, and</span>
<span class="sd">                `info`.</span>
<span class="sd">            episode: This provides access to all of the internal episode state,</span>
<span class="sd">                which may be useful for model-based or multi-agent algorithms.</span>
<span class="sd">            explore: Whether to pick an exploitation or</span>
<span class="sd">                exploration action</span>
<span class="sd">                (default: None -&gt; use self.config[&quot;explore&quot;]).</span>
<span class="sd">            timestep: The current (sampling) time step.</span>

<span class="sd">        Keyword Args:</span>
<span class="sd">            kwargs: Forward compatibility placeholder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple consisting of the action, the list of RNN state outputs (if</span>
<span class="sd">            any), and a dictionary of extra features (if any).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Build the input-dict used for the call to</span>
        <span class="c1"># `self.compute_actions_from_input_dict()`.</span>
        <span class="k">if</span> <span class="n">input_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">obs</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
                    <span class="n">input_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;state_in_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
            <span class="k">if</span> <span class="n">prev_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_action</span>
            <span class="k">if</span> <span class="n">prev_reward</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_reward</span>
            <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">]</span> <span class="o">=</span> <span class="n">info</span>

        <span class="c1"># Batch all data in input dict.</span>
        <span class="n">input_dict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">map_structure_with_path</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="p">(</span>
                <span class="n">s</span>
                <span class="k">if</span> <span class="n">p</span> <span class="o">==</span> <span class="s2">&quot;seq_lens&quot;</span>
                <span class="k">else</span> <span class="n">s</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">torch</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="n">input_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">episodes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">episode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">episodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">episode</span><span class="p">]</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_actions_from_input_dict</span><span class="p">(</span>
            <span class="n">input_dict</span><span class="o">=</span><span class="n">SampleBatch</span><span class="p">(</span><span class="n">input_dict</span><span class="p">),</span>
            <span class="n">episodes</span><span class="o">=</span><span class="n">episodes</span><span class="p">,</span>
            <span class="n">explore</span><span class="o">=</span><span class="n">explore</span><span class="p">,</span>
            <span class="n">timestep</span><span class="o">=</span><span class="n">timestep</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Some policies don&#39;t return a tuple, but always just a single action.</span>
        <span class="c1"># E.g. ES and ARS.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">single_action</span> <span class="o">=</span> <span class="n">out</span>
            <span class="n">state_out</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">info</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># Normal case: Policy should return (action, state, info) tuple.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batched_action</span><span class="p">,</span> <span class="n">state_out</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">out</span>
            <span class="n">single_action</span> <span class="o">=</span> <span class="n">unbatch</span><span class="p">(</span><span class="n">batched_action</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">single_action</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">single_action</span> <span class="o">=</span> <span class="n">single_action</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Return action, internal state(s), infos.</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">single_action</span><span class="p">,</span>
            <span class="n">tree</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state_out</span><span class="p">),</span>
            <span class="n">tree</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">info</span><span class="p">),</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Policy.compute_actions_from_input_dict"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions_from_input_dict.html#ray.rllib.Policy.compute_actions_from_input_dict">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">compute_actions_from_input_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">SampleBatch</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorStructType</span><span class="p">]],</span>
        <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Computes actions from collected samples (across multiple-agents).</span>

<span class="sd">        Takes an input dict (usually a SampleBatch) as its main data input.</span>
<span class="sd">        This allows for using this method in case a more complex input pattern</span>
<span class="sd">        (view requirements) is needed, for example when the Model requires the</span>
<span class="sd">        last n observations, the last m actions/rewards, or a combination</span>
<span class="sd">        of any of these.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_dict: A SampleBatch or input dict containing the Tensors</span>
<span class="sd">                to compute actions. `input_dict` already abides to the</span>
<span class="sd">                Policy&#39;s as well as the Model&#39;s view requirements and can</span>
<span class="sd">                thus be passed to the Model as-is.</span>
<span class="sd">            explore: Whether to pick an exploitation or exploration</span>
<span class="sd">                action (default: None -&gt; use self.config[&quot;explore&quot;]).</span>
<span class="sd">            timestep: The current (sampling) time step.</span>
<span class="sd">            episodes: This provides access to all of the internal episodes&#39;</span>
<span class="sd">                state, which may be useful for model-based or multi-agent</span>
<span class="sd">                algorithms.</span>

<span class="sd">        Keyword Args:</span>
<span class="sd">            kwargs: Forward compatibility placeholder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            actions: Batch of output actions, with shape like</span>
<span class="sd">                [BATCH_SIZE, ACTION_SHAPE].</span>
<span class="sd">            state_outs: List of RNN state output</span>
<span class="sd">                batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].</span>
<span class="sd">            info: Dictionary of extra feature batches, if any, with shape like</span>
<span class="sd">                {&quot;f1&quot;: [BATCH_SIZE, ...], &quot;f2&quot;: [BATCH_SIZE, ...]}.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Default implementation just passes obs, prev-a/r, and states on to</span>
        <span class="c1"># `self.compute_actions()`.</span>
        <span class="n">state_batches</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span><span class="p">[:</span><span class="mi">9</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;state_in_&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_actions</span><span class="p">(</span>
            <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">],</span>
            <span class="n">state_batches</span><span class="p">,</span>
            <span class="n">prev_action_batch</span><span class="o">=</span><span class="n">input_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">),</span>
            <span class="n">prev_reward_batch</span><span class="o">=</span><span class="n">input_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">),</span>
            <span class="n">info_batch</span><span class="o">=</span><span class="n">input_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">),</span>
            <span class="n">explore</span><span class="o">=</span><span class="n">explore</span><span class="p">,</span>
            <span class="n">timestep</span><span class="o">=</span><span class="n">timestep</span><span class="p">,</span>
            <span class="n">episodes</span><span class="o">=</span><span class="n">episodes</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Policy.compute_actions"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions.html#ray.rllib.Policy.compute_actions">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">compute_actions</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span> <span class="n">TensorStructType</span><span class="p">],</span>
        <span class="n">state_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prev_action_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span> <span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prev_reward_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span> <span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">info_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Computes actions for the current policy.</span>

<span class="sd">        Args:</span>
<span class="sd">            obs_batch: Batch of observations.</span>
<span class="sd">            state_batches: List of RNN state input batches, if any.</span>
<span class="sd">            prev_action_batch: Batch of previous action values.</span>
<span class="sd">            prev_reward_batch: Batch of previous rewards.</span>
<span class="sd">            info_batch: Batch of info objects.</span>
<span class="sd">            episodes: List of Episode objects, one for each obs in</span>
<span class="sd">                obs_batch. This provides access to all of the internal</span>
<span class="sd">                episode state, which may be useful for model-based or</span>
<span class="sd">                multi-agent algorithms.</span>
<span class="sd">            explore: Whether to pick an exploitation or exploration action.</span>
<span class="sd">                Set to None (default) for using the value of</span>
<span class="sd">                `self.config[&quot;explore&quot;]`.</span>
<span class="sd">            timestep: The current (sampling) time step.</span>

<span class="sd">        Keyword Args:</span>
<span class="sd">            kwargs: Forward compatibility placeholder</span>

<span class="sd">        Returns:</span>
<span class="sd">            actions: Batch of output actions, with shape like</span>
<span class="sd">                [BATCH_SIZE, ACTION_SHAPE].</span>
<span class="sd">            state_outs (List[TensorType]): List of RNN state output</span>
<span class="sd">                batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].</span>
<span class="sd">            info (List[dict]): Dictionary of extra feature batches, if any,</span>
<span class="sd">                with shape like</span>
<span class="sd">                {&quot;f1&quot;: [BATCH_SIZE, ...], &quot;f2&quot;: [BATCH_SIZE, ...]}.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.compute_log_likelihoods"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_log_likelihoods.html#ray.rllib.Policy.compute_log_likelihoods">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">compute_log_likelihoods</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">actions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">],</span>
        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">],</span>
        <span class="n">state_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prev_action_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prev_reward_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">actions_normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">in_training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorType</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the log-prob/likelihood for a given action and observation.</span>

<span class="sd">        The log-likelihood is calculated using this Policy&#39;s action</span>
<span class="sd">        distribution class (self.dist_class).</span>

<span class="sd">        Args:</span>
<span class="sd">            actions: Batch of actions, for which to retrieve the</span>
<span class="sd">                log-probs/likelihoods (given all other inputs: obs,</span>
<span class="sd">                states, ..).</span>
<span class="sd">            obs_batch: Batch of observations.</span>
<span class="sd">            state_batches: List of RNN state input batches, if any.</span>
<span class="sd">            prev_action_batch: Batch of previous action values.</span>
<span class="sd">            prev_reward_batch: Batch of previous rewards.</span>
<span class="sd">            actions_normalized: Is the given `actions` already normalized</span>
<span class="sd">                (between -1.0 and 1.0) or not? If not and</span>
<span class="sd">                `normalize_actions=True`, we need to normalize the given</span>
<span class="sd">                actions first, before calculating log likelihoods.</span>
<span class="sd">            in_training: Whether to use the forward_train() or forward_exploration() of</span>
<span class="sd">                the underlying RLModule.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Batch of log probs/likelihoods, with shape: [BATCH_SIZE].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.postprocess_trajectory"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.postprocess_trajectory.html#ray.rllib.Policy.postprocess_trajectory">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">postprocess_trajectory</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sample_batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">,</span>
        <span class="n">other_agent_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Dict</span><span class="p">[</span><span class="n">AgentID</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="s2">&quot;Policy&quot;</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">episode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SampleBatch</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Implements algorithm-specific trajectory postprocessing.</span>

<span class="sd">        This will be called on each trajectory fragment computed during policy</span>
<span class="sd">        evaluation. Each fragment is guaranteed to be only from one episode.</span>
<span class="sd">        The given fragment may or may not contain the end of this episode,</span>
<span class="sd">        depending on the `batch_mode=truncate_episodes|complete_episodes`,</span>
<span class="sd">        `rollout_fragment_length`, and other settings.</span>

<span class="sd">        Args:</span>
<span class="sd">            sample_batch: batch of experiences for the policy,</span>
<span class="sd">                which will contain at most one episode trajectory.</span>
<span class="sd">            other_agent_batches: In a multi-agent env, this contains a</span>
<span class="sd">                mapping of agent ids to (policy, agent_batch) tuples</span>
<span class="sd">                containing the policy and experiences of the other agents.</span>
<span class="sd">            episode: An optional multi-agent episode object to provide</span>
<span class="sd">                access to all of the internal episode state, which may</span>
<span class="sd">                be useful for model-based or multi-agent algorithms.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The postprocessed sample batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The default implementation just returns the same, unaltered batch.</span>
        <span class="k">return</span> <span class="n">sample_batch</span></div>

<div class="viewcode-block" id="Policy.loss"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.loss.html#ray.rllib.Policy.loss">[docs]</a>    <span class="nd">@ExperimentalAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">dist_class</span><span class="p">:</span> <span class="n">ActionDistribution</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">:</span> <span class="n">SampleBatch</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Loss function for this Policy.</span>

<span class="sd">        Override this method in order to implement custom loss computations.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The model to calculate the loss(es).</span>
<span class="sd">            dist_class: The action distribution class to sample actions</span>
<span class="sd">                from the model&#39;s outputs.</span>
<span class="sd">            train_batch: The input batch on which to calculate the loss.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Either a single loss tensor or a list of loss tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.learn_on_batch"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.learn_on_batch.html#ray.rllib.Policy.learn_on_batch">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">learn_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Perform one learning update, given `samples`.</span>

<span class="sd">        Either this method or the combination of `compute_gradients` and</span>
<span class="sd">        `apply_gradients` must be implemented by subclasses.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: The SampleBatch object to learn from.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of extra metadata from `compute_gradients()`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; policy, sample_batch = ... # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; policy.learn_on_batch(sample_batch) # doctest: +SKIP</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The default implementation is simply a fused `compute_gradients` plus</span>
        <span class="c1"># `apply_gradients` call.</span>
        <span class="n">grads</span><span class="p">,</span> <span class="n">grad_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">grad_info</span></div>

<div class="viewcode-block" id="Policy.learn_on_batch_from_replay_buffer"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.learn_on_batch_from_replay_buffer.html#ray.rllib.Policy.learn_on_batch_from_replay_buffer">[docs]</a>    <span class="nd">@ExperimentalAPI</span>
    <span class="k">def</span> <span class="nf">learn_on_batch_from_replay_buffer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">replay_actor</span><span class="p">:</span> <span class="n">ActorHandle</span><span class="p">,</span> <span class="n">policy_id</span><span class="p">:</span> <span class="n">PolicyID</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Samples a batch from given replay actor and performs an update.</span>

<span class="sd">        Args:</span>
<span class="sd">            replay_actor: The replay buffer actor to sample from.</span>
<span class="sd">            policy_id: The ID of this policy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of extra metadata from `compute_gradients()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Sample a batch from the given replay actor.</span>
        <span class="c1"># Note that for better performance (less data sent through the</span>
        <span class="c1"># network), this policy should be co-located on the same node</span>
        <span class="c1"># as `replay_actor`. Such a co-location step is usually done during</span>
        <span class="c1"># the Algorithm&#39;s `setup()` phase.</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">replay_actor</span><span class="o">.</span><span class="n">replay</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">policy_id</span><span class="o">=</span><span class="n">policy_id</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="c1"># Send to own learn_on_batch method for updating.</span>
        <span class="c1"># TODO: hack w/ `hasattr`</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;devices&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_batch_into_buffer</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">learn_on_loaded_batch</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">learn_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></div>

<div class="viewcode-block" id="Policy.load_batch_into_buffer"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.load_batch_into_buffer.html#ray.rllib.Policy.load_batch_into_buffer">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">load_batch_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">,</span> <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Bulk-loads the given SampleBatch into the devices&#39; memories.</span>

<span class="sd">        The data is split equally across all the Policy&#39;s devices.</span>
<span class="sd">        If the data is not evenly divisible by the batch size, excess data</span>
<span class="sd">        should be discarded.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: The SampleBatch to load.</span>
<span class="sd">            buffer_index: The index of the buffer (a MultiGPUTowerStack) to use</span>
<span class="sd">                on the devices. The number of buffers on each device depends</span>
<span class="sd">                on the value of the `num_multi_gpu_tower_stacks` config key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of tuples loaded per device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.get_num_samples_loaded_into_buffer"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_num_samples_loaded_into_buffer.html#ray.rllib.Policy.get_num_samples_loaded_into_buffer">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">get_num_samples_loaded_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of currently loaded samples in the given buffer.</span>

<span class="sd">        Args:</span>
<span class="sd">            buffer_index: The index of the buffer (a MultiGPUTowerStack)</span>
<span class="sd">                to use on the devices. The number of buffers on each device</span>
<span class="sd">                depends on the value of the `num_multi_gpu_tower_stacks` config</span>
<span class="sd">                key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of tuples loaded per device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.learn_on_loaded_batch"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.learn_on_loaded_batch.html#ray.rllib.Policy.learn_on_loaded_batch">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">learn_on_loaded_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Runs a single step of SGD on an already loaded data in a buffer.</span>

<span class="sd">        Runs an SGD step over a slice of the pre-loaded batch, offset by</span>
<span class="sd">        the `offset` argument (useful for performing n minibatch SGD</span>
<span class="sd">        updates repeatedly on the same, already pre-loaded data).</span>

<span class="sd">        Updates the model weights based on the averaged per-device gradients.</span>

<span class="sd">        Args:</span>
<span class="sd">            offset: Offset into the preloaded data. Used for pre-loading</span>
<span class="sd">                a train-batch once to a device, then iterating over</span>
<span class="sd">                (subsampling through) this batch n times doing minibatch SGD.</span>
<span class="sd">            buffer_index: The index of the buffer (a MultiGPUTowerStack)</span>
<span class="sd">                to take the already pre-loaded data from. The number of buffers</span>
<span class="sd">                on each device depends on the value of the</span>
<span class="sd">                `num_multi_gpu_tower_stacks` config key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The outputs of extra_ops evaluated over the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.compute_gradients"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_gradients.html#ray.rllib.Policy.compute_gradients">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">:</span> <span class="n">SampleBatch</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Computes gradients given a batch of experiences.</span>

<span class="sd">        Either this in combination with `apply_gradients()` or</span>
<span class="sd">        `learn_on_batch()` must be implemented by subclasses.</span>

<span class="sd">        Args:</span>
<span class="sd">            postprocessed_batch: The SampleBatch object to use</span>
<span class="sd">                for calculating gradients.</span>

<span class="sd">        Returns:</span>
<span class="sd">            grads: List of gradient output values.</span>
<span class="sd">            grad_info: Extra policy-specific info values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.apply_gradients"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.apply_gradients.html#ray.rllib.Policy.apply_gradients">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">ModelGradients</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Applies the (previously) computed gradients.</span>

<span class="sd">        Either this in combination with `compute_gradients()` or</span>
<span class="sd">        `learn_on_batch()` must be implemented by subclasses.</span>

<span class="sd">        Args:</span>
<span class="sd">            gradients: The already calculated gradients to apply to this</span>
<span class="sd">                Policy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.get_weights"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_weights.html#ray.rllib.Policy.get_weights">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelWeights</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns model weights.</span>

<span class="sd">        Note: The return value of this method will reside under the &quot;weights&quot;</span>
<span class="sd">        key in the return value of Policy.get_state(). Model weights are only</span>
<span class="sd">        one part of a Policy&#39;s state. Other state information contains:</span>
<span class="sd">        optimizer variables, exploration state, and global state vars such as</span>
<span class="sd">        the sampling timestep.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Serializable copy or view of model weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.set_weights"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.set_weights.html#ray.rllib.Policy.set_weights">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">ModelWeights</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sets this Policy&#39;s model&#39;s weights.</span>

<span class="sd">        Note: Model weights are only one part of a Policy&#39;s state. Other</span>
<span class="sd">        state information contains: optimizer variables, exploration state,</span>
<span class="sd">        and global state vars such as the sampling timestep.</span>

<span class="sd">        Args:</span>
<span class="sd">            weights: Serializable copy or view of model weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.get_exploration_state"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_exploration_state.html#ray.rllib.Policy.get_exploration_state">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">get_exploration_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the state of this Policy&#39;s exploration component.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Serializable information on the `self.exploration` object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span></div>

<div class="viewcode-block" id="Policy.is_recurrent"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.is_recurrent.html#ray.rllib.Policy.is_recurrent">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">is_recurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Whether this Policy holds a recurrent Model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            True if this Policy has-a RNN-based Model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="Policy.num_state_tensors"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.num_state_tensors.html#ray.rllib.Policy.num_state_tensors">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">num_state_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The number of internal states needed by the RNN-Model of the Policy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: The number of RNN internal states kept by this Policy&#39;s Model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="Policy.get_initial_state"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_initial_state.html#ray.rllib.Policy.get_initial_state">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">get_initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns initial RNN state for the current policy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[TensorType]: Initial RNN state for the current policy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[]</span></div>

<div class="viewcode-block" id="Policy.get_state"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_state.html#ray.rllib.Policy.get_state">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PolicyState</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the entire current state of this Policy.</span>

<span class="sd">        Note: Not to be confused with an RNN model&#39;s internal state.</span>
<span class="sd">        State includes the Model(s)&#39; weights, optimizer weights,</span>
<span class="sd">        the exploration component&#39;s state, as well as global variables, such</span>
<span class="sd">        as sampling timesteps.</span>

<span class="sd">        Note that the state may contain references to the original variables.</span>
<span class="sd">        This means that you may need to deepcopy() the state before mutating it.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Serialized local state.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># All the policy&#39;s weights.</span>
            <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weights</span><span class="p">(),</span>
            <span class="c1"># The current global timestep.</span>
            <span class="s2">&quot;global_timestep&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">,</span>
            <span class="c1"># The current num_grad_updates counter.</span>
            <span class="s2">&quot;num_grad_updates&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_grad_updates</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Add this Policy&#39;s spec so it can be retreived w/o access to the original</span>
        <span class="c1"># code.</span>
        <span class="n">policy_spec</span> <span class="o">=</span> <span class="n">PolicySpec</span><span class="p">(</span>
            <span class="n">policy_class</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
            <span class="n">observation_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
            <span class="n">action_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;policy_spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">serialize</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;enable_connectors&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="c1"># Checkpoint connectors state as well if enabled.</span>
            <span class="n">connector_configs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span><span class="p">:</span>
                <span class="n">connector_configs</span><span class="p">[</span><span class="s2">&quot;agent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span><span class="o">.</span><span class="n">to_state</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_connectors</span><span class="p">:</span>
                <span class="n">connector_configs</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_connectors</span><span class="o">.</span><span class="n">to_state</span><span class="p">()</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;connector_configs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">connector_configs</span>

        <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="Policy.restore_connectors"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.restore_connectors.html#ray.rllib.Policy.restore_connectors">[docs]</a>    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">restore_connectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">PolicyState</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Restore agent and action connectors if configs available.</span>

<span class="sd">        Args:</span>
<span class="sd">            state: The new state to set this policy to. Can be</span>
<span class="sd">                obtained by calling `self.get_state()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># To avoid a circular dependency problem cause by SampleBatch.</span>
        <span class="kn">from</span> <span class="nn">ray.rllib.connectors.util</span> <span class="kn">import</span> <span class="n">restore_connectors_for_policy</span>

        <span class="c1"># No-op if connector is not enabled.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;enable_connectors&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">connector_configs</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;connector_configs&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="k">if</span> <span class="s2">&quot;agent&quot;</span> <span class="ow">in</span> <span class="n">connector_configs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span> <span class="o">=</span> <span class="n">restore_connectors_for_policy</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span> <span class="n">connector_configs</span><span class="p">[</span><span class="s2">&quot;agent&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;restoring agent connectors:&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agent_connectors</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">indentation</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
        <span class="k">if</span> <span class="s2">&quot;action&quot;</span> <span class="ow">in</span> <span class="n">connector_configs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_connectors</span> <span class="o">=</span> <span class="n">restore_connectors_for_policy</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span> <span class="n">connector_configs</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;restoring action connectors:&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_connectors</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">indentation</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span></div>

<div class="viewcode-block" id="Policy.set_state"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.set_state.html#ray.rllib.Policy.set_state">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">PolicyState</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Restores the entire current state of this Policy from `state`.</span>

<span class="sd">        Args:</span>
<span class="sd">            state: The new state to set this policy to. Can be</span>
<span class="sd">                obtained by calling `self.get_state()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;policy_spec&quot;</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="n">policy_spec</span> <span class="o">=</span> <span class="n">PolicySpec</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;policy_spec&quot;</span><span class="p">])</span>
            <span class="c1"># Assert spaces remained the same.</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">policy_spec</span><span class="o">.</span><span class="n">observation_space</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span>
            <span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;`observation_space` in given policy state (&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">policy_spec</span><span class="o">.</span><span class="n">observation_space</span><span class="si">}</span><span class="s2">) does not match this Policy&#39;s &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;observation space (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">policy_spec</span><span class="o">.</span><span class="n">action_space</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">action_space</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span>
            <span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;`action_space` in given policy state (&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">policy_spec</span><span class="o">.</span><span class="n">action_space</span><span class="si">}</span><span class="s2">) does not match this Policy&#39;s &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;action space (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
            <span class="c1"># Override config, if part of the spec.</span>
            <span class="k">if</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">config</span>

        <span class="c1"># Override NN weights.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">restore_connectors</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></div>

<div class="viewcode-block" id="Policy.apply"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.apply.html#ray.rllib.Policy.apply">[docs]</a>    <span class="nd">@ExperimentalAPI</span>
    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="s2">&quot;Policy&quot;</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]],</span> <span class="n">T</span><span class="p">],</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Calls the given function with this Policy instance.</span>

<span class="sd">        Useful for when the Policy class has been converted into a ActorHandle</span>
<span class="sd">        and the user needs to execute some functionality (e.g. add a property)</span>
<span class="sd">        on the underlying policy object.</span>

<span class="sd">        Args:</span>
<span class="sd">            func: The function to call, with this Policy as first</span>
<span class="sd">                argument, followed by args, and kwargs.</span>
<span class="sd">            args: Optional additional args to pass to the function call.</span>
<span class="sd">            kwargs: Optional additional kwargs to pass to the function call.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The return value of the function call.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Policy.on_global_var_update"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.on_global_var_update.html#ray.rllib.Policy.on_global_var_update">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">on_global_var_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_vars</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Called on an update to global vars.</span>

<span class="sd">        Args:</span>
<span class="sd">            global_vars: Global variables by str key, broadcast from the</span>
<span class="sd">                driver.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Store the current global time step (sum over all policies&#39; sample</span>
        <span class="c1"># steps).</span>
        <span class="c1"># Make sure, we keep global_timestep as a Tensor for tf-eager</span>
        <span class="c1"># (leads to memory leaks if not doing so).</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;tf2&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">global_vars</span><span class="p">[</span><span class="s2">&quot;timestep&quot;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">=</span> <span class="n">global_vars</span><span class="p">[</span><span class="s2">&quot;timestep&quot;</span><span class="p">]</span>
        <span class="c1"># Update our lifetime gradient update counter.</span>
        <span class="n">num_grad_updates</span> <span class="o">=</span> <span class="n">global_vars</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_grad_updates&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_grad_updates</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_grad_updates</span> <span class="o">=</span> <span class="n">num_grad_updates</span></div>

<div class="viewcode-block" id="Policy.export_checkpoint"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.export_checkpoint.html#ray.rllib.Policy.export_checkpoint">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">export_checkpoint</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">filename_prefix</span><span class="o">=</span><span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">policy_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PolicyState</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">checkpoint_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cloudpickle&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Exports Policy checkpoint to a local directory and returns an AIR Checkpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            export_dir: Local writable directory to store the AIR Checkpoint</span>
<span class="sd">                information into.</span>
<span class="sd">            policy_state: An optional PolicyState to write to disk. Used by</span>
<span class="sd">                `Algorithm.save_checkpoint()` to save on the additional</span>
<span class="sd">                `self.get_state()` calls of its different Policies.</span>
<span class="sd">            checkpoint_format: Either one of &#39;cloudpickle&#39; or &#39;msgpack&#39;.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; from ray.rllib.algorithms.ppo import PPOTorchPolicy</span>
<span class="sd">            &gt;&gt;&gt; policy = PPOTorchPolicy(...) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; policy.export_checkpoint(&quot;/tmp/export_dir&quot;) # doctest: +SKIP</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># `filename_prefix` should not longer be used as new Policy checkpoints</span>
        <span class="c1"># contain more than one file with a fixed filename structure.</span>
        <span class="k">if</span> <span class="n">filename_prefix</span> <span class="o">!=</span> <span class="n">DEPRECATED_VALUE</span><span class="p">:</span>
            <span class="n">deprecation_warning</span><span class="p">(</span>
                <span class="n">old</span><span class="o">=</span><span class="s2">&quot;Policy.export_checkpoint(filename_prefix=...)&quot;</span><span class="p">,</span>
                <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">checkpoint_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;cloudpickle&quot;</span><span class="p">,</span> <span class="s2">&quot;msgpack&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Value of `checkpoint_format` (</span><span class="si">{</span><span class="n">checkpoint_format</span><span class="si">}</span><span class="s2">) must either be &quot;</span>
                <span class="s2">&quot;&#39;cloudpickle&#39; or &#39;msgpack&#39;!&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">policy_state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">policy_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>

        <span class="c1"># Write main policy state file.</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">checkpoint_format</span> <span class="o">==</span> <span class="s2">&quot;cloudpickle&quot;</span><span class="p">:</span>
            <span class="n">policy_state</span><span class="p">[</span><span class="s2">&quot;checkpoint_version&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">CHECKPOINT_VERSION</span>
            <span class="n">state_file</span> <span class="o">=</span> <span class="s2">&quot;policy_state.pkl&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="n">state_file</span><span class="p">),</span> <span class="s2">&quot;w+b&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">policy_state</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.rllib.algorithms.algorithm_config</span> <span class="kn">import</span> <span class="n">AlgorithmConfig</span>

            <span class="n">msgpack</span> <span class="o">=</span> <span class="n">try_import_msgpack</span><span class="p">(</span><span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">policy_state</span><span class="p">[</span><span class="s2">&quot;checkpoint_version&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">CHECKPOINT_VERSION</span><span class="p">)</span>
            <span class="c1"># Serialize the config for msgpack dump&#39;ing.</span>
            <span class="n">policy_state</span><span class="p">[</span><span class="s2">&quot;policy_spec&quot;</span><span class="p">][</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">AlgorithmConfig</span><span class="o">.</span><span class="n">_serialize_dict</span><span class="p">(</span>
                <span class="n">policy_state</span><span class="p">[</span><span class="s2">&quot;policy_spec&quot;</span><span class="p">][</span><span class="s2">&quot;config&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">state_file</span> <span class="o">=</span> <span class="s2">&quot;policy_state.msgpck&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="n">state_file</span><span class="p">),</span> <span class="s2">&quot;w+b&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">msgpack</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">policy_state</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

        <span class="c1"># Write RLlib checkpoint json.</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="s2">&quot;rllib_checkpoint.json&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;Policy&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;checkpoint_version&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">policy_state</span><span class="p">[</span><span class="s2">&quot;checkpoint_version&quot;</span><span class="p">]),</span>
                    <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">checkpoint_format</span><span class="p">,</span>
                    <span class="s2">&quot;state_file&quot;</span><span class="p">:</span> <span class="n">state_file</span><span class="p">,</span>
                    <span class="s2">&quot;ray_version&quot;</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                    <span class="s2">&quot;ray_commit&quot;</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">__commit__</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="n">f</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Add external model files, if required.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;export_native_model_files&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">export_model</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">))</span></div>

<div class="viewcode-block" id="Policy.export_model"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.export_model.html#ray.rllib.Policy.export_model">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">export_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Exports the Policy&#39;s Model to local directory for serving.</span>

<span class="sd">        Note: The file format will depend on the deep learning framework used.</span>
<span class="sd">        See the child classed of Policy and their `export_model`</span>
<span class="sd">        implementations for more details.</span>

<span class="sd">        Args:</span>
<span class="sd">            export_dir: Local writable directory.</span>
<span class="sd">            onnx: If given, will export model in ONNX format. The</span>
<span class="sd">                value of this parameter set the ONNX OpSet version to use.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If a native DL-framework based model (e.g. a keras Model)</span>
<span class="sd">            cannot be saved to disk for various reasons.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.import_model_from_h5"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.import_model_from_h5.html#ray.rllib.Policy.import_model_from_h5">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">import_model_from_h5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">import_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Imports Policy from local file.</span>

<span class="sd">        Args:</span>
<span class="sd">            import_file: Local readable file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Policy.get_session"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_session.html#ray.rllib.Policy.get_session">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;tf1.Session&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns tf.Session object to use for computing actions or None.</span>

<span class="sd">        Note: This method only applies to TFPolicy sub-classes. All other</span>
<span class="sd">        sub-classes should expect a None to be returned from this method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The tf Session to use for computing actions and losses with</span>
<span class="sd">                this policy or None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Policy.get_host"><a class="viewcode-back" href="../../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.get_host.html#ray.rllib.Policy.get_host">[docs]</a>    <span class="k">def</span> <span class="nf">get_host</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the computer&#39;s network name.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The computer&#39;s networks name or an empty string, if the network</span>
<span class="sd">            name could not be determined.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">platform</span><span class="o">.</span><span class="n">node</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_get_num_gpus_for_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Decide on the number of CPU/GPU nodes this policy should run on.</span>

<span class="sd">        Return:</span>
<span class="sd">            0 if policy should run on CPU. &gt;0 if policy should run on 1 or</span>
<span class="sd">            more GPUs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">worker_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;worker_index&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">fake_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_fake_gpus&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">_mode</span><span class="p">()</span> <span class="o">==</span> <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">LOCAL_MODE</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">fake_gpus</span>
        <span class="p">):</span>
            <span class="c1"># If in local debugging mode, and _fake_gpus is not on.</span>
            <span class="n">num_gpus</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="n">worker_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># if we are in the new rl trainer world num_gpus is deprecated.</span>
            <span class="c1"># so use num_gpus_per_worker for policy sampling</span>
            <span class="c1"># we need this .get() syntax here to ensure backwards compatibility.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_enable_learner_api&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">num_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus_per_worker&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># If head node, take num_gpus.</span>
                <span class="n">num_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If worker node, take num_gpus_per_worker</span>
            <span class="n">num_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus_per_worker&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dev</span> <span class="o">=</span> <span class="s2">&quot;CPU&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dev</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">,</span> <span class="s2">&quot;fake-GPUs&quot;</span> <span class="k">if</span> <span class="n">fake_gpus</span> <span class="k">else</span> <span class="s2">&quot;GPUs&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Policy (worker=</span><span class="si">{}</span><span class="s2">) running on </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">worker_idx</span> <span class="k">if</span> <span class="n">worker_idx</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="n">dev</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">num_gpus</span>

    <span class="k">def</span> <span class="nf">_create_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Exploration</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates the Policy&#39;s Exploration object.</span>

<span class="sd">        This method only exists b/c some Trainers do not use TfPolicy nor</span>
<span class="sd">        TorchPolicy, but inherit directly from Policy. Others inherit from</span>
<span class="sd">        TfPolicy w/o using DynamicTFPolicy.</span>
<span class="sd">        TODO(sven): unify these cases.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Exploration: The Exploration object to be used by this Policy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;exploration&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span>

        <span class="n">exploration</span> <span class="o">=</span> <span class="n">from_config</span><span class="p">(</span>
            <span class="n">Exploration</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;exploration_config&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;StochasticSampling&quot;</span><span class="p">}),</span>
            <span class="n">action_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">policy_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_workers&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="n">worker_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;worker_index&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="n">framework</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;framework&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;framework&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">exploration</span>

    <span class="k">def</span> <span class="nf">_get_default_view_requirements</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a default ViewRequirements dict.</span>

<span class="sd">        Note: This is the base/maximum requirement dict, from which later</span>
<span class="sd">        some requirements will be subtracted again automatically to streamline</span>
<span class="sd">        data collection, batch creation, and data transfer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ViewReqDict: The default view requirements dict.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Default view requirements (equal to those that we would use before</span>
        <span class="c1"># the trajectory view API was introduced).</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(</span><span class="n">space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">NEXT_OBS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                <span class="n">data_col</span><span class="o">=</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">,</span>
                <span class="n">shift</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
                <span class="n">used_for_compute_actions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">ACTIONS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                <span class="n">space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">used_for_compute_actions</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">),</span>
            <span class="c1"># For backward compatibility with custom Models that don&#39;t specify</span>
            <span class="c1"># these explicitly (will be removed by Policy if not used).</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                <span class="n">data_col</span><span class="o">=</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">ACTIONS</span><span class="p">,</span> <span class="n">shift</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span>
            <span class="p">),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">REWARDS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(),</span>
            <span class="c1"># For backward compatibility with custom Models that don&#39;t specify</span>
            <span class="c1"># these explicitly (will be removed by Policy if not used).</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                <span class="n">data_col</span><span class="o">=</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">REWARDS</span><span class="p">,</span> <span class="n">shift</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">TERMINATEDS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">TRUNCATEDS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(</span><span class="n">used_for_compute_actions</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">EPS_ID</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">UNROLL_ID</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">AGENT_INDEX</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(),</span>
            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">T</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(),</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">_initialize_loss_from_dummy_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">auto_remove_unneeded_view_reqs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">stats_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Performs test calls through policy&#39;s model and loss.</span>

<span class="sd">        NOTE: This base method should work for define-by-run Policies such as</span>
<span class="sd">        torch and tf-eager policies.</span>

<span class="sd">        If required, will thereby detect automatically, which data views are</span>
<span class="sd">        required by a) the forward pass, b) the postprocessing, and c) the loss</span>
<span class="sd">        functions, and remove those from self.view_requirements that are not</span>
<span class="sd">        necessary for these computations (to save data storage and transfer).</span>

<span class="sd">        Args:</span>
<span class="sd">            auto_remove_unneeded_view_reqs: Whether to automatically</span>
<span class="sd">                remove those ViewRequirements records from</span>
<span class="sd">                self.view_requirements that are not needed.</span>
<span class="sd">            stats_fn (Optional[Callable[[Policy, SampleBatch], Dict[str,</span>
<span class="sd">                TensorType]]]): An optional stats function to be called after</span>
<span class="sd">                the loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_disable_initialize_loss_from_dummy_batch&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">return</span>
        <span class="c1"># Signal Policy that currently we do not like to eager/jit trace</span>
        <span class="c1"># any function calls. This is to be able to track, which columns</span>
        <span class="c1"># in the dummy batch are accessed by the different function (e.g.</span>
        <span class="c1"># loss) such that we can then adjust our view requirements.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_no_tracing</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># Save for later so that loss init does not change global timestep</span>
        <span class="n">global_ts_before_init</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">convert_to_numpy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">))</span>

        <span class="n">sample_batch_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_divisibility_req</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">],</span>  <span class="c1"># Don&#39;t go over the asked batch size.</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dummy_batch_from_view_requirements</span><span class="p">(</span>
            <span class="n">sample_batch_size</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_tensor_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">)</span>
        <span class="c1"># With RL modules you want the explore flag to be True for initialization of the</span>
        <span class="c1"># tensors and placeholder you&#39;d need for training.</span>
        <span class="n">explore</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_enable_rl_module_api&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">actions</span><span class="p">,</span> <span class="n">state_outs</span><span class="p">,</span> <span class="n">extra_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_actions_from_input_dict</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="n">explore</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">view_req</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">accessed_keys</span><span class="p">:</span>
                <span class="n">view_req</span><span class="o">.</span><span class="n">used_for_compute_actions</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># Add all extra action outputs to view reqirements (these may be</span>
        <span class="c1"># filtered out later again, if not needed for postprocessing or loss).</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">extra_outs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
                    <span class="c1"># the assumption is that value is a nested_dict of np.arrays leaves</span>
                    <span class="n">space</span> <span class="o">=</span> <span class="n">get_gym_space_from_struct_of_tensors</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                        <span class="n">space</span><span class="o">=</span><span class="n">space</span><span class="p">,</span> <span class="n">used_for_compute_actions</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;policy.compute_actions_from_input_dict() returns an &quot;</span>
                        <span class="s2">&quot;extra action output that is neither a numpy array nor a dict.&quot;</span>
                    <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">accessed_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">used_for_compute_actions</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># TODO (kourosh) Why did we use to make used_for_compute_actions True here?</span>
        <span class="n">new_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dummy_batch_from_view_requirements</span><span class="p">(</span><span class="n">sample_batch_size</span><span class="p">)</span>
        <span class="c1"># Make sure the dummy_batch will return numpy arrays when accessed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">set_get_interceptor</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># try to re-use the output of the previous run to avoid overriding things that</span>
        <span class="c1"># would break (e.g. scale = 0 of Normal distribution cannot be zero)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">new_batch</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

        <span class="c1"># Make sure the book-keeping of dummy_batch keys are reset to correcly track</span>
        <span class="c1"># what is accessed, what is added and what&#39;s deleted from now on.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">accessed_keys</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">deleted_keys</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">added_keys</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="p">:</span>
            <span class="c1"># Policies with RLModules don&#39;t have an exploration object.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">postprocess_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">)</span>

        <span class="n">postprocessed_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocess_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">)</span>
        <span class="n">seq_lens</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">state_outs</span><span class="p">:</span>
            <span class="n">B</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># For RNNs, have B=4, T=[depends on sample_batch_size]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="s2">&quot;state_in_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="n">postprocessed_batch</span><span class="p">:</span>
                <span class="n">postprocessed_batch</span><span class="p">[</span><span class="s2">&quot;state_in_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">postprocessed_batch</span><span class="p">[</span>
                    <span class="s2">&quot;state_in_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="p">][:</span><span class="n">B</span><span class="p">]</span>
                <span class="k">if</span> <span class="s2">&quot;state_out_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="n">postprocessed_batch</span><span class="p">:</span>
                    <span class="n">postprocessed_batch</span><span class="p">[</span><span class="s2">&quot;state_out_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">postprocessed_batch</span><span class="p">[</span>
                        <span class="s2">&quot;state_out_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="p">][:</span><span class="n">B</span><span class="p">]</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">sample_batch_size</span> <span class="o">//</span> <span class="n">B</span>
            <span class="n">seq_lens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">seq_len</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">postprocessed_batch</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">]</span> <span class="o">=</span> <span class="n">seq_lens</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_enable_learner_api&quot;</span><span class="p">):</span>
            <span class="c1"># Switch on lazy to-tensor conversion on `postprocessed_batch`.</span>
            <span class="n">train_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_tensor_dict</span><span class="p">(</span><span class="n">postprocessed_batch</span><span class="p">)</span>
            <span class="c1"># Calling loss, so set `is_training` to True.</span>
            <span class="n">train_batch</span><span class="o">.</span><span class="n">set_training</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">seq_lens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">train_batch</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">]</span> <span class="o">=</span> <span class="n">seq_lens</span>
            <span class="n">train_batch</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">count</span>

            <span class="c1"># Call the loss function, if it exists.</span>
            <span class="c1"># TODO(jungong) : clean up after all agents get migrated.</span>
            <span class="c1"># We should simply do self.loss(...) here.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">is_overridden</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;in_evaluation&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">)</span>
            <span class="c1"># Call the stats fn, if given.</span>
            <span class="c1"># TODO(jungong) : clean up after all agents get migrated.</span>
            <span class="c1"># We should simply do self.stats_fn(train_batch) here.</span>
            <span class="k">if</span> <span class="n">stats_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">stats_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;stats_fn&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;in_evaluation&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stats_fn</span><span class="p">(</span><span class="n">train_batch</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># This is not needed to run a training with the Learner API, but useful if</span>
            <span class="c1"># we want to create a batche of data for training from view requirements.</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">postprocessed_batch</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span>
                <span class="nb">set</span><span class="p">(</span><span class="n">new_batch</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="p">):</span>
                <span class="c1"># Add all columns generated by postprocessing to view requirements.</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span> <span class="ow">and</span> <span class="n">key</span> <span class="o">!=</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                        <span class="n">used_for_compute_actions</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>

        <span class="c1"># Re-enable tracing.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_no_tracing</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Add new columns automatically to view-reqs.</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_enable_learner_api&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">auto_remove_unneeded_view_reqs</span>
        <span class="p">):</span>
            <span class="c1"># Add those needed for postprocessing and training.</span>
            <span class="n">all_accessed_keys</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">train_batch</span><span class="o">.</span><span class="n">accessed_keys</span>
                <span class="o">|</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">accessed_keys</span>
                <span class="o">|</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">added_keys</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">all_accessed_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span> <span class="ow">and</span> <span class="n">key</span> <span class="o">!=</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                        <span class="n">used_for_compute_actions</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="ow">or</span> <span class="n">is_overridden</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">):</span>
                <span class="c1"># Tag those only needed for post-processing (with some</span>
                <span class="c1"># exceptions).</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">accessed_keys</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">train_batch</span><span class="o">.</span><span class="n">accessed_keys</span>
                        <span class="ow">and</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span>
                        <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">view_requirements</span>
                        <span class="ow">and</span> <span class="n">key</span>
                        <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">EPS_ID</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">AGENT_INDEX</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">UNROLL_ID</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">TERMINATEDS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">TRUNCATEDS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">REWARDS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                        <span class="p">]</span>
                    <span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">used_for_training</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="c1"># Remove those not needed at all (leave those that are needed</span>
                <span class="c1"># by Sampler to properly execute sample collection). Also always leave</span>
                <span class="c1"># TERMINATEDS, TRUNCATEDS, REWARDS, INFOS, no matter what.</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_accessed_keys</span>
                        <span class="ow">and</span> <span class="n">key</span>
                        <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">EPS_ID</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">AGENT_INDEX</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">UNROLL_ID</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">TERMINATEDS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">TRUNCATEDS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">REWARDS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">,</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                        <span class="p">]</span>
                        <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">view_requirements</span>
                    <span class="p">):</span>
                        <span class="c1"># If user deleted this key manually in postprocessing</span>
                        <span class="c1"># fn, warn about it and do not remove from</span>
                        <span class="c1"># view-requirements.</span>
                        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">deleted_keys</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                                <span class="s2">&quot;SampleBatch key &#39;</span><span class="si">{}</span><span class="s2">&#39; was deleted manually in &quot;</span>
                                <span class="s2">&quot;postprocessing function! RLlib will &quot;</span>
                                <span class="s2">&quot;automatically remove non-used items from the &quot;</span>
                                <span class="s2">&quot;data stream. Remove the `del` from your &quot;</span>
                                <span class="s2">&quot;postprocessing function.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                            <span class="p">)</span>
                        <span class="c1"># If we are not writing output to disk, save to erase</span>
                        <span class="c1"># this key to save space in the sample batch.</span>
                        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">=</span> <span class="n">global_ts_before_init</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">global_ts_before_init</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Variable self.global_timestep of policy </span><span class="si">{}</span><span class="s2"> needs to be &quot;</span>
                <span class="s2">&quot;either of type `int` or `tf.Variable`, &quot;</span>
                <span class="s2">&quot;but is of type </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">))</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_dummy_batch_from_view_requirements</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SampleBatch</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates a numpy dummy batch based on the Policy&#39;s view requirements.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size: The size of the batch to create.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, TensorType]: The dummy batch containing all zero values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">view_col</span><span class="p">,</span> <span class="n">view_req</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">data_col</span> <span class="o">=</span> <span class="n">view_req</span><span class="o">.</span><span class="n">data_col</span> <span class="ow">or</span> <span class="n">view_col</span>
            <span class="c1"># Flattened dummy batch.</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">view_req</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">)))</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">data_col</span> <span class="o">==</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span>
                    <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;_disable_preprocessor_api&quot;</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="ow">or</span> <span class="p">(</span>
                    <span class="n">data_col</span> <span class="o">==</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">ACTIONS</span>
                    <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_disable_action_flattening&quot;</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">):</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_action_shape</span><span class="p">(</span>
                    <span class="n">view_req</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="n">framework</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;framework&quot;</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">ret</span><span class="p">[</span><span class="n">view_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="c1"># Non-flattened dummy batch.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Range of indices on time-axis, e.g. &quot;-50:-1&quot;.</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">view_req</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">):</span>
                    <span class="n">time_size</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">view_req</span><span class="o">.</span><span class="n">shift_arr</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">view_req</span><span class="o">.</span><span class="n">shift_arr</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="n">ret</span><span class="p">[</span><span class="n">view_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_dummy_batch_for_space</span><span class="p">(</span>
                        <span class="n">view_req</span><span class="o">.</span><span class="n">space</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">time_size</span><span class="o">=</span><span class="n">time_size</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">ret</span><span class="p">[</span><span class="n">view_col</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">view_req</span><span class="o">.</span><span class="n">space</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>

        <span class="c1"># Due to different view requirements for the different columns,</span>
        <span class="c1"># columns in the resulting batch may not all have the same batch size.</span>
        <span class="k">return</span> <span class="n">SampleBatch</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_model_view_requirements_from_init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Uses Model&#39;s (or this Policy&#39;s) init state to add needed ViewReqs.</span>

<span class="sd">        Can be called from within a Policy to make sure RNNs automatically</span>
<span class="sd">        update their internal state-related view requirements.</span>
<span class="sd">        Changes the `self.view_requirements` dict.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_init_state_automatically_added</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">obj</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;view_requirements&quot;</span><span class="p">):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">view_requirements</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">ViewRequirement</span><span class="p">(</span><span class="n">space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="n">view_reqs</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">view_requirements</span>
        <span class="c1"># Add state-ins to this model&#39;s view.</span>
        <span class="n">init_state</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;get_initial_state&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">callable</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">):</span>
            <span class="n">init_state</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Add this functionality automatically for new native model API.</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">tf</span>
                <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">)</span>
                <span class="ow">and</span> <span class="s2">&quot;state_in_0&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">view_reqs</span>
            <span class="p">):</span>
                <span class="n">obj</span><span class="o">.</span><span class="n">get_initial_state</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">[</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">view_req</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">view_req</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">view_requirements</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;state_in_&quot;</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">obj</span><span class="o">.</span><span class="n">get_initial_state</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="s2">&quot;state_in_0&quot;</span> <span class="ow">in</span> <span class="n">view_reqs</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_recurrent</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="kc">True</span>

        <span class="c1"># Make sure auto-generated init-state view requirements get added</span>
        <span class="c1"># to both Policy and Model, no matter what.</span>
        <span class="n">view_reqs</span> <span class="o">=</span> <span class="p">[</span><span class="n">view_reqs</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">]</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;view_requirements&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">init_state</span><span class="p">):</span>
            <span class="c1"># Allow `state` to be either a Space (use zeros as initial values)</span>
            <span class="c1"># or any value (e.g. a dict or a non-zero tensor).</span>
            <span class="n">fw</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">np</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">torch</span>
                <span class="k">if</span> <span class="n">torch</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">fw</span><span class="p">:</span>
                <span class="n">space</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">Box</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">state</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">fw</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">state</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">)</span> <span class="k">else</span> <span class="n">state</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">space</span> <span class="o">=</span> <span class="n">state</span>
            <span class="k">for</span> <span class="n">vr</span> <span class="ow">in</span> <span class="n">view_reqs</span><span class="p">:</span>
                <span class="c1"># Only override if user has not already provided</span>
                <span class="c1"># custom view-requirements for state_in_n.</span>
                <span class="k">if</span> <span class="s2">&quot;state_in_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vr</span><span class="p">:</span>
                    <span class="n">vr</span><span class="p">[</span><span class="s2">&quot;state_in_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                        <span class="s2">&quot;state_out_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
                        <span class="n">shift</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">used_for_compute_actions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">batch_repeat_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                            <span class="s2">&quot;max_seq_len&quot;</span><span class="p">,</span> <span class="mi">1</span>
                        <span class="p">),</span>
                        <span class="n">space</span><span class="o">=</span><span class="n">space</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="c1"># Only override if user has not already provided</span>
                <span class="c1"># custom view-requirements for state_out_n.</span>
                <span class="k">if</span> <span class="s2">&quot;state_out_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vr</span><span class="p">:</span>
                    <span class="n">vr</span><span class="p">[</span><span class="s2">&quot;state_out_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
                        <span class="n">space</span><span class="o">=</span><span class="n">space</span><span class="p">,</span> <span class="n">used_for_training</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">)</span>

    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;get_exploration_state&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_exploration_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_exploration_state</span><span class="p">()</span></div>


<span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">get_gym_space_from_struct_of_tensors</span><span class="p">(</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Mapping</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="n">value_dict</span> <span class="o">=</span> <span class="n">NestedDict</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">struct</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">value_dict</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">get_gym_space_from_struct_of_spaces</span><span class="p">(</span><span class="n">struct</span><span class="o">.</span><span class="n">asdict</span><span class="p">())</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unsupported type of value </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2"> passed &quot;</span>
            <span class="s2">&quot;to get_gym_space_from_struct_of_tensors. Only Nested dict with &quot;</span>
            <span class="s2">&quot;np.ndarray leaves or an np.ndarray are supported.&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">space</span>


<span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">get_gym_space_from_struct_of_spaces</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span>
            <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">get_gym_space_from_struct_of_spaces</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Tuple</span><span class="p">([</span><span class="n">get_gym_space_from_struct_of_spaces</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">value</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span>
        <span class="p">),</span> <span class="s2">&quot;The struct of spaces should only contain dicts, tiples and primitive &quot;</span>
        <span class="s2">&quot;gym spaces.&quot;</span>
        <span class="k">return</span> <span class="n">value</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>