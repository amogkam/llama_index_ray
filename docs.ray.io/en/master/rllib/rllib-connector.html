
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Connectors (Alpha) &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/versionwarning.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../_static/js/docsearch.js"></script>
    <script src="../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../_static/js/termynal.js"></script>
    <script defer="defer" src="../_static/js/custom.js"></script>
    <script defer="defer" src="../_static/js/top-navigation.js"></script>
    <script src="../_static/js/tags.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/rllib/rllib-connector.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="RL Modules (Alpha)" href="rllib-rlmodule.html" />
    <link rel="prev" title="Catalog (Alpha)" href="rllib-catalogs.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "rllib/rllib-connector", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Ray RLlib
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-training.html">
     Getting Started with RLlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rllib-env.html">
     Environments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-algorithms.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="user-guides.html">
     User Guides
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-advanced-api.html">
       Advanced Python APIs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-models.html">
       Models, Preprocessors, and Action Distributions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-saving-and-loading-algos-and-policies.html">
       Saving and Loading your RL Algorithms and Policies
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-concepts.html">
       How To Customize Policies
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-sample-collection.html">
       Sample Collections and Trajectory Views
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-replay-buffers.html">
       Replay Buffers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-offline.html">
       Working With Offline Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-catalogs.html">
       Catalog (Alpha)
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="rllib-connector.html#">
       Connectors (Alpha)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-rlmodule.html">
       RL Modules (Alpha)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-fault-tolerance.html">
       Fault Tolerance And Elastic Training
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-dev.html">
       How To Contribute to RLlib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-cli.html">
       Working with the RLlib CLI
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-examples.html">
     Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="package_ref/index.html">
     Ray RLlib API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Frllib/rllib-connector.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/rllib/rllib-connector.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/rllib/rllib-connector.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#key-concepts">
   Key Concepts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#agentconnector">
     AgentConnector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#actionconnector">
     ActionConnector
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#common-data-types">
   Common Data Types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#agentconnectordatatype">
     AgentConnectorDataType
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#agentconnectorsoutput">
     AgentConnectorsOutput
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#actionconnectordatatype">
     ActionConnectorDataType
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#advanced-connectors">
   Advanced Connectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#policy-checkpoint">
   Policy Checkpoint
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#serving-and-inference">
   Serving and Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#adapting-a-policy-for-different-environments">
   Adapting a Policy for Different Environments
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#end-to-end-example">
   End-to-end Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#notable-todos">
   Notable TODOs
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Connectors (Alpha)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#key-concepts">
   Key Concepts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#agentconnector">
     AgentConnector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#actionconnector">
     ActionConnector
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#common-data-types">
   Common Data Types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#agentconnectordatatype">
     AgentConnectorDataType
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#agentconnectorsoutput">
     AgentConnectorsOutput
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-connector.html#actionconnectordatatype">
     ActionConnectorDataType
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#advanced-connectors">
   Advanced Connectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#policy-checkpoint">
   Policy Checkpoint
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#serving-and-inference">
   Serving and Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#adapting-a-policy-for-different-environments">
   Adapting a Policy for Different Environments
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#end-to-end-example">
   End-to-end Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-connector.html#notable-todos">
   Notable TODOs
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/top.png" /></a>
<div class="bottom-right-promo-banner docutils">
<a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/square.png" /></a>
</div>
<section id="connectors-alpha">
<h1>Connectors (Alpha)<a class="headerlink" href="rllib-connector.html#connectors-alpha" title="Permalink to this headline">#</a></h1>
<p>Connector are components that handle transformations on inputs and outputs of a given RL policy, with the goal of improving
the durability and maintainability of <a class="reference internal" href="rllib-saving-and-loading-algos-and-policies.html#rllib-saving-and-loading-algos-and-policies-docs"><span class="std std-ref">RLlib’s Policy checkpoints</span></a>.</p>
<p>RLlib algorithms usually require one or more <em>user environments</em> and <em>policies</em> (usually a neural network).</p>
<p>Data observed from the environments usually go through multiple steps of preprocessing before they reach
the policy, while the output of the policy also gets transformed multiple times before they are used to control
specific agents in the environments.</p>
<p>By consolidating these transformations under the framework of connectors, users of RLlib will be able to:</p>
<ul class="simple">
<li><p>Restore and deploy individual RLlib policies without having to restore training-related logics of RLlib Algorithms.</p></li>
<li><p>Ensure policies are more durable than the algorithms they get trained with.</p></li>
<li><p>Allow policies to be adapted to work with different versions of an environment.</p></li>
<li><p>Run inference with RLlib policies without worrying about the exact trajectory view requirements or state inputs.</p></li>
</ul>
<p>Connectors can be enabled by setting the <code class="docutils literal notranslate"><span class="pre">enable_connectors</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">True</span></code> with <code class="docutils literal notranslate"><span class="pre">AlgorithmConfig.rollouts()</span></code> API.</p>
<section id="key-concepts">
<h2>Key Concepts<a class="headerlink" href="rllib-connector.html#key-concepts" title="Permalink to this headline">#</a></h2>
<img alt="../_images/connector-diagram.svg" class="align-center" src="../_images/connector-diagram.svg" /><p>We have two classes of connectors. The first is an <code class="docutils literal notranslate"><span class="pre">AgentConnector</span></code>, which is used to transform observed data from environments to the policy.
The second is an <code class="docutils literal notranslate"><span class="pre">ActionConnector</span></code>, which is used to transform the outputs from the policy to actions.</p>
<section id="agentconnector">
<h3>AgentConnector<a class="headerlink" href="rllib-connector.html#agentconnector" title="Permalink to this headline">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">AgentConnectors</span></code> handle the job of transforming environment observation data into a format that is understood by
the policy (e.g., flattening complex nested observations into a flat tensor). The high-level APIs are:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">AgentConnector</span><span class="p">(</span><span class="n">Connector</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">acd_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">AgentConnectorDataType</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">AgentConnectorDataType</span><span class="p">]:</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">ac_data</span><span class="p">:</span> <span class="n">AgentConnectorDataType</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AgentConnectorDataType</span><span class="p">:</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">on_policy_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">ActionConnectorDataType</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>AgentConnector operates on a list of observation data.
The list is constructed by grouping together observations from agents that are mapped to a same policy.</p>
<p>This setup is useful for certain multi-agent use cases where individual observations may need to be
modified based on data from other agents.
This can also be useful if users who need to construct meta-observations, e.g., build a graph as input
to the policy from individual agent observations.</p>
<p>For convenience, if an <code class="docutils literal notranslate"><span class="pre">AgentConnector</span></code> does not operate on the full list of agent data, it can be
implemented by simply overriding the <code class="docutils literal notranslate"><span class="pre">transform()</span></code> API.</p>
<p>AgentConnectors also provide a way for recording the output of the policy at the current time step
(prior to transformation via ActionConnectors) to be later used for inference in the next time step.
This is done through the <code class="docutils literal notranslate"><span class="pre">on_policy_output()</span></code> API call and is useful when your policy is a
recurrent network, attention network, or auto-regressive model.</p>
</section>
<section id="actionconnector">
<h3>ActionConnector<a class="headerlink" href="rllib-connector.html#actionconnector" title="Permalink to this headline">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ActionConnector</span></code> has a simpler API, which operates on individual actions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ActionConnector</span><span class="p">(</span><span class="n">Connector</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">ac_data</span><span class="p">:</span> <span class="n">ActionConnectorDataType</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionConnectorDataType</span><span class="p">:</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">ac_data</span><span class="p">:</span> <span class="n">ActionConnectorDataType</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionConnectorDataType</span><span class="p">:</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>In this case, <code class="docutils literal notranslate"><span class="pre">__call__</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> are equivalent. Users may choose to override either
API to implement an ActionConnector.</p>
</section>
</section>
<section id="common-data-types">
<h2>Common Data Types<a class="headerlink" href="rllib-connector.html#common-data-types" title="Permalink to this headline">#</a></h2>
<section id="agentconnectordatatype">
<h3>AgentConnectorDataType<a class="headerlink" href="rllib-connector.html#agentconnectordatatype" title="Permalink to this headline">#</a></h3>
<p>Per-agent observation data that goes through an <code class="docutils literal notranslate"><span class="pre">AgentConnector</span></code> is in the format of <code class="docutils literal notranslate"><span class="pre">AgentConnectorDataType</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ExperimentalAPI</span>
<span class="k">class</span> <span class="nc">AgentConnectorDataType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Data type that is fed into and yielded from agent connectors.</span>

<span class="sd">    Args:</span>
<span class="sd">        env_id: ID of the environment.</span>
<span class="sd">        agent_id: ID to help identify the agent from which the data is received.</span>
<span class="sd">        data: A payload (``data``). With RLlib&#39;s default sampler, the payload</span>
<span class="sd">            is a dictionary of arbitrary data columns (obs, rewards, terminateds,</span>
<span class="sd">            truncateds, etc).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">agent_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_id</span> <span class="o">=</span> <span class="n">env_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent_id</span> <span class="o">=</span> <span class="n">agent_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>


</pre></div>
</div>
</section>
<section id="agentconnectorsoutput">
<h3>AgentConnectorsOutput<a class="headerlink" href="rllib-connector.html#agentconnectorsoutput" title="Permalink to this headline">#</a></h3>
<p>The output from RLlib’s default agent connector pipeline is in <code class="docutils literal notranslate"><span class="pre">AgentConnectorsOutput</span></code> format.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ExperimentalAPI</span>
<span class="k">class</span> <span class="nc">AgentConnectorsOutput</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Final output data type of agent connectors.</span>

<span class="sd">    Args are populated depending on the AgentConnector settings.</span>
<span class="sd">    The branching happens in ViewRequirementAgentConnector.</span>

<span class="sd">    Args:</span>
<span class="sd">        raw_dict: The raw input dictionary that sampler can use to</span>
<span class="sd">            build episodes and training batches.</span>
<span class="sd">            This raw dict also gets passed into ActionConnectors in case</span>
<span class="sd">            it contains data useful for action adaptation (e.g. action masks).</span>
<span class="sd">        sample_batch: The SampleBatch that can be immediately used for</span>
<span class="sd">            querying the policy for next action.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">raw_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorStructType</span><span class="p">],</span> <span class="n">sample_batch</span><span class="p">:</span> <span class="s2">&quot;SampleBatch&quot;</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">raw_dict</span> <span class="o">=</span> <span class="n">raw_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_batch</span> <span class="o">=</span> <span class="n">sample_batch</span>


</pre></div>
</div>
<p>Note that in addition to the processed sample batch, which can be used for running the policy
forward pass, <code class="docutils literal notranslate"><span class="pre">AgentConnectorsOutput</span></code> also provides the original raw input dict, because it
sometimes contains data required for downstream processing (e.g. action masks).</p>
</section>
<section id="actionconnectordatatype">
<h3>ActionConnectorDataType<a class="headerlink" href="rllib-connector.html#actionconnectordatatype" title="Permalink to this headline">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ActionConnectorDataType</span></code> is the data type <code class="docutils literal notranslate"><span class="pre">ActionConnector</span></code> deals with.
It is basically env and agent IDs, input_dict, and <code class="docutils literal notranslate"><span class="pre">PolicyOutputType</span></code>.
The raw input dict is made available for action connectors in case some of the
data fields are needed for adapting action outputs, for example action masks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ExperimentalAPI</span>
<span class="k">class</span> <span class="nc">ActionConnectorDataType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Data type that is fed into and yielded from agent connectors.</span>

<span class="sd">    Args:</span>
<span class="sd">        env_id: ID of the environment.</span>
<span class="sd">        agent_id: ID to help identify the agent from which the data is received.</span>
<span class="sd">        input_dict: Input data that was passed into the policy.</span>
<span class="sd">            Sometimes output must be adapted based on the input, for example</span>
<span class="sd">            action masking. So the entire input data structure is provided here.</span>
<span class="sd">        output: An object of PolicyOutputType. It is is composed of the</span>
<span class="sd">            action output, the internal state output, and additional data fetches.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">env_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">agent_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">input_dict</span><span class="p">:</span> <span class="n">TensorStructType</span><span class="p">,</span>
        <span class="n">output</span><span class="p">:</span> <span class="n">PolicyOutputType</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_id</span> <span class="o">=</span> <span class="n">env_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent_id</span> <span class="o">=</span> <span class="n">agent_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dict</span> <span class="o">=</span> <span class="n">input_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span>


</pre></div>
</div>
<p>Before, users of RLlib policies would have to come up with the right observation and state inputs
before they can call a policy. With agent connectors, this task is taken care of automatically.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">PolicyOutputType</span> <span class="o">=</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">,</span> <span class="n">StateBatches</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]</span>
</pre></div>
</div>
</section>
</section>
<section id="advanced-connectors">
<h2>Advanced Connectors<a class="headerlink" href="rllib-connector.html#advanced-connectors" title="Permalink to this headline">#</a></h2>
<p>Lambda Connector helps turn simple transformation functions into agent or action
connectors without having users worry about the high-level list or non-list APIs.
Lambda Connector has separate agent and action versions, for example:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-0">
Lambda Agent Connector</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># An example agent connector that filters INFOS column out of</span>
<span class="c1"># observation data.</span>
<span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="n">d</span><span class="p">:</span> <span class="n">ActionConnectorDataType</span><span class="p">):</span>
    <span class="k">del</span> <span class="n">d</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">d</span>

<span class="n">FilterInfosColumnAgentConnector</span> <span class="o">=</span> <span class="n">register_lambda_agent_connector</span><span class="p">(</span>
    <span class="s2">&quot;FilterInfosColumnAgentConnector&quot;</span><span class="p">,</span> <span class="nb">filter</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-1">
Lambda Action Connector</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># An example action connector that scales actions output by the</span>
<span class="c1"># policy by a factor of 2.</span>
<span class="n">ScaleActionConnector</span> <span class="o">=</span> <span class="n">register_lambda_action_connector</span><span class="p">(</span>
    <span class="s2">&quot;ScaleActionConnector&quot;</span><span class="p">,</span>
    <span class="k">lambda</span> <span class="n">actions</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">fetches</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">actions</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">fetches</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Multiple connectors can be composed into a <code class="docutils literal notranslate"><span class="pre">ConnectorPipeline</span></code>, which handles
proper running of all children connectors in sequence and provides basic operations to modify and update the composition of connectors.</p>
<p><code class="docutils literal notranslate"><span class="pre">ConnectorPipeline</span></code> also has agent and action versions:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-2" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-2">
AgentConnectorPipeline</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example construction of an AgentConnectorPipeline.</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">ActionConnectorPipeline</span><span class="p">(</span>
    <span class="n">ctx</span><span class="p">,</span>
    <span class="p">[</span><span class="n">ClipRewardAgentConnector</span><span class="p">(),</span> <span class="n">ViewRequirementAgentConnector</span><span class="p">()]</span>
<span class="p">)</span>

<span class="c1"># For demonstration purpose, we will add an ObsPreprocessorConnector</span>
<span class="c1"># in front of the ViewRequirementAgentConnector.</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">insert_before</span><span class="p">(</span><span class="s2">&quot;ViewRequirementAgentConnector&quot;</span><span class="p">,</span> <span class="n">ObsPreprocessorConnector</span><span class="p">())</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-3">
Action Lambda Connector</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example construction of an ActionConnectorPipeline.</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">ActionConnectorPipeline</span><span class="p">(</span>
    <span class="n">ctx</span><span class="p">,</span>
    <span class="p">[</span><span class="n">ConvertToNumpyConnector</span><span class="p">(),</span> <span class="n">ClipActionsConnector</span><span class="p">(),</span> <span class="n">ImmutableActionsConnector</span><span class="p">()]</span>
<span class="p">)</span>

<span class="c1"># For demonstration purpose, we will drop the last ImmutableActionsConnector here.</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;ImmutableActionsConnector&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="policy-checkpoint">
<h2>Policy Checkpoint<a class="headerlink" href="rllib-connector.html#policy-checkpoint" title="Permalink to this headline">#</a></h2>
<p>If connectors are enabled, RLlib will try to save policy checkpoints in properly serialized formats instead of
relying on python pickling. Eventually, the goal is to save policy checkpoints in serialized JSON files
to ensure maximum compatibility between RLlib and python versions.</p>
<p>When enabled, the configurations of agent and action connectors will get serialized and saved with checkpointed
policy states.
These connectors, together with the specific transformations they represent,
can be easily recovered (by RLlib-provided utils) to simplify deployment and inference use cases.</p>
<p>You can read more on <a class="reference internal" href="rllib-saving-and-loading-algos-and-policies.html#rllib-saving-and-loading-algos-and-policies-docs"><span class="std std-ref">Policy checkpoints here</span></a>.</p>
</section>
<section id="serving-and-inference">
<h2>Serving and Inference<a class="headerlink" href="rllib-connector.html#serving-and-inference" title="Permalink to this headline">#</a></h2>
<p>With connectors essentially checkpointing all the transformations used during training,
policies can be easily restored without the original algorithm for local inference,
as demonstrated by the following Cartpole example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># Restore policy.</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">Policy</span><span class="o">.</span><span class="n">from_checkpoint</span><span class="p">(</span>
        <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint_path</span><span class="p">,</span>
        <span class="n">policy_ids</span><span class="o">=</span><span class="p">[</span><span class="n">policy_id</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="c1"># Run CartPole.</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">terminated</span> <span class="o">=</span> <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">terminated</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">truncated</span><span class="p">:</span>
        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Use local_policy_inference() to run inference, so we do not have to</span>
        <span class="c1"># provide policy states or extra fetch dictionaries.</span>
        <span class="c1"># &quot;env_1&quot; and &quot;agent_1&quot; are dummy env and agent IDs to run connectors with.</span>
        <span class="n">policy_outputs</span> <span class="o">=</span> <span class="n">local_policy_inference</span><span class="p">(</span>
            <span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;env_1&quot;</span><span class="p">,</span> <span class="s2">&quot;agent_1&quot;</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">policy_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">policy_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>

        <span class="c1"># Step environment forward one more step.</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
</pre></div>
</div>
<p>RLlib will also provide utils soon to make server/client deployment of trained policies much easier.
See <a class="reference internal" href="rllib-connector.html#notable-todos">Notable TODOs</a>.</p>
</section>
<section id="adapting-a-policy-for-different-environments">
<h2>Adapting a Policy for Different Environments<a class="headerlink" href="rllib-connector.html#adapting-a-policy-for-different-environments" title="Permalink to this headline">#</a></h2>
<p>It is not uncommon for user environments to go through active development iterations.
Policies trained with an older version of an environment may be rendered useless for updated environments.
While env wrapper helps with this problem in many cases, connectors allow policies trained with
different environments to work together at the same time.</p>
<p>Here is an example demonstrating adaptation of a policy trained for the standard Cartpole environment
for a new mock Cartpole environment that returns additional features and requires extra action inputs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyCartPole</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A mock CartPole environment.</span>

<span class="sd">    Gives 2 additional observation states and takes 2 discrete actions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">MultiDiscrete</span><span class="p">(</span><span class="n">nvec</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
        <span class="c1"># Take the first action.</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="c1"># Fake additional data points to the obs.</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">obs</span><span class="p">,</span> <span class="p">[</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">obs</span><span class="p">,</span> <span class="p">[</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">])),</span> <span class="n">info</span>


<span class="c1"># Custom agent connector to drop the last 2 feature values.</span>
<span class="k">def</span> <span class="nf">v2_to_v1_obs</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorStructType</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorStructType</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">NEXT_OBS</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">NEXT_OBS</span><span class="p">][:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="c1"># Agent connector that adapts observations from the new CartPole env</span>
<span class="c1"># into old format.</span>
<span class="n">V2ToV1ObsAgentConnector</span> <span class="o">=</span> <span class="n">register_lambda_agent_connector</span><span class="p">(</span>
    <span class="s2">&quot;V2ToV1ObsAgentConnector&quot;</span><span class="p">,</span> <span class="n">v2_to_v1_obs</span>
<span class="p">)</span>


<span class="c1"># Custom action connector to add a placeholder action as the addtional action input.</span>
<span class="k">def</span> <span class="nf">v1_to_v2_action</span><span class="p">(</span>
    <span class="n">actions</span><span class="p">:</span> <span class="n">TensorStructType</span><span class="p">,</span> <span class="n">states</span><span class="p">:</span> <span class="n">StateBatches</span><span class="p">,</span> <span class="n">fetches</span><span class="p">:</span> <span class="n">Dict</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PolicyOutputType</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">actions</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="n">states</span><span class="p">,</span> <span class="n">fetches</span>


<span class="c1"># Action connector that adapts action outputs from the old policy</span>
<span class="c1"># into new actions for the mock environment.</span>
<span class="n">V1ToV2ActionConnector</span> <span class="o">=</span> <span class="n">register_lambda_action_connector</span><span class="p">(</span>
    <span class="s2">&quot;V1ToV2ActionConnector&quot;</span><span class="p">,</span> <span class="n">v1_to_v2_action</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">policy_id</span><span class="p">):</span>
    <span class="c1"># Restore policy.</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">Policy</span><span class="o">.</span><span class="n">from_checkpoint</span><span class="p">(</span>
        <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint_path</span><span class="p">,</span>
        <span class="n">policy_ids</span><span class="o">=</span><span class="p">[</span><span class="n">policy_id</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="c1"># Adapt policy trained for standard CartPole to the new env.</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="n">ConnectorContext</span> <span class="o">=</span> <span class="n">ConnectorContext</span><span class="o">.</span><span class="n">from_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>

    <span class="c1"># When this policy was trained, it relied on FlattenDataAgentConnector</span>
    <span class="c1"># to add a batch dimension to single observations.</span>
    <span class="c1"># This is not necessary anymore, so we first remove the previously used</span>
    <span class="c1"># FlattenDataAgentConnector.</span>
    <span class="n">policy</span><span class="o">.</span><span class="n">agent_connectors</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;FlattenDataAgentConnector&quot;</span><span class="p">)</span>

    <span class="c1"># We then add the two adapter connectors.</span>
    <span class="n">policy</span><span class="o">.</span><span class="n">agent_connectors</span><span class="o">.</span><span class="n">prepend</span><span class="p">(</span><span class="n">V2ToV1ObsAgentConnector</span><span class="p">(</span><span class="n">ctx</span><span class="p">))</span>
    <span class="n">policy</span><span class="o">.</span><span class="n">action_connectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">V1ToV2ActionConnector</span><span class="p">(</span><span class="n">ctx</span><span class="p">))</span>

    <span class="c1"># Run CartPole.</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">MyCartPole</span><span class="p">()</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Use local_policy_inference() to easily run poicy with observations.</span>
        <span class="n">policy_outputs</span> <span class="o">=</span> <span class="n">local_policy_inference</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;env_1&quot;</span><span class="p">,</span> <span class="s2">&quot;agent_1&quot;</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">policy_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">actions</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">policy_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>

        <span class="n">obs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>


</pre></div>
</div>
</section>
<section id="end-to-end-example">
<h2>End-to-end Example<a class="headerlink" href="rllib-connector.html#end-to-end-example" title="Permalink to this headline">#</a></h2>
<p>TODO: End-to-end case study: adapting an old policy to bootstrap the training of new LSTM policies,
then serve the newly trained policy in a server/client setup.</p>
</section>
<section id="notable-todos">
<h2>Notable TODOs<a class="headerlink" href="rllib-connector.html#notable-todos" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Bring connectors to offline algorithms.</p></li>
<li><p>Migrate rollout worker filters to connector.</p></li>
<li><p>Migrate episode building and traning sample collection into connector.</p></li>
<li><p>Examples and utilities demostrating deployment of RLlib policies in a client-server remote environment.</p></li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="rllib-catalogs.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Catalog (Alpha)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="rllib-rlmodule.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">RL Modules (Alpha)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>