
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Models, Preprocessors, and Action Distributions &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/versionwarning.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../_static/js/docsearch.js"></script>
    <script src="../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../_static/js/termynal.js"></script>
    <script defer="defer" src="../_static/js/custom.js"></script>
    <script defer="defer" src="../_static/js/top-navigation.js"></script>
    <script src="../_static/js/tags.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/rllib/rllib-models.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Saving and Loading your RL Algorithms and Policies" href="rllib-saving-and-loading-algos-and-policies.html" />
    <link rel="prev" title="Advanced Python APIs" href="rllib-advanced-api.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "rllib/rllib-models", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Ray RLlib
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-training.html">
     Getting Started with RLlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rllib-env.html">
     Environments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-algorithms.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="user-guides.html">
     User Guides
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-advanced-api.html">
       Advanced Python APIs
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="rllib-models.html#">
       Models, Preprocessors, and Action Distributions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-saving-and-loading-algos-and-policies.html">
       Saving and Loading your RL Algorithms and Policies
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-concepts.html">
       How To Customize Policies
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-sample-collection.html">
       Sample Collections and Trajectory Views
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-replay-buffers.html">
       Replay Buffers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-offline.html">
       Working With Offline Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-catalogs.html">
       Catalog (Alpha)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-connector.html">
       Connectors (Alpha)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-rlmodule.html">
       RL Modules (Alpha)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-fault-tolerance.html">
       Fault Tolerance And Elastic Training
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-dev.html">
       How To Contribute to RLlib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-cli.html">
       Working with the RLlib CLI
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-examples.html">
     Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="package_ref/index.html">
     Ray RLlib API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Frllib/rllib-models.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/rllib/rllib-models.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/rllib/rllib-models.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#default-behaviors">
   Default Behaviors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#built-in-preprocessors">
     Built-in Preprocessors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#default-model-config-settings">
     Default Model Config Settings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#built-in-models">
     Built-in Models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#built-in-auto-lstm-and-auto-attention-wrappers">
     Built-in auto-LSTM, and auto-Attention Wrappers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#customizing-preprocessors-and-models">
   Customizing Preprocessors and Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#custom-preprocessors-and-environment-filters">
     Custom Preprocessors and Environment Filters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#custom-models-implementing-your-own-forward-logic">
     Custom Models: Implementing your own Forward Logic
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#custom-tensorflow-models">
       Custom TensorFlow Models
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#custom-pytorch-models">
       Custom PyTorch Models
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#wrapping-a-custom-model-tf-and-pytorch-with-an-lstm-or-attention-net">
       Wrapping a Custom Model (TF and PyTorch) with an LSTM- or Attention Net
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#implementing-custom-recurrent-networks">
       Implementing custom Recurrent Networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#implementing-custom-attention-networks">
       Implementing custom Attention Networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#batch-normalization">
       Batch Normalization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#custom-model-apis-on-top-of-default-or-custom-models">
       Custom Model APIs (on Top of Default- or Custom Models)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#more-examples-for-building-custom-models">
       More examples for Building Custom Models
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#custom-action-distributions">
   Custom Action Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#supervised-model-losses">
   Supervised Model Losses
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#self-supervised-model-losses">
   Self-Supervised Model Losses
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#variable-length-complex-observation-spaces">
   Variable-length / Complex Observation Spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#variable-length-parametric-action-spaces">
   Variable-length / Parametric Action Spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#autoregressive-action-distributions">
   Autoregressive Action Distributions
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Models, Preprocessors, and Action Distributions</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#default-behaviors">
   Default Behaviors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#built-in-preprocessors">
     Built-in Preprocessors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#default-model-config-settings">
     Default Model Config Settings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#built-in-models">
     Built-in Models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#built-in-auto-lstm-and-auto-attention-wrappers">
     Built-in auto-LSTM, and auto-Attention Wrappers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#customizing-preprocessors-and-models">
   Customizing Preprocessors and Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#custom-preprocessors-and-environment-filters">
     Custom Preprocessors and Environment Filters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="rllib-models.html#custom-models-implementing-your-own-forward-logic">
     Custom Models: Implementing your own Forward Logic
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#custom-tensorflow-models">
       Custom TensorFlow Models
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#custom-pytorch-models">
       Custom PyTorch Models
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#wrapping-a-custom-model-tf-and-pytorch-with-an-lstm-or-attention-net">
       Wrapping a Custom Model (TF and PyTorch) with an LSTM- or Attention Net
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#implementing-custom-recurrent-networks">
       Implementing custom Recurrent Networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#implementing-custom-attention-networks">
       Implementing custom Attention Networks
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#batch-normalization">
       Batch Normalization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#custom-model-apis-on-top-of-default-or-custom-models">
       Custom Model APIs (on Top of Default- or Custom Models)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="rllib-models.html#more-examples-for-building-custom-models">
       More examples for Building Custom Models
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#custom-action-distributions">
   Custom Action Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#supervised-model-losses">
   Supervised Model Losses
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#self-supervised-model-losses">
   Self-Supervised Model Losses
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#variable-length-complex-observation-spaces">
   Variable-length / Complex Observation Spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#variable-length-parametric-action-spaces">
   Variable-length / Parametric Action Spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-models.html#autoregressive-action-distributions">
   Autoregressive Action Distributions
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/top.png" /></a>
<div class="bottom-right-promo-banner docutils">
<a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/square.png" /></a>
</div>
<section id="models-preprocessors-and-action-distributions">
<span id="rllib-models-walkthrough"></span><h1>Models, Preprocessors, and Action Distributions<a class="headerlink" href="rllib-models.html#models-preprocessors-and-action-distributions" title="Permalink to this headline">#</a></h1>
<p>The following diagram provides a conceptual overview of data flow between different components in RLlib.
We start with an <code class="docutils literal notranslate"><span class="pre">Environment</span></code>, which - given an action - produces an observation.
The observation is preprocessed by a <code class="docutils literal notranslate"><span class="pre">Preprocessor</span></code> and <code class="docutils literal notranslate"><span class="pre">Filter</span></code> (e.g. for running mean normalization)
before being sent to a neural network <code class="docutils literal notranslate"><span class="pre">Model</span></code>. The model output is in turn
interpreted by an <code class="docutils literal notranslate"><span class="pre">ActionDistribution</span></code> to determine the next action.</p>
<img alt="../_images/rllib-components.svg" src="../_images/rllib-components.svg" /><p>The components highlighted in green can be replaced with custom user-defined
implementations, as described in the next sections. The purple components are
RLlib internal, which means they can only be modified by changing the algorithm
source code.</p>
<section id="default-behaviors">
<h2>Default Behaviors<a class="headerlink" href="rllib-models.html#default-behaviors" title="Permalink to this headline">#</a></h2>
<section id="built-in-preprocessors">
<h3>Built-in Preprocessors<a class="headerlink" href="rllib-models.html#built-in-preprocessors" title="Permalink to this headline">#</a></h3>
<p>RLlib tries to pick one of its built-in preprocessors based on the environment’s
observation space. Thereby, the following simple rules apply:</p>
<ul class="simple">
<li><p>Discrete observations are one-hot encoded, e.g. <code class="docutils literal notranslate"><span class="pre">Discrete(3)</span> <span class="pre">and</span> <span class="pre">value=1</span> <span class="pre">-&gt;</span> <span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">0]</span></code>.</p></li>
<li><p>MultiDiscrete observations are encoded by one-hot encoding each discrete element
and then concatenating the respective one-hot encoded vectors.
e.g. <code class="docutils literal notranslate"><span class="pre">MultiDiscrete([3,</span> <span class="pre">4])</span> <span class="pre">and</span> <span class="pre">value=[1,</span> <span class="pre">3]</span> <span class="pre">-&gt;</span> <span class="pre">[0</span> <span class="pre">1</span> <span class="pre">0</span> <span class="pre">0</span> <span class="pre">0</span> <span class="pre">0</span> <span class="pre">1]</span></code> because
the first <code class="docutils literal notranslate"><span class="pre">1</span></code> is encoded as <code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">1</span> <span class="pre">0]</span></code> and the second <code class="docutils literal notranslate"><span class="pre">3</span></code> is encoded as
<code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">0</span> <span class="pre">0</span> <span class="pre">1]</span></code>; these two vectors are then concatenated to <code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">1</span> <span class="pre">0</span> <span class="pre">0</span> <span class="pre">0</span> <span class="pre">0</span> <span class="pre">1]</span></code>.</p></li>
<li><p>Tuple and Dict observations are flattened, thereby, Discrete and MultiDiscrete
sub-spaces are handled as described above.
Also, the original dict/tuple observations are still available inside a) the Model via the input
dict’s “obs” key (the flattened observations are in “obs_flat”), as well as b) the Policy
via the following line of code (e.g. put this into your loss function to access the original
observations: <code class="docutils literal notranslate"><span class="pre">dict_or_tuple_obs</span> <span class="pre">=</span> <span class="pre">restore_original_dimensions(input_dict[&quot;obs&quot;],</span> <span class="pre">self.obs_space,</span> <span class="pre">&quot;tf|torch&quot;)</span></code></p></li>
</ul>
<p>For Atari observation spaces, RLlib defaults to using the <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/env/wrappers/atari_wrappers.py">DeepMind preprocessors</a>
(<code class="docutils literal notranslate"><span class="pre">preprocessor_pref=deepmind</span></code>). However, if the Algorithm’s config key <code class="docutils literal notranslate"><span class="pre">preprocessor_pref</span></code> is set to “rllib”,
the following mappings apply for Atari-type observation spaces:</p>
<ul class="simple">
<li><p>Images of shape <code class="docutils literal notranslate"><span class="pre">(210,</span> <span class="pre">160,</span> <span class="pre">3)</span></code> are downscaled to <code class="docutils literal notranslate"><span class="pre">dim</span> <span class="pre">x</span> <span class="pre">dim</span></code>, where
<code class="docutils literal notranslate"><span class="pre">dim</span></code> is a model config key (see default Model config below). Also, you can set
<code class="docutils literal notranslate"><span class="pre">grayscale=True</span></code> for reducing the color channel to 1, or <code class="docutils literal notranslate"><span class="pre">zero_mean=True</span></code> for
producing -1.0 to 1.0 values (instead of 0.0 to 1.0 values by default).</p></li>
<li><p>Atari RAM observations (1D space of shape <code class="docutils literal notranslate"><span class="pre">(128,</span> <span class="pre">)</span></code>) are zero-averaged
(values between -1.0 and 1.0).</p></li>
</ul>
<p>In all other cases, no preprocessor will be used and the raw observations from the environment
will be sent directly into your model.</p>
</section>
<section id="default-model-config-settings">
<h3>Default Model Config Settings<a class="headerlink" href="rllib-models.html#default-model-config-settings" title="Permalink to this headline">#</a></h3>
<p>In the following paragraphs, we will first describe RLlib’s default behavior for automatically constructing
models (if you don’t setup a custom one), then dive into how you can customize your models by changing these
settings or writing your own model classes.</p>
<p>By default, RLlib will use the following config settings for your models.
These include options for the <code class="docutils literal notranslate"><span class="pre">FullyConnectedNetworks</span></code> (<code class="docutils literal notranslate"><span class="pre">fcnet_hiddens</span></code> and <code class="docutils literal notranslate"><span class="pre">fcnet_activation</span></code>),
<code class="docutils literal notranslate"><span class="pre">VisionNetworks</span></code> (<code class="docutils literal notranslate"><span class="pre">conv_filters</span></code> and <code class="docutils literal notranslate"><span class="pre">conv_activation</span></code>), auto-RNN wrapping, auto-Attention (<a class="reference external" href="https://arxiv.org/abs/1910.06764">GTrXL</a>) wrapping,
and some special options for Atari environments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MODEL_DEFAULTS</span><span class="p">:</span> <span class="n">ModelConfigDict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># Experimental flag.</span>
    <span class="c1"># If True, user specified no preprocessor to be created</span>
    <span class="c1"># (via config._disable_preprocessor_api=True). If True, observations</span>
    <span class="c1"># will arrive in model as they are returned by the env.</span>
    <span class="s2">&quot;_disable_preprocessor_api&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Experimental flag.</span>
    <span class="c1"># If True, RLlib will no longer flatten the policy-computed actions into</span>
    <span class="c1"># a single tensor (for storage in SampleCollectors/output files/etc..),</span>
    <span class="c1"># but leave (possibly nested) actions as-is. Disabling flattening affects:</span>
    <span class="c1"># - SampleCollectors: Have to store possibly nested action structs.</span>
    <span class="c1"># - Models that have the previous action(s) as part of their input.</span>
    <span class="c1"># - Algorithms reading from offline files (incl. action information).</span>
    <span class="s2">&quot;_disable_action_flattening&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>

    <span class="c1"># === Built-in options ===</span>
    <span class="c1"># FullyConnectedNetwork (tf and torch): rllib.models.tf|torch.fcnet.py</span>
    <span class="c1"># These are used if no custom model is specified and the input space is 1D.</span>
    <span class="c1"># Number of hidden layers to be used.</span>
    <span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span>
    <span class="c1"># Activation function descriptor.</span>
    <span class="c1"># Supported values are: &quot;tanh&quot;, &quot;relu&quot;, &quot;swish&quot; (or &quot;silu&quot;, which is the same),</span>
    <span class="c1"># &quot;linear&quot; (or None).</span>
    <span class="s2">&quot;fcnet_activation&quot;</span><span class="p">:</span> <span class="s2">&quot;tanh&quot;</span><span class="p">,</span>

    <span class="c1"># VisionNetwork (tf and torch): rllib.models.tf|torch.visionnet.py</span>
    <span class="c1"># These are used if no custom model is specified and the input space is 2D.</span>
    <span class="c1"># Filter config: List of [out_channels, kernel, stride] for each filter.</span>
    <span class="c1"># Example:</span>
    <span class="c1"># Use None for making RLlib try to find a default filter setup given the</span>
    <span class="c1"># observation space.</span>
    <span class="s2">&quot;conv_filters&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># Activation function descriptor.</span>
    <span class="c1"># Supported values are: &quot;tanh&quot;, &quot;relu&quot;, &quot;swish&quot; (or &quot;silu&quot;, which is the same),</span>
    <span class="c1"># &quot;linear&quot; (or None).</span>
    <span class="s2">&quot;conv_activation&quot;</span><span class="p">:</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>

    <span class="c1"># Some default models support a final FC stack of n Dense layers with given</span>
    <span class="c1"># activation:</span>
    <span class="c1"># - Complex observation spaces: Image components are fed through</span>
    <span class="c1">#   VisionNets, flat Boxes are left as-is, Discrete are one-hot&#39;d, then</span>
    <span class="c1">#   everything is concated and pushed through this final FC stack.</span>
    <span class="c1"># - VisionNets (CNNs), e.g. after the CNN stack, there may be</span>
    <span class="c1">#   additional Dense layers.</span>
    <span class="c1"># - FullyConnectedNetworks will have this additional FCStack as well</span>
    <span class="c1"># (that&#39;s why it&#39;s empty by default).</span>
    <span class="s2">&quot;post_fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;post_fcnet_activation&quot;</span><span class="p">:</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>

    <span class="c1"># For DiagGaussian action distributions, make the second half of the model</span>
    <span class="c1"># outputs floating bias variables instead of state-dependent. This only</span>
    <span class="c1"># has an effect is using the default fully connected net.</span>
    <span class="s2">&quot;free_log_std&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Whether to skip the final linear layer used to resize the hidden layer</span>
    <span class="c1"># outputs to size `num_outputs`. If True, then the last hidden layer</span>
    <span class="c1"># should already match num_outputs.</span>
    <span class="s2">&quot;no_final_linear&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Whether layers should be shared for the value function.</span>
    <span class="s2">&quot;vf_share_layers&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>

    <span class="c1"># == LSTM ==</span>
    <span class="c1"># Whether to wrap the model with an LSTM.</span>
    <span class="s2">&quot;use_lstm&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Max seq len for training the LSTM, defaults to 20.</span>
    <span class="s2">&quot;max_seq_len&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="c1"># Size of the LSTM cell.</span>
    <span class="s2">&quot;lstm_cell_size&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="c1"># Whether to feed a_{t-1} to LSTM (one-hot encoded if discrete).</span>
    <span class="s2">&quot;lstm_use_prev_action&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Whether to feed r_{t-1} to LSTM.</span>
    <span class="s2">&quot;lstm_use_prev_reward&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Whether the LSTM is time-major (TxBx..) or batch-major (BxTx..).</span>
    <span class="s2">&quot;_time_major&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>

    <span class="c1"># == Attention Nets (experimental: torch-version is untested) ==</span>
    <span class="c1"># Whether to use a GTrXL (&quot;Gru transformer XL&quot;; attention net) as the</span>
    <span class="c1"># wrapper Model around the default Model.</span>
    <span class="s2">&quot;use_attention&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># The number of transformer units within GTrXL.</span>
    <span class="c1"># A transformer unit in GTrXL consists of a) MultiHeadAttention module and</span>
    <span class="c1"># b) a position-wise MLP.</span>
    <span class="s2">&quot;attention_num_transformer_units&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># The input and output size of each transformer unit.</span>
    <span class="s2">&quot;attention_dim&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="c1"># The number of attention heads within the MultiHeadAttention units.</span>
    <span class="s2">&quot;attention_num_heads&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># The dim of a single head (within the MultiHeadAttention units).</span>
    <span class="s2">&quot;attention_head_dim&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="c1"># The memory sizes for inference and training.</span>
    <span class="s2">&quot;attention_memory_inference&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s2">&quot;attention_memory_training&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="c1"># The output dim of the position-wise MLP.</span>
    <span class="s2">&quot;attention_position_wise_mlp_dim&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="c1"># The initial bias values for the 2 GRU gates within a transformer unit.</span>
    <span class="s2">&quot;attention_init_gru_gate_bias&quot;</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span>
    <span class="c1"># Whether to feed a_{t-n:t-1} to GTrXL (one-hot encoded if discrete).</span>
    <span class="s2">&quot;attention_use_n_prev_actions&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="c1"># Whether to feed r_{t-n:t-1} to GTrXL.</span>
    <span class="s2">&quot;attention_use_n_prev_rewards&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>

    <span class="c1"># == Atari ==</span>
    <span class="c1"># Set to True to enable 4x stacking behavior.</span>
    <span class="s2">&quot;framestack&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># Final resized frame dimension</span>
    <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">84</span><span class="p">,</span>
    <span class="c1"># (deprecated) Converts ATARI frame to 1 Channel Grayscale image</span>
    <span class="s2">&quot;grayscale&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># (deprecated) Changes frame to range from [-1, 1] if true</span>
    <span class="s2">&quot;zero_mean&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>

    <span class="c1"># === Options for custom models ===</span>
    <span class="c1"># Name of a custom model to use</span>
    <span class="s2">&quot;custom_model&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># Extra options to pass to the custom classes. These will be available to</span>
    <span class="c1"># the Model&#39;s constructor in the model_config field. Also, they will be</span>
    <span class="c1"># attempted to be passed as **kwargs to ModelV2 models. For an example,</span>
    <span class="c1"># see rllib/models/[tf|torch]/attention_net.py.</span>
    <span class="s2">&quot;custom_model_config&quot;</span><span class="p">:</span> <span class="p">{},</span>
    <span class="c1"># Name of a custom action distribution to use.</span>
    <span class="s2">&quot;custom_action_dist&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># Custom preprocessors are deprecated. Please use a wrapper class around</span>
    <span class="c1"># your environment instead to preprocess observations.</span>
    <span class="s2">&quot;custom_preprocessor&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>

    <span class="c1"># === Options for ModelConfigs in RLModules ===</span>
    <span class="c1"># The latent dimension to encode into.</span>
    <span class="c1"># Since most RLModules have an encoder and heads, this establishes an agreement</span>
    <span class="c1"># on the dimensionality of the latent space they share.</span>
    <span class="c1"># This has no effect for models outside RLModule.</span>
    <span class="c1"># If None, model_config[&#39;fcnet_hiddens&#39;][-1] value will be used to guarantee</span>
    <span class="c1"># backward compatibility to old configs. This yields different models than past</span>
    <span class="c1"># versions of RLlib.</span>
    <span class="s2">&quot;encoder_latent_dim&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># Whether to always check the inputs and outputs of RLlib&#39;s default models for</span>
    <span class="c1"># their specifications. Input specifications are checked on failed forward passes</span>
    <span class="c1"># of the models regardless of this flag. If this flag is set to `True`, inputs and</span>
    <span class="c1"># outputs are checked on every call. This leads to a slow-down and should only be</span>
    <span class="c1"># used for debugging. Note that this flag is only relevant for instances of</span>
    <span class="c1"># RLlib&#39;s Model class. These are commonly generated from ModelConfigs in RLModules.</span>
    <span class="s2">&quot;always_check_shapes&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>

    <span class="c1"># Deprecated keys:</span>
    <span class="c1"># Use `lstm_use_prev_action` or `lstm_use_prev_reward` instead.</span>
    <span class="s2">&quot;lstm_use_prev_action_reward&quot;</span><span class="p">:</span> <span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
    <span class="c1"># Deprecated in anticipation of RLModules API</span>
    <span class="s2">&quot;_use_default_native_models&quot;</span><span class="p">:</span> <span class="n">DEPRECATED_VALUE</span><span class="p">,</span>

<span class="p">}</span>
</pre></div>
</div>
<p>The dict above (or an overriding sub-set) is handed to the Algorithm via the <code class="docutils literal notranslate"><span class="pre">model</span></code> key within
the main config dict like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">algo_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># All model-related settings go into this sub-dict.</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="c1"># By default, the MODEL_DEFAULTS dict above will be used.</span>

        <span class="c1"># Change individual keys in that dict by overriding them, e.g.</span>
        <span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span>
        <span class="s2">&quot;fcnet_activation&quot;</span><span class="p">:</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
    <span class="p">},</span>

    <span class="c1"># ... other Algorithm config keys, e.g. &quot;lr&quot; ...</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.00001</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="built-in-models">
<h3>Built-in Models<a class="headerlink" href="rllib-models.html#built-in-models" title="Permalink to this headline">#</a></h3>
<p>After preprocessing (if applicable) the raw environment outputs, the processed observations are fed through the policy’s model.
In case, no custom model is specified (see further below on how to customize models), RLlib will pick a default model
based on simple heuristics:</p>
<ul class="simple">
<li><p>A vision network (<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tf/visionnet.py">TF</a> or <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/visionnet.py">Torch</a>)
for observations that have a shape of length larger than 2, for example, <code class="docutils literal notranslate"><span class="pre">(84</span> <span class="pre">x</span> <span class="pre">84</span> <span class="pre">x</span> <span class="pre">3)</span></code>.</p></li>
<li><p>A fully connected network (<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tf/fcnet.py">TF</a> or <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/fcnet.py">Torch</a>)
for everything else.</p></li>
</ul>
<p>These default model types can further be configured via the <code class="docutils literal notranslate"><span class="pre">model</span></code> config key inside your Algorithm config (as discussed above).
Available settings are <a class="reference external" href="rllib-models.html#default-model-config-settings">listed above</a> and also documented in the <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/catalog.py">model catalog file</a>.</p>
<p>Note that for the vision network case, you’ll probably have to configure <code class="docutils literal notranslate"><span class="pre">conv_filters</span></code>, if your environment observations
have custom sizes. For example, <code class="docutils literal notranslate"><span class="pre">&quot;model&quot;:</span> <span class="pre">{&quot;dim&quot;:</span> <span class="pre">42,</span> <span class="pre">&quot;conv_filters&quot;:</span> <span class="pre">[[16,</span> <span class="pre">[4,</span> <span class="pre">4],</span> <span class="pre">2],</span> <span class="pre">[32,</span> <span class="pre">[4,</span> <span class="pre">4],</span> <span class="pre">2],</span> <span class="pre">[512,</span> <span class="pre">[11,</span> <span class="pre">11],</span> <span class="pre">1]]}</span></code> for 42x42 observations.
Thereby, always make sure that the last Conv2D output has an output shape of <code class="docutils literal notranslate"><span class="pre">[B,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">X]</span></code> (<code class="docutils literal notranslate"><span class="pre">[B,</span> <span class="pre">X,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> for PyTorch), where B=batch and
X=last Conv2D layer’s number of filters, so that RLlib can flatten it. An informative error will be thrown if this is not the case.</p>
</section>
<section id="built-in-auto-lstm-and-auto-attention-wrappers">
<span id="auto-lstm-and-attention"></span><h3>Built-in auto-LSTM, and auto-Attention Wrappers<a class="headerlink" href="rllib-models.html#built-in-auto-lstm-and-auto-attention-wrappers" title="Permalink to this headline">#</a></h3>
<p>In addition, if you set <code class="docutils literal notranslate"><span class="pre">&quot;use_lstm&quot;:</span> <span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;use_attention&quot;:</span> <span class="pre">True</span></code> in your model config,
your model’s output will be further processed by an LSTM cell
(<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tf/recurrent_net.py">TF</a> or <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/recurrent_net.py">Torch</a>),
or an attention (<a class="reference external" href="https://arxiv.org/abs/1910.06764">GTrXL</a>) network
(<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tf/attention_net.py">TF</a> or
<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/attention_net.py">Torch</a>), respectively.
More generally, RLlib supports the use of recurrent/attention models for all
its policy-gradient algorithms (A3C, PPO, PG, IMPALA), and the necessary sequence processing support
is built into its policy evaluation utilities.</p>
<p>See above for which additional config keys to use to configure in more detail these two auto-wrappers
(e.g. you can specify the size of the LSTM layer by <code class="docutils literal notranslate"><span class="pre">lstm_cell_size</span></code> or the attention dim by <code class="docutils literal notranslate"><span class="pre">attention_dim</span></code>).</p>
<p>For fully customized RNN/LSTM/Attention-Net setups see the <a class="reference external" href="rllib-models.html#rnns">Recurrent Models</a> and
<a class="reference external" href="rllib-models.html#attention">Attention Networks/Transformers</a> sections below.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is not possible to use both auto-wrappers (lstm and attention) at the same time. Doing so will create an error.</p>
</div>
</section>
</section>
<section id="customizing-preprocessors-and-models">
<h2>Customizing Preprocessors and Models<a class="headerlink" href="rllib-models.html#customizing-preprocessors-and-models" title="Permalink to this headline">#</a></h2>
<section id="custom-preprocessors-and-environment-filters">
<h3>Custom Preprocessors and Environment Filters<a class="headerlink" href="rllib-models.html#custom-preprocessors-and-environment-filters" title="Permalink to this headline">#</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Custom preprocessors have been fully deprecated, since they sometimes conflict with the built-in preprocessors for handling complex observation spaces.
Please use <a class="reference external" href="https://github.com/Farama-Foundation/Gymnasium/tree/main/gymnasium/wrappers">wrapper classes</a> around your environment instead of preprocessors.
Note that the built-in <strong>default</strong> Preprocessors described above will still be used and won’t be deprecated.</p>
</div>
<p>Instead of using the deprecated custom Preprocessors, you should use <code class="docutils literal notranslate"><span class="pre">gym.Wrappers</span></code> to preprocess your environment’s output (observations and rewards),
but also your Model’s computed actions before sending them back to the environment.</p>
<p>For example, for manipulating your env’s observations or rewards, do:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.numpy</span> <span class="kn">import</span> <span class="n">one_hot</span>

<span class="k">class</span> <span class="nc">OneHotEnv</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ObservationWrapper</span><span class="p">):</span>
    <span class="c1"># Override `observation` to custom process the original observation</span>
    <span class="c1"># coming from the env.</span>
    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="c1"># E.g. one-hotting a float obs [0.0, 5.0[.</span>
        <span class="k">return</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ClipRewardEnv</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">RewardWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">min_</span><span class="p">,</span> <span class="n">max_</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min</span> <span class="o">=</span> <span class="n">min_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max</span> <span class="o">=</span> <span class="n">max_</span>

    <span class="c1"># Override `reward` to custom process the original reward coming</span>
    <span class="c1"># from the env.</span>
    <span class="k">def</span> <span class="nf">reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="c1"># E.g. simple clipping between min and max.</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="custom-models-implementing-your-own-forward-logic">
<h3>Custom Models: Implementing your own Forward Logic<a class="headerlink" href="rllib-models.html#custom-models-implementing-your-own-forward-logic" title="Permalink to this headline">#</a></h3>
<p>If you would like to provide your own model logic (instead of using RLlib’s built-in defaults), you
can sub-class either <code class="docutils literal notranslate"><span class="pre">TFModelV2</span></code> (for TensorFlow) or <code class="docutils literal notranslate"><span class="pre">TorchModelV2</span></code> (for PyTorch) and then
register and specify your sub-class in the config as follows:</p>
<section id="custom-tensorflow-models">
<span id="tensorflow-models"></span><h4>Custom TensorFlow Models<a class="headerlink" href="rllib-models.html#custom-tensorflow-models" title="Permalink to this headline">#</a></h4>
<p>Custom TensorFlow models should subclass <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tf/tf_modelv2.py">TFModelV2</a> and implement the <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> and <code class="docutils literal notranslate"><span class="pre">forward()</span></code> methods.
<code class="docutils literal notranslate"><span class="pre">forward()</span></code> takes a dict of tensor inputs (mapping str to Tensor types), whose keys and values depend on
the <a class="reference external" href="rllib-sample-collection.html">view requirements</a> of the model.
Normally, this input dict contains only the current observation <code class="docutils literal notranslate"><span class="pre">obs</span></code> and an <code class="docutils literal notranslate"><span class="pre">is_training</span></code> boolean flag, as well as an optional list of RNN states.
<code class="docutils literal notranslate"><span class="pre">forward()</span></code> should return the model output (of size <code class="docutils literal notranslate"><span class="pre">self.num_outputs</span></code>) and - if applicable - a new list of internal
states (in case of RNNs or attention nets). You can also override extra methods of the model such as <code class="docutils literal notranslate"><span class="pre">value_function</span></code> to implement
a custom value branch.</p>
<p>Additional supervised/self-supervised losses can be added via the <code class="docutils literal notranslate"><span class="pre">TFModelV2.custom_loss</span></code> method:</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ray.rllib.models.tf.tf_modelv2.</span></span><span class="sig-name descname"><span class="pre">TFModelV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config:</span> <span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ray/rllib/models/tf/tf_modelv2.html#TFModelV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>TF version of ModelV2, which should contain a tf keras Model.</p>
<p>Note that this class by itself is not a valid model unless you
implement forward() in a subclass.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">context</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">contextlib.AbstractContextManager</span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/tf/tf_modelv2.html#TFModelV2.context"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Returns a contextmanager for the current TF graph.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update_ops</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/tf/tf_modelv2.html#TFModelV2.update_ops"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Return the list of update ops for this model.</p>
<p>For example, this should include any BatchNorm update ops.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">register_variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variables</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/tf/tf_modelv2.html#TFModelV2.register_variables"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Register the given list of variables with this model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">as_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/tf/tf_modelv2.html#TFModelV2.variables"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Returns the list (or a dict) of variables for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>as_dict</strong> – Whether variables should be returned as dict-values
(using descriptive str keys).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The list (or dict if <code class="xref py py-obj docutils literal notranslate"><span class="pre">as_dict</span></code> is True) of all variables of this
ModelV2.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">trainable_variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">as_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/tf/tf_modelv2.html#TFModelV2.trainable_variables"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Returns the list of trainable variables for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>as_dict</strong> – Whether variables should be returned as dict-values
(using descriptive keys).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The list (or dict if <code class="xref py py-obj docutils literal notranslate"><span class="pre">as_dict</span></code> is True) of all trainable
(tf)/requires_grad (torch) variables of this ModelV2.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<p>Once implemented, your TF model can then be registered and used in place of a built-in default one:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.rllib.algorithms.ppo</span> <span class="k">as</span> <span class="nn">ppo</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models</span> <span class="kn">import</span> <span class="n">ModelCatalog</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models.tf.tf_modelv2</span> <span class="kn">import</span> <span class="n">TFModelV2</span>

<span class="k">class</span> <span class="nc">MyModelClass</span><span class="p">(</span><span class="n">TFModelV2</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span> <span class="o">...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span> <span class="o">...</span>
    <span class="k">def</span> <span class="nf">value_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="o">...</span>

<span class="n">ModelCatalog</span><span class="o">.</span><span class="n">register_custom_model</span><span class="p">(</span><span class="s2">&quot;my_tf_model&quot;</span><span class="p">,</span> <span class="n">MyModelClass</span><span class="p">)</span>

<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">algo</span> <span class="o">=</span> <span class="n">ppo</span><span class="o">.</span><span class="n">PPO</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;custom_model&quot;</span><span class="p">:</span> <span class="s2">&quot;my_tf_model&quot;</span><span class="p">,</span>
        <span class="c1"># Extra kwargs to be passed to your model&#39;s c&#39;tor.</span>
        <span class="s2">&quot;custom_model_config&quot;</span><span class="p">:</span> <span class="p">{},</span>
    <span class="p">},</span>
<span class="p">})</span>
</pre></div>
</div>
<p>See the <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_keras_model.py">keras model example</a> for a full example of a TF custom model.</p>
<p>More examples and explanations on how to implement custom Tuple/Dict processing models
(also check out <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/tests/test_nested_observation_spaces.py">this test case here</a>),
custom RNNs, custom model APIs (on top of default models) follow further below.</p>
</section>
<section id="custom-pytorch-models">
<span id="torch-models"></span><h4>Custom PyTorch Models<a class="headerlink" href="rllib-models.html#custom-pytorch-models" title="Permalink to this headline">#</a></h4>
<p>Similarly, you can create and register custom PyTorch models by subclassing
<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/torch_modelv2.py">TorchModelV2</a> and implement the <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> and <code class="docutils literal notranslate"><span class="pre">forward()</span></code> methods.
<code class="docutils literal notranslate"><span class="pre">forward()</span></code> takes a dict of tensor inputs (mapping str to PyTorch tensor types), whose keys and values depend on
the <a class="reference external" href="rllib-sample-collection.html">view requirements</a> of the model.
Usually, the dict contains only the current observation <code class="docutils literal notranslate"><span class="pre">obs</span></code> and an <code class="docutils literal notranslate"><span class="pre">is_training</span></code> boolean flag, as well as an optional list of RNN states.
<code class="docutils literal notranslate"><span class="pre">forward()</span></code> should return the model output (of size <code class="docutils literal notranslate"><span class="pre">self.num_outputs</span></code>) and - if applicable - a new list of internal
states (in case of RNNs or attention nets). You can also override extra methods of the model such as <code class="docutils literal notranslate"><span class="pre">value_function</span></code> to implement
a custom value branch.</p>
<p>Additional supervised/self-supervised losses can be added via the <code class="docutils literal notranslate"><span class="pre">TorchModelV2.custom_loss</span></code> method:</p>
<p>See these examples of <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/fcnet.py">fully connected</a>, <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/visionnet.py">convolutional</a>, and <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/recurrent_net.py">recurrent</a> torch models.</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ray.rllib.models.torch.torch_modelv2.</span></span><span class="sig-name descname"><span class="pre">TorchModelV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config:</span> <span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ray/rllib/models/torch/torch_modelv2.html#TorchModelV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Torch version of ModelV2.</p>
<p>Note that this class by itself is not a valid model unless you
inherit from nn.Module and implement forward() in a subclass.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">as_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/torch/torch_modelv2.html#TorchModelV2.variables"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Returns the list (or a dict) of variables for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>as_dict</strong> – Whether variables should be returned as dict-values
(using descriptive str keys).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The list (or dict if <code class="xref py py-obj docutils literal notranslate"><span class="pre">as_dict</span></code> is True) of all variables of this
ModelV2.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">trainable_variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">as_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/torch/torch_modelv2.html#TorchModelV2.trainable_variables"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Returns the list of trainable variables for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>as_dict</strong> – Whether variables should be returned as dict-values
(using descriptive keys).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The list (or dict if <code class="xref py py-obj docutils literal notranslate"><span class="pre">as_dict</span></code> is True) of all trainable
(tf)/requires_grad (torch) variables of this ModelV2.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<p>Once implemented, your PyTorch model can then be registered and used in place of a built-in model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray.rllib.algorithms</span> <span class="kn">import</span> <span class="n">ppo</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models</span> <span class="kn">import</span> <span class="n">ModelCatalog</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models.torch.torch_modelv2</span> <span class="kn">import</span> <span class="n">TorchModelV2</span>

<span class="k">class</span> <span class="nc">CustomTorchModel</span><span class="p">(</span><span class="n">TorchModelV2</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span> <span class="o">...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span> <span class="o">...</span>
    <span class="k">def</span> <span class="nf">value_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="o">...</span>

<span class="n">ModelCatalog</span><span class="o">.</span><span class="n">register_custom_model</span><span class="p">(</span><span class="s2">&quot;my_torch_model&quot;</span><span class="p">,</span> <span class="n">CustomTorchModel</span><span class="p">)</span>

<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">algo</span> <span class="o">=</span> <span class="n">ppo</span><span class="o">.</span><span class="n">PPO</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;framework&quot;</span><span class="p">:</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;custom_model&quot;</span><span class="p">:</span> <span class="s2">&quot;my_torch_model&quot;</span><span class="p">,</span>
        <span class="c1"># Extra kwargs to be passed to your model&#39;s c&#39;tor.</span>
        <span class="s2">&quot;custom_model_config&quot;</span><span class="p">:</span> <span class="p">{},</span>
    <span class="p">},</span>
<span class="p">})</span>
</pre></div>
</div>
<p>See the <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/models/">torch model examples</a> for various examples on how to build a custom
PyTorch model (including recurrent ones).</p>
<p>More examples and explanations on how to implement custom Tuple/Dict processing models (also check out <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/tests/test_nested_observation_spaces.py">this test case here</a>),
custom RNNs, custom model APIs (on top of default models) follow further below.</p>
</section>
<section id="wrapping-a-custom-model-tf-and-pytorch-with-an-lstm-or-attention-net">
<h4>Wrapping a Custom Model (TF and PyTorch) with an LSTM- or Attention Net<a class="headerlink" href="rllib-models.html#wrapping-a-custom-model-tf-and-pytorch-with-an-lstm-or-attention-net" title="Permalink to this headline">#</a></h4>
<p>You can also use a custom (TF or PyTorch) model with our auto-wrappers for LSTMs (<code class="docutils literal notranslate"><span class="pre">use_lstm=True</span></code>) or Attention networks (<code class="docutils literal notranslate"><span class="pre">use_attention=True</span></code>).
For example, if you would like to wrap some non-default model logic with an LSTM, simply do:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>

<span class="c1"># The custom model that will be wrapped by an LSTM.</span>
<span class="k">class</span> <span class="nc">MyCustomModel</span><span class="p">(</span><span class="n">TorchModelV2</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_size</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Implement your own forward logic, whose output will then be sent</span>
    <span class="c1"># through an LSTM.</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;obs_flat&quot;</span><span class="p">]</span>
        <span class="c1"># Store last batch size for value_function output.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_size</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Return 2x the obs (and empty states).</span>
        <span class="c1"># This will further be sent through an automatically provided</span>
        <span class="c1"># LSTM head (b/c we are setting use_lstm=True below).</span>
        <span class="k">return</span> <span class="n">obs</span> <span class="o">*</span> <span class="mf">2.0</span><span class="p">,</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">value_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_size</span><span class="p">,)))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

    <span class="c1"># Register the above custom model.</span>
    <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">register_custom_model</span><span class="p">(</span><span class="s2">&quot;my_torch_model&quot;</span><span class="p">,</span> <span class="n">MyCustomModel</span><span class="p">)</span>

    <span class="c1"># Create the Algorithm from a config object.</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">ppo</span><span class="o">.</span><span class="n">PPOConfig</span><span class="p">()</span>
        <span class="o">.</span><span class="n">environment</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">framework</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">training</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="p">{</span>
                <span class="c1"># Auto-wrap the custom(!) model with an LSTM.</span>
                <span class="s2">&quot;use_lstm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="c1"># To further customize the LSTM auto-wrapper.</span>
                <span class="s2">&quot;lstm_cell_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
                <span class="c1"># Specify our custom model from above.</span>
                <span class="s2">&quot;custom_model&quot;</span><span class="p">:</span> <span class="s2">&quot;my_torch_model&quot;</span><span class="p">,</span>
                <span class="c1"># Extra kwargs to be passed to your model&#39;s c&#39;tor.</span>
                <span class="s2">&quot;custom_model_config&quot;</span><span class="p">:</span> <span class="p">{},</span>
            <span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">algo</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="n">algo</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">algo</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

</pre></div>
</div>
</section>
<section id="implementing-custom-recurrent-networks">
<span id="rnns"></span><h4>Implementing custom Recurrent Networks<a class="headerlink" href="rllib-models.html#implementing-custom-recurrent-networks" title="Permalink to this headline">#</a></h4>
<p>Instead of using the <code class="docutils literal notranslate"><span class="pre">use_lstm:</span> <span class="pre">True</span></code> option, it may be preferable to use a custom recurrent model.
This provides more control over postprocessing the LSTM’s output and can also allow the use of multiple LSTM cells to process different portions of the input.
For an RNN model it is recommended to subclass <code class="docutils literal notranslate"><span class="pre">RecurrentNetwork</span></code> (either the <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tf/recurrent_net.py">TF</a>
or <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/recurrent_net.py">PyTorch</a> versions) and then implement <code class="docutils literal notranslate"><span class="pre">__init__()</span></code>,
<code class="docutils literal notranslate"><span class="pre">get_initial_state()</span></code>, and <code class="docutils literal notranslate"><span class="pre">forward_rnn()</span></code>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="ray.rllib.models.tf.recurrent_net.RecurrentNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ray.rllib.models.tf.recurrent_net.</span></span><span class="sig-name descname"><span class="pre">RecurrentNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config:</span> <span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ray/rllib/models/tf/recurrent_net.html#RecurrentNetwork"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="rllib-models.html#ray.rllib.models.tf.recurrent_net.RecurrentNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Helper class to simplify implementing RNN models with TFModelV2.</p>
<p>Instead of implementing forward(), you can implement forward_rnn() which
takes batches with the time dimension added already.</p>
<p>Here is an example implementation for a subclass
<code class="docutils literal notranslate"><span class="pre">MyRNNClass(RecurrentNetwork)</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModelClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">cell_size</span> <span class="o">=</span> <span class="mi">256</span>

    <span class="c1"># Define input layers</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">state_in_h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">state_in_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">seq_in</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="c1"># Send to LSTM cell</span>
    <span class="n">lstm_out</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
        <span class="n">cell_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lstm&quot;</span><span class="p">)(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">input_layer</span><span class="p">,</span>
            <span class="n">mask</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">seq_in</span><span class="p">),</span>
            <span class="n">initial_state</span><span class="o">=</span><span class="p">[</span><span class="n">state_in_h</span><span class="p">,</span> <span class="n">state_in_c</span><span class="p">])</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="o">...</span><span class="p">)(</span><span class="n">lstm_out</span><span class="p">)</span>

    <span class="c1"># Create the RNN model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">seq_in</span><span class="p">,</span> <span class="n">state_in_h</span><span class="p">,</span> <span class="n">state_in_c</span><span class="p">],</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output_layer</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ray.rllib.models.tf.recurrent_net.RecurrentNetwork.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space:</span> <span class="pre">&lt;MagicMock</span> <span class="pre">name='mock.spaces.Space'</span> <span class="pre">id='139637273977104'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config:</span> <span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="rllib-models.html#ray.rllib.models.tf.recurrent_net.RecurrentNetwork.__init__" title="Permalink to this definition">#</a></dt>
<dd><p>Initializes a TFModelV2 instance.</p>
<p>Here is an example implementation for a subclass
<code class="docutils literal notranslate"><span class="pre">MyModelClass(TFModelV2)</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModelClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="o">...</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="o">...</span><span class="p">)(</span><span class="n">hidden_layer</span><span class="p">)</span>
    <span class="n">value_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="o">...</span><span class="p">)(</span><span class="n">hidden_layer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
        <span class="n">input_layer</span><span class="p">,</span> <span class="p">[</span><span class="n">output_layer</span><span class="p">,</span> <span class="n">value_layer</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ray.rllib.models.tf.recurrent_net.RecurrentNetwork.get_initial_state">
<span class="sig-name descname"><span class="pre">get_initial_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/tf/recurrent_net.html#RecurrentNetwork.get_initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="rllib-models.html#ray.rllib.models.tf.recurrent_net.RecurrentNetwork.get_initial_state" title="Permalink to this definition">#</a></dt>
<dd><p>Get the initial recurrent state values for the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of np.array objects, if any</p>
</dd>
</dl>
<p>Sample implementation for the <code class="docutils literal notranslate"><span class="pre">MyRNNClass</span></code> example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ray.rllib.models.tf.recurrent_net.RecurrentNetwork.forward_rnn">
<span class="sig-name descname"><span class="pre">forward_rnn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_lens</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.array</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">jnp.ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tf.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ray/rllib/models/tf/recurrent_net.html#RecurrentNetwork.forward_rnn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="rllib-models.html#ray.rllib.models.tf.recurrent_net.RecurrentNetwork.forward_rnn" title="Permalink to this definition">#</a></dt>
<dd><p>Call the model with the given input tensors and state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – observation tensor with shape [B, T, obs_size].</p></li>
<li><p><strong>state</strong> – list of state tensors, each with shape [B, T, size].</p></li>
<li><p><strong>seq_lens</strong> – 1d tensor holding input sequence lengths.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>The model output tensor of shape</dt><dd><p>[B, T, num_outputs] and the list of new state tensors each with
shape [B, size].</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(outputs, new_state)</p>
</dd>
</dl>
<p>Sample implementation for the <code class="docutils literal notranslate"><span class="pre">MyRNNClass</span></code> example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward_rnn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
    <span class="n">model_out</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_model</span><span class="p">([</span><span class="n">inputs</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">]</span> <span class="o">+</span> <span class="n">state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_out</span><span class="p">,</span> <span class="p">[</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<p>Note that the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> arg entering <code class="docutils literal notranslate"><span class="pre">forward_rnn</span></code> is already a time-ranked single tensor (not an <code class="docutils literal notranslate"><span class="pre">input_dict</span></code>!) with shape <code class="docutils literal notranslate"><span class="pre">(B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">...)</span></code>.
If you further want to customize and need more direct access to the complete (non time-ranked) <code class="docutils literal notranslate"><span class="pre">input_dict</span></code>, you can also override
your Model’s <code class="docutils literal notranslate"><span class="pre">forward</span></code> method directly (as you would do with a non-RNN ModelV2). In that case, though, you are responsible for changing your inputs
and add the time rank to the incoming data (usually you just have to reshape).</p>
<p>You can check out the <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/models/rnn_model.py">rnn_model.py</a> models as examples to implement
your own (either TF or Torch).</p>
</section>
<section id="implementing-custom-attention-networks">
<span id="attention"></span><h4>Implementing custom Attention Networks<a class="headerlink" href="rllib-models.html#implementing-custom-attention-networks" title="Permalink to this headline">#</a></h4>
<p>Similar to the RNN case described above, you could also implement your own attention-based networks, instead of using the
<code class="docutils literal notranslate"><span class="pre">use_attention:</span> <span class="pre">True</span></code> flag in your model config.</p>
<p>Check out RLlib’s <a class="reference external" href="https://arxiv.org/abs/1910.06764">GTrXL (Attention Net)</a> implementations
(for <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tf/attention_net.py">TF</a> and <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/torch/attention_net.py">PyTorch</a>)
to get a better idea on how to write your own models of this type. These are the models we use
as wrappers when <code class="docutils literal notranslate"><span class="pre">use_attention=True</span></code>.</p>
<p>You can run <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/attention_net.py">this example script</a> to run these nets within some of our algorithms.
<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/tests/test_attention_nets.py">There is also a test case</a>, which confirms their learning capabilities in PPO and IMPALA.</p>
</section>
<section id="batch-normalization">
<h4>Batch Normalization<a class="headerlink" href="rllib-models.html#batch-normalization" title="Permalink to this headline">#</a></h4>
<p>You can use <code class="docutils literal notranslate"><span class="pre">tf.layers.batch_normalization(x,</span> <span class="pre">training=input_dict[&quot;is_training&quot;])</span></code> to add batch norm layers to your custom model
(see a <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/batch_norm_model.py">code example here</a>).
RLlib will automatically run the update ops for the batch norm layers during optimization
(see <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/policy/tf_policy.py">tf_policy.py</a> and
<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/execution/multi_gpu_learner_thread.py">multi_gpu_learner_thread.py</a> for the exact handling of these updates).</p>
<p>In case RLlib does not properly detect the update ops for your custom model, you can override the <code class="docutils literal notranslate"><span class="pre">update_ops()</span></code> method to return the list of ops to run for updates.</p>
</section>
<section id="custom-model-apis-on-top-of-default-or-custom-models">
<h4>Custom Model APIs (on Top of Default- or Custom Models)<a class="headerlink" href="rllib-models.html#custom-model-apis-on-top-of-default-or-custom-models" title="Permalink to this headline">#</a></h4>
<p>So far we talked about a) the default models that are built into RLlib and are being provided
automatically if you don’t specify anything in your Algorithm’s config and b) custom Models through
which you can define any arbitrary forward passes.</p>
<p>Another typical situation in which you would have to customize a model would be to
add a new API that your algorithm needs in order to learn, for example a Q-value
calculating head on top of your policy model. In order to expand a Model’s API, simply
define and implement a new method (e.g. <code class="docutils literal notranslate"><span class="pre">get_q_values()</span></code>) in your TF- or TorchModelV2 sub-class.</p>
<p>You can now wrap this new API either around RLlib’s default models or around
your custom (<code class="docutils literal notranslate"><span class="pre">forward()</span></code>-overriding) model classes. Here are two examples that illustrate how to do this:</p>
<p><strong>The Q-head API: Adding a dueling layer on top of a default RLlib model</strong>.</p>
<p>The following code adds a <code class="docutils literal notranslate"><span class="pre">get_q_values()</span></code> method to the automatically chosen
default Model (e.g. a <code class="docutils literal notranslate"><span class="pre">FullyConnectedNetwork</span></code> if the observation space is a 1D Box
or Discrete):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DuelingQModel</span><span class="p">(</span><span class="n">TFModelV2</span><span class="p">):</span>  <span class="c1"># or: TorchModelV2</span>
    <span class="sd">&quot;&quot;&quot;A simple, hard-coded dueling head model.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="c1"># Pass num_outputs=None into super constructor (so that no action/</span>
        <span class="c1"># logits output layer is built).</span>
        <span class="c1"># Alternatively, you can pass in num_outputs=[last layer size of</span>
        <span class="c1"># config[model][fcnet_hiddens]] AND set no_last_linear=True, but</span>
        <span class="c1"># this seems more tedious as you will have to explain users of this</span>
        <span class="c1"># class that num_outputs is NOT the size of your Q-output layer.</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DuelingQModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span>
        <span class="p">)</span>
        <span class="c1"># Now: self.num_outputs contains the last layer&#39;s size, which</span>
        <span class="c1"># we can use to construct the dueling head (see torch: SlimFC</span>
        <span class="c1"># below).</span>

        <span class="c1"># Construct advantage head ...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">)</span>
        <span class="c1"># torch:</span>
        <span class="c1"># self.A = SlimFC(</span>
        <span class="c1">#     in_size=self.num_outputs, out_size=num_outputs)</span>

        <span class="c1"># ... and value head.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># torch:</span>
        <span class="c1"># self.V = SlimFC(in_size=self.num_outputs, out_size=1)</span>

    <span class="k">def</span> <span class="nf">get_q_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">underlying_output</span><span class="p">):</span>
        <span class="c1"># Calculate q-values following dueling logic:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">underlying_output</span><span class="p">)</span>  <span class="c1"># value</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">underlying_output</span><span class="p">)</span>  <span class="c1"># advantages (per action)</span>
        <span class="n">advantages_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">advantages_centered</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">advantages_mean</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">v</span> <span class="o">+</span> <span class="n">advantages_centered</span>  <span class="c1"># q-values</span>


</pre></div>
</div>
<p>Now, for your algorithm that needs to have this model API to work properly (e.g. DQN),
you use this following code to construct the complete final Model using the
<code class="docutils literal notranslate"><span class="pre">ModelCatalog.get_model_v2</span></code> factory function (<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/catalog.py">code here</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">my_dueling_model</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
        <span class="n">obs_space</span><span class="o">=</span><span class="n">obs_space</span><span class="p">,</span>
        <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
        <span class="n">num_outputs</span><span class="o">=</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
        <span class="n">model_config</span><span class="o">=</span><span class="n">MODEL_DEFAULTS</span><span class="p">,</span>
        <span class="n">framework</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">framework</span><span class="p">,</span>
        <span class="c1"># Providing the `model_interface` arg will make the factory</span>
        <span class="c1"># wrap the chosen default model with our new model API class</span>
        <span class="c1"># (DuelingQModel). This way, both `forward` and `get_q_values`</span>
        <span class="c1"># are available in the returned class.</span>
        <span class="n">model_interface</span><span class="o">=</span><span class="n">DuelingQModel</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">framework</span> <span class="o">!=</span> <span class="s2">&quot;torch&quot;</span>
        <span class="k">else</span> <span class="n">TorchDuelingQModel</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;dueling_q_model&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>With the model object constructed above, you can get the underlying intermediate output (before the dueling head)
by calling <code class="docutils literal notranslate"><span class="pre">my_dueling_model</span></code> directly (<code class="docutils literal notranslate"><span class="pre">out</span> <span class="pre">=</span> <span class="pre">my_dueling_model([input_dict])</span></code>), and then passing <code class="docutils literal notranslate"><span class="pre">out</span></code> into
your custom <code class="docutils literal notranslate"><span class="pre">get_q_values</span></code> method: <code class="docutils literal notranslate"><span class="pre">q_values</span> <span class="pre">=</span> <span class="pre">my_dueling_model.get_q_values(out)</span></code>.</p>
<p><strong>The single Q-value API for SAC</strong>.</p>
<p>Our DQN model from above takes an observation and outputs one Q-value per (discrete) action.
Continuous SAC - on the other hand - uses Models that calculate one Q-value only
for a single (<strong>continuous</strong>) action, given an observation and that particular action.</p>
<p>Let’s take a look at how we would construct this API and wrap it around a custom model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>

<span class="k">class</span> <span class="nc">TorchContActionQModel</span><span class="p">(</span><span class="n">TorchModelV2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A simple, q-value-from-cont-action model (for e.g. SAC type algos).&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="c1"># Pass num_outputs=None into super constructor (so that no action/</span>
        <span class="c1"># logits output layer is built).</span>
        <span class="c1"># Alternatively, you can pass in num_outputs=[last layer size of</span>
        <span class="c1"># config[model][fcnet_hiddens]] AND set no_last_linear=True, but</span>
        <span class="c1"># this seems more tedious as you will have to explain users of this</span>
        <span class="c1"># class that num_outputs is NOT the size of your Q-output layer.</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TorchContActionQModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span>
        <span class="p">)</span>

        <span class="c1"># Now: self.num_outputs contains the last layer&#39;s size, which</span>
        <span class="c1"># we can use to construct the single q-value computing head.</span>

        <span class="c1"># Nest an RLlib FullyConnectedNetwork (torch or tf) into this one here</span>
        <span class="c1"># to be used for Q-value calculation.</span>
        <span class="c1"># Use the current value of self.num_outputs, which is the wrapped</span>
        <span class="c1"># model&#39;s output layer size.</span>
        <span class="n">combined_space</span> <span class="o">=</span> <span class="n">Box</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">+</span> <span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_head</span> <span class="o">=</span> <span class="n">TorchFullyConnectedNetwork</span><span class="p">(</span>
            <span class="n">combined_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="s2">&quot;q_head&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Missing here: Probably still have to provide action output layer</span>
        <span class="c1"># and value layer and make sure self.num_outputs is correctly set.</span>

    <span class="k">def</span> <span class="nf">get_single_q_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">underlying_output</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="c1"># Calculate the q-value after concating the underlying output with</span>
        <span class="c1"># the given action.</span>
        <span class="n">input_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">underlying_output</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Construct a simple input_dict (needed for self.q_head as it&#39;s an</span>
        <span class="c1"># RLlib ModelV2).</span>
        <span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;obs&quot;</span><span class="p">:</span> <span class="n">input_</span><span class="p">}</span>
        <span class="c1"># Ignore state outputs.</span>
        <span class="n">q_values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_head</span><span class="p">(</span><span class="n">input_dict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q_values</span>


</pre></div>
</div>
<p>Now, for your algorithm that needs to have this model API to work properly (e.g. SAC),
you use this following code to construct the complete final Model using the
<code class="docutils literal notranslate"><span class="pre">ModelCatalog.get_model_v2</span></code> factory function (<a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/catalog.py">code here</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">my_cont_action_q_model</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
        <span class="n">obs_space</span><span class="o">=</span><span class="n">obs_space</span><span class="p">,</span>
        <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
        <span class="n">num_outputs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">model_config</span><span class="o">=</span><span class="n">MODEL_DEFAULTS</span><span class="p">,</span>
        <span class="n">framework</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">framework</span><span class="p">,</span>
        <span class="c1"># Providing the `model_interface` arg will make the factory</span>
        <span class="c1"># wrap the chosen default model with our new model API class</span>
        <span class="c1"># (DuelingQModel). This way, both `forward` and `get_q_values`</span>
        <span class="c1"># are available in the returned class.</span>
        <span class="n">model_interface</span><span class="o">=</span><span class="n">ContActionQModel</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">framework</span> <span class="o">!=</span> <span class="s2">&quot;torch&quot;</span>
        <span class="k">else</span> <span class="n">TorchContActionQModel</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cont_action_q_model&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>With the model object constructed above, you can get the underlying intermediate output (before the q-head)
by calling <code class="docutils literal notranslate"><span class="pre">my_cont_action_q_model</span></code> directly (<code class="docutils literal notranslate"><span class="pre">out</span> <span class="pre">=</span> <span class="pre">my_cont_action_q_model([input_dict])</span></code>), and then passing <code class="docutils literal notranslate"><span class="pre">out</span></code>
and some action into your custom <code class="docutils literal notranslate"><span class="pre">get_single_q_value</span></code> method:
<code class="docutils literal notranslate"><span class="pre">q_value</span> <span class="pre">=</span> <span class="pre">my_cont_action_q_model.get_signle_q_value(out,</span> <span class="pre">action)</span></code>.</p>
</section>
<section id="more-examples-for-building-custom-models">
<h4>More examples for Building Custom Models<a class="headerlink" href="rllib-models.html#more-examples-for-building-custom-models" title="Permalink to this headline">#</a></h4>
<p><strong>A multi-input capable model for Tuple observation spaces (for PPO)</strong></p>
<p>RLlib’s default preprocessor for Tuple and Dict spaces is to flatten incoming observations
into one flat <strong>1D</strong> array, and then pick a fully connected network (by default) to
process this flattened vector. This is usually ok, if you have only 1D Box or
Discrete/MultiDiscrete sub-spaces in your observations.</p>
<p>However, what if you had a complex observation space with one or more image components in
it (besides 1D Boxes and discrete spaces). You would probably want to preprocess each of the
image components using some convolutional network, and then concatenate their outputs
with the remaining non-image (flat) inputs (the 1D Box and discrete/one-hot components).</p>
<p>Take a look at this model example that does exactly that:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ComplexInputNetwork</span><span class="p">(</span><span class="n">TFModelV2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;TFModelV2 concat&#39;ing CNN outputs to flat input(s), followed by FC(s).</span>

<span class="sd">    Note: This model should be used for complex (Dict or Tuple) observation</span>
<span class="sd">    spaces that have one or more image components.</span>

<span class="sd">    The data flow is as follows:</span>

<span class="sd">    `obs` (e.g. Tuple[img0, img1, discrete0]) -&gt; `CNN0 + CNN1 + ONE-HOT`</span>
<span class="sd">    `CNN0 + CNN1 + ONE-HOT` -&gt; concat all flat outputs -&gt; `out`</span>
<span class="sd">    `out` -&gt; (optional) FC-stack -&gt; `out2`</span>
<span class="sd">    `out2` -&gt; action (logits) and vaulue heads.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_space</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">obs_space</span><span class="o">.</span><span class="n">original_space</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="s2">&quot;original_space&quot;</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">obs_space</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">processed_obs_space</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_space</span>
            <span class="k">if</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_disable_preprocessor_api&quot;</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">obs_space</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">flattened_input_space</span> <span class="o">=</span> <span class="n">flatten_space</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">original_space</span><span class="p">)</span>

        <span class="c1"># Build the CNN(s) given obs_space&#39;s image components.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cnns</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dims</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">concat_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">component</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flattened_input_space</span><span class="p">):</span>
            <span class="c1"># Image space.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">component</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">component</span><span class="p">,</span> <span class="n">Box</span><span class="p">):</span>
                <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;conv_filters&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="p">[</span><span class="s2">&quot;conv_filters&quot;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="s2">&quot;conv_filters&quot;</span> <span class="ow">in</span> <span class="n">model_config</span>
                    <span class="k">else</span> <span class="n">get_filter_config</span><span class="p">(</span><span class="n">component</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
                    <span class="s2">&quot;conv_activation&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;conv_activation&quot;</span><span class="p">),</span>
                    <span class="s2">&quot;post_fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
                    <span class="n">component</span><span class="p">,</span>
                    <span class="n">action_space</span><span class="p">,</span>
                    <span class="n">num_outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">model_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                    <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cnn_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">concat_size</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cnns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">)</span>
            <span class="c1"># Discrete|MultiDiscrete inputs -&gt; One-hot encode.</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">component</span><span class="p">,</span> <span class="p">(</span><span class="n">Discrete</span><span class="p">,</span> <span class="n">MultiDiscrete</span><span class="p">)):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">component</span><span class="p">,</span> <span class="n">Discrete</span><span class="p">):</span>
                    <span class="n">size</span> <span class="o">=</span> <span class="n">component</span><span class="o">.</span><span class="n">n</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">component</span><span class="o">.</span><span class="n">nvec</span><span class="p">)</span>
                <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="p">[</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;fcnet_activation&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;fcnet_activation&quot;</span><span class="p">),</span>
                    <span class="s2">&quot;post_fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
                    <span class="n">Box</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">size</span><span class="p">,),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="n">action_space</span><span class="p">,</span>
                    <span class="n">num_outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">model_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                    <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;one_hot_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">concat_size</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">)</span>
            <span class="c1"># Everything else (1D Box).</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">component</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
                <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="p">[</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;fcnet_activation&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;fcnet_activation&quot;</span><span class="p">),</span>
                    <span class="s2">&quot;post_fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
                    <span class="n">Box</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">size</span><span class="p">,),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="n">action_space</span><span class="p">,</span>
                    <span class="n">num_outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">model_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                    <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>
                <span class="n">concat_size</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">)</span>

        <span class="c1"># Optional post-concat FC-stack.</span>
        <span class="n">post_fc_stack_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;post_fcnet_hiddens&quot;</span><span class="p">,</span> <span class="p">[]),</span>
            <span class="s2">&quot;fcnet_activation&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;post_fcnet_activation&quot;</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_fc_stack</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
            <span class="n">Box</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">concat_size</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">post_fc_stack_config</span><span class="p">,</span>
            <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;post_fc_stack&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Actions and value heads.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logits_and_value_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_value_out</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">num_outputs</span><span class="p">:</span>
            <span class="c1"># Action-distribution head.</span>
            <span class="n">concat_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">post_fc_stack</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">,))</span>
            <span class="n">logits_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">num_outputs</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">normc_initializer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span>
            <span class="p">)(</span><span class="n">concat_layer</span><span class="p">)</span>

            <span class="c1"># Create the value branch model.</span>
            <span class="n">value_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">normc_initializer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;value_out&quot;</span><span class="p">,</span>
            <span class="p">)(</span><span class="n">concat_layer</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logits_and_value_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
                <span class="n">concat_layer</span><span class="p">,</span> <span class="p">[</span><span class="n">logits_layer</span><span class="p">,</span> <span class="n">value_layer</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_fc_stack</span><span class="o">.</span><span class="n">num_outputs</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">ModelV2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span> <span class="ow">in</span> <span class="n">input_dict</span> <span class="ow">and</span> <span class="s2">&quot;obs_flat&quot;</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="p">:</span>
            <span class="n">orig_obs</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">orig_obs</span> <span class="o">=</span> <span class="n">restore_original_dimensions</span><span class="p">(</span>
                <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_obs_space</span><span class="p">,</span> <span class="n">tensorlib</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Push image observations through our CNNs.</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">component</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">orig_obs</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnns</span><span class="p">:</span>
                <span class="n">cnn_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnns</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">SampleBatch</span><span class="p">({</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">component</span><span class="p">}))</span>
                <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cnn_out</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;int&quot;</span> <span class="ow">in</span> <span class="n">component</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
                    <span class="n">one_hot_in</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">one_hot</span><span class="p">(</span>
                            <span class="n">component</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flattened_input_space</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="p">}</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">one_hot_in</span> <span class="o">=</span> <span class="p">{</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">component</span><span class="p">}</span>
                <span class="n">one_hot_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">SampleBatch</span><span class="p">(</span><span class="n">one_hot_in</span><span class="p">))</span>
                <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_hot_out</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nn_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">[</span><span class="n">i</span><span class="p">](</span>
                    <span class="n">SampleBatch</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">component</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]]),</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn_out</span><span class="p">)</span>
        <span class="c1"># Concat all outputs and the non-image inputs.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Push through (optional) FC-stack (this may be an empty stack).</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_fc_stack</span><span class="p">(</span><span class="n">SampleBatch</span><span class="p">({</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">out</span><span class="p">}))</span>

        <span class="c1"># No logits/value branches.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_and_value_model</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="p">[]</span>

        <span class="c1"># Logits- and value branches.</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_and_value_model</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_value_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="p">[]</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">ModelV2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">value_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_value_out</span>


</pre></div>
</div>
<p><strong>Using the Trajectory View API: Passing in the last n actions (or rewards or observations) as inputs to a custom Model</strong></p>
<p>It is sometimes helpful for learning not only to look at the current observation
in order to calculate the next action, but also at the past n observations.
In other cases, you may want to provide the most recent rewards or actions to the model as well
(like our LSTM wrapper does if you specify: <code class="docutils literal notranslate"><span class="pre">use_lstm=True</span></code> and <code class="docutils literal notranslate"><span class="pre">lstm_use_prev_action/reward=True</span></code>).
All this may even be useful when not working with partially observable environments (PO-MDPs)
and/or RNN/Attention models, as for example in classic Atari runs, where we usually use framestacking of
the last four observed images.</p>
<p>The <a class="reference external" href="rllib-sample-collection.html#trajectory-view-api">trajectory view API</a> allows your models
to specify these more complex “view requirements”.</p>
<p>Here is a simple (non-RNN/Attention) example of a Model that takes as input
the last 3 observations (very similar to the recommended “framestacking” for
learning in Atari environments):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>

<span class="k">class</span> <span class="nc">FrameStackingCartPoleModel</span><span class="p">(</span><span class="n">TFModelV2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A simple FC model that takes the last n observations as input.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">num_frames</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FrameStackingCartPoleModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span> <span class="o">=</span> <span class="n">num_frames</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_outputs</span>

        <span class="c1"># Construct actual (very simple) FC model.</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">,</span> <span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">obs_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">([</span><span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">])(</span>
            <span class="n">obs</span>
        <span class="p">)</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">))</span>
        <span class="n">rewards_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">])(</span><span class="n">rewards</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">))</span>
        <span class="n">actions_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">([</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">])(</span>
            <span class="n">actions</span>
        <span class="p">)</span>
        <span class="n">input_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span>
            <span class="p">[</span><span class="n">obs_reshaped</span><span class="p">,</span> <span class="n">actions_reshaped</span><span class="p">,</span> <span class="n">rewards_reshaped</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">layer1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">input_</span><span class="p">)</span>
        <span class="n">layer2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">layer1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">)(</span><span class="n">layer2</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">layer1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">([</span><span class="n">obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">],</span> <span class="p">[</span><span class="n">out</span><span class="p">,</span> <span class="n">values</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_value</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="s2">&quot;prev_n_obs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
            <span class="n">data_col</span><span class="o">=</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="s2">&quot;-</span><span class="si">{}</span><span class="s2">:0&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_frames</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">space</span><span class="o">=</span><span class="n">obs_space</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="s2">&quot;prev_n_rewards&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
            <span class="n">data_col</span><span class="o">=</span><span class="s2">&quot;rewards&quot;</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="s2">&quot;-</span><span class="si">{}</span><span class="s2">:-1&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="s2">&quot;prev_n_actions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ViewRequirement</span><span class="p">(</span>
            <span class="n">data_col</span><span class="o">=</span><span class="s2">&quot;actions&quot;</span><span class="p">,</span>
            <span class="n">shift</span><span class="o">=</span><span class="s2">&quot;-</span><span class="si">{}</span><span class="s2">:-1&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">),</span>
            <span class="n">space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;prev_n_obs&quot;</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;prev_n_rewards&quot;</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;prev_n_actions&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
        <span class="n">out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">([</span><span class="n">obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">value_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_last_value</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>


</pre></div>
</div>
<p>A PyTorch version of the above model is also <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/models/trajectory_view_utilizing_models.py">given in the same file</a>.</p>
</section>
</section>
</section>
<section id="custom-action-distributions">
<h2>Custom Action Distributions<a class="headerlink" href="rllib-models.html#custom-action-distributions" title="Permalink to this headline">#</a></h2>
<p>Similar to custom models and preprocessors, you can also specify a custom action distribution class as follows. The action dist class is passed a reference to the <code class="docutils literal notranslate"><span class="pre">model</span></code>, which you can use to access <code class="docutils literal notranslate"><span class="pre">model.model_config</span></code> or other attributes of the model. This is commonly used to implement <a class="reference external" href="rllib-models.html#autoregressive-action-distributions">autoregressive action outputs</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.rllib.algorithms.ppo</span> <span class="k">as</span> <span class="nn">ppo</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models</span> <span class="kn">import</span> <span class="n">ModelCatalog</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models.preprocessors</span> <span class="kn">import</span> <span class="n">Preprocessor</span>

<span class="k">class</span> <span class="nc">MyActionDist</span><span class="p">(</span><span class="n">ActionDistribution</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">required_model_output_shape</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">model_config</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">7</span>  <span class="c1"># controls model output feature vector size</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyActionDist</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">==</span> <span class="mi">7</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="o">...</span>
    <span class="k">def</span> <span class="nf">logp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span> <span class="o">...</span>
    <span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="o">...</span>

<span class="n">ModelCatalog</span><span class="o">.</span><span class="n">register_custom_action_dist</span><span class="p">(</span><span class="s2">&quot;my_dist&quot;</span><span class="p">,</span> <span class="n">MyActionDist</span><span class="p">)</span>

<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">algo</span> <span class="o">=</span> <span class="n">ppo</span><span class="o">.</span><span class="n">PPO</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;custom_action_dist&quot;</span><span class="p">:</span> <span class="s2">&quot;my_dist&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">})</span>
</pre></div>
</div>
</section>
<section id="supervised-model-losses">
<h2>Supervised Model Losses<a class="headerlink" href="rllib-models.html#supervised-model-losses" title="Permalink to this headline">#</a></h2>
<p>You can mix supervised losses into any RLlib algorithm through custom models. For example, you can add an imitation learning loss on expert experiences, or a self-supervised autoencoder loss within the model. These losses can be defined over either policy evaluation inputs, or data read from <a class="reference external" href="rllib-offline.html#input-pipeline-for-supervised-losses">offline storage</a>.</p>
<p><strong>TensorFlow</strong>: To add a supervised loss to a custom TF model, you need to override the <code class="docutils literal notranslate"><span class="pre">custom_loss()</span></code> method. This method takes in the existing policy loss for the algorithm, which you can add your own supervised loss to before returning. For debugging, you can also return a dictionary of scalar tensors in the <code class="docutils literal notranslate"><span class="pre">metrics()</span></code> method. Here is a <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_loss.py">runnable example</a> of adding an imitation loss to CartPole training that is defined over a <a class="reference external" href="rllib-offline.html#input-pipeline-for-supervised-losses">offline dataset</a>.</p>
<p><strong>PyTorch</strong>: There is no explicit API for adding losses to custom torch models. However, you can modify the loss in the policy definition directly. Like for TF models, offline datasets can be incorporated by creating an input reader and calling <code class="docutils literal notranslate"><span class="pre">reader.next()</span></code> in the loss forward pass.</p>
</section>
<section id="self-supervised-model-losses">
<h2>Self-Supervised Model Losses<a class="headerlink" href="rllib-models.html#self-supervised-model-losses" title="Permalink to this headline">#</a></h2>
<p>You can also use the <code class="docutils literal notranslate"><span class="pre">custom_loss()</span></code> API to add in self-supervised losses such as VAE reconstruction loss and L2-regularization.</p>
</section>
<section id="variable-length-complex-observation-spaces">
<h2>Variable-length / Complex Observation Spaces<a class="headerlink" href="rllib-models.html#variable-length-complex-observation-spaces" title="Permalink to this headline">#</a></h2>
<p>RLlib supports complex and variable-length observation spaces, including <code class="docutils literal notranslate"><span class="pre">gym.spaces.Tuple</span></code>, <code class="docutils literal notranslate"><span class="pre">gym.spaces.Dict</span></code>, and <code class="docutils literal notranslate"><span class="pre">rllib.utils.spaces.Repeated</span></code>. The handling of these spaces is transparent to the user. RLlib internally will insert preprocessors to insert padding for repeated elements, flatten complex observations into a fixed-size vector during transit, and unpack the vector into the structured tensor before sending it to the model. The flattened observation is available to the model as <code class="docutils literal notranslate"><span class="pre">input_dict[&quot;obs_flat&quot;]</span></code>, and the unpacked observation as <code class="docutils literal notranslate"><span class="pre">input_dict[&quot;obs&quot;]</span></code>.</p>
<p>To enable batching of struct observations, RLlib unpacks them in a <a class="reference external" href="https://github.com/tensorflow/community/blob/master/rfcs/20190910-struct-tensor.md">StructTensor-like format</a>. In summary, repeated fields are “pushed down” and become the outer dimensions of tensor batches, as illustrated in this figure from the StructTensor RFC.</p>
<img alt="../_images/struct-tensor.png" src="../_images/struct-tensor.png" />
<dl class="simple">
<dt>For further information about complex observation spaces, see:</dt><dd><ul class="simple">
<li><p>A custom environment and model that uses <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/complex_struct_space.py">repeated struct fields</a>.</p></li>
<li><p>The pydoc of the <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/utils/spaces/repeated.py">Repeated space</a>.</p></li>
<li><p>The pydoc of the batched <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/models/repeated_values.py">repeated values tensor</a>.</p></li>
<li><p>The <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/tests/test_nested_observation_spaces.py">unit tests</a> for Tuple and Dict spaces.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="variable-length-parametric-action-spaces">
<h2>Variable-length / Parametric Action Spaces<a class="headerlink" href="rllib-models.html#variable-length-parametric-action-spaces" title="Permalink to this headline">#</a></h2>
<p>Custom models can be used to work with environments where (1) the set of valid actions <a class="reference external" href="https://neuro.cs.ut.ee/the-use-of-embeddings-in-openai-five">varies per step</a>, and/or (2) the number of valid actions is <a class="reference external" href="https://arxiv.org/abs/1811.00260">very large</a>. The general idea is that the meaning of actions can be completely conditioned on the observation, i.e., the <code class="docutils literal notranslate"><span class="pre">a</span></code> in <code class="docutils literal notranslate"><span class="pre">Q(s,</span> <span class="pre">a)</span></code> becomes just a token in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">MAX_AVAIL_ACTIONS)</span></code> that only has meaning in the context of <code class="docutils literal notranslate"><span class="pre">s</span></code>. This works with algorithms in the <a class="reference external" href="../rllib-env.html">DQN and policy-gradient families</a> and can be implemented as follows:</p>
<ol class="arabic simple">
<li><p>The environment should return a mask and/or list of valid action embeddings as part of the observation for each step. To enable batching, the number of actions can be allowed to vary from 1 to some max number:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyParamActionEnv</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_avail_actions</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">Discrete</span><span class="p">(</span><span class="n">max_avail_actions</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">Dict</span><span class="p">({</span>
            <span class="s2">&quot;action_mask&quot;</span><span class="p">:</span> <span class="n">Box</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">max_avail_actions</span><span class="p">,</span> <span class="p">)),</span>
            <span class="s2">&quot;avail_actions&quot;</span><span class="p">:</span> <span class="n">Box</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">max_avail_actions</span><span class="p">,</span> <span class="n">action_embedding_sz</span><span class="p">)),</span>
            <span class="s2">&quot;real_obs&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
        <span class="p">})</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>A custom model can be defined that can interpret the <code class="docutils literal notranslate"><span class="pre">action_mask</span></code> and <code class="docutils literal notranslate"><span class="pre">avail_actions</span></code> portions of the observation. Here the model computes the action logits via the dot product of some network output and each action embedding. Invalid actions can be masked out of the softmax by scaling the probability to zero:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ParametricActionsModel</span><span class="p">(</span><span class="n">TFModelV2</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">obs_space</span><span class="p">,</span>
                 <span class="n">action_space</span><span class="p">,</span>
                 <span class="n">num_outputs</span><span class="p">,</span>
                 <span class="n">model_config</span><span class="p">,</span>
                 <span class="n">name</span><span class="p">,</span>
                 <span class="n">true_obs_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,),</span>
                 <span class="n">action_embed_size</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ParametricActionsModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_embed_model</span> <span class="o">=</span> <span class="n">FullyConnectedNetwork</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
        <span class="c1"># Extract the available actions tensor from the observation.</span>
        <span class="n">avail_actions</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">][</span><span class="s2">&quot;avail_actions&quot;</span><span class="p">]</span>
        <span class="n">action_mask</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">][</span><span class="s2">&quot;action_mask&quot;</span><span class="p">]</span>

        <span class="c1"># Compute the predicted action embedding</span>
        <span class="n">action_embed</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_embed_model</span><span class="p">({</span>
            <span class="s2">&quot;obs&quot;</span><span class="p">:</span> <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">][</span><span class="s2">&quot;cart&quot;</span><span class="p">]</span>
        <span class="p">})</span>

        <span class="c1"># Expand the model output to [BATCH, 1, EMBED_SIZE]. Note that the</span>
        <span class="c1"># avail actions tensor is of shape [BATCH, MAX_ACTIONS, EMBED_SIZE].</span>
        <span class="n">intent_vector</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">action_embed</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Batch dot product =&gt; shape of logits is [BATCH, MAX_ACTIONS].</span>
        <span class="n">action_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">avail_actions</span> <span class="o">*</span> <span class="n">intent_vector</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Mask out invalid actions (use tf.float32.min for stability)</span>
        <span class="n">inf_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">action_mask</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action_logits</span> <span class="o">+</span> <span class="n">inf_mask</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>Depending on your use case it may make sense to use <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/models/action_mask_model.py">just the <strong>masking</strong></a>, <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/parametric_actions_cartpole.py">just action <strong>embeddings</strong></a>, or <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/models/parametric_actions_model.py"><strong>both</strong></a>.  For a runnable example of “just action embeddings” in code,
check out <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/parametric_actions_cartpole.py">examples/parametric_actions_cartpole.py</a>.</p>
<p>Note that since masking introduces <code class="docutils literal notranslate"><span class="pre">tf.float32.min</span></code> values into the model output, this technique might not work with all algorithm options. For example, algorithms might crash if they incorrectly process the <code class="docutils literal notranslate"><span class="pre">tf.float32.min</span></code> values. The cartpole example has working configurations for DQN (must set <code class="docutils literal notranslate"><span class="pre">hiddens=[]</span></code>), PPO (must disable running mean and set <code class="docutils literal notranslate"><span class="pre">model.vf_share_layers=True</span></code>), and several other algorithms. Not all algorithms support parametric actions; see the <a class="reference external" href="rllib-algorithms.html#available-algorithms-overview">algorithm overview</a>.</p>
</section>
<section id="autoregressive-action-distributions">
<h2>Autoregressive Action Distributions<a class="headerlink" href="rllib-models.html#autoregressive-action-distributions" title="Permalink to this headline">#</a></h2>
<p>In an action space with multiple components (e.g., <code class="docutils literal notranslate"><span class="pre">Tuple(a1,</span> <span class="pre">a2)</span></code>), you might want <code class="docutils literal notranslate"><span class="pre">a2</span></code> to be conditioned on the sampled value of <code class="docutils literal notranslate"><span class="pre">a1</span></code>, i.e., <code class="docutils literal notranslate"><span class="pre">a2_sampled</span> <span class="pre">~</span> <span class="pre">P(a2</span> <span class="pre">|</span> <span class="pre">a1_sampled,</span> <span class="pre">obs)</span></code>. Normally, <code class="docutils literal notranslate"><span class="pre">a1</span></code> and <code class="docutils literal notranslate"><span class="pre">a2</span></code> would be sampled independently, reducing the expressivity of the policy.</p>
<p>To do this, you need both a custom model that implements the autoregressive pattern, and a custom action distribution class that leverages that model. The <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/autoregressive_action_dist.py">autoregressive_action_dist.py</a> example shows how this can be implemented for a simple binary action space. For a more complex space, a more efficient architecture such as a <a class="reference external" href="https://arxiv.org/abs/1502.03509">MADE</a> is recommended. Note that sampling a <code class="xref py py-obj docutils literal notranslate"><span class="pre">N-part</span></code> action requires <code class="xref py py-obj docutils literal notranslate"><span class="pre">N</span></code> forward passes through the model, however computing the log probability of an action can be done in one pass:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BinaryAutoregressiveOutput</span><span class="p">(</span><span class="n">ActionDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Action distribution P(a1, a2) = P(a1) * P(a2 | a1)&quot;&quot;&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">required_model_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">16</span>  <span class="c1"># controls model output feature vector size</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># first, sample a1</span>
        <span class="n">a1_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_a1_distribution</span><span class="p">()</span>
        <span class="n">a1</span> <span class="o">=</span> <span class="n">a1_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

        <span class="c1"># sample a2 conditioned on a1</span>
        <span class="n">a2_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_a2_distribution</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="n">a2_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

        <span class="c1"># return the action tuple</span>
        <span class="k">return</span> <span class="n">TupleActions</span><span class="p">([</span><span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">logp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
        <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">actions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">a1_vec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">a1_logits</span><span class="p">,</span> <span class="n">a2_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">action_model</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">a1_vec</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">Categorical</span><span class="p">(</span><span class="n">a1_logits</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">logp</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span> <span class="o">+</span> <span class="n">Categorical</span><span class="p">(</span>
            <span class="n">a2_logits</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">logp</span><span class="p">(</span><span class="n">a2</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_a1_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">BATCH</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">a1_logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">action_model</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">BATCH</span><span class="p">,</span> <span class="mi">1</span><span class="p">))])</span>
        <span class="n">a1_dist</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">a1_logits</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a1_dist</span>

    <span class="k">def</span> <span class="nf">_a2_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a1</span><span class="p">):</span>
        <span class="n">a1_vec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">a2_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">action_model</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">a1_vec</span><span class="p">])</span>
        <span class="n">a2_dist</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">a2_logits</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a2_dist</span>

<span class="k">class</span> <span class="nc">AutoregressiveActionsModel</span><span class="p">(</span><span class="n">TFModelV2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implements the `.action_model` branch required above.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span>
                 <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AutoregressiveActionsModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action_space</span> <span class="o">!=</span> <span class="n">Tuple</span><span class="p">([</span><span class="n">Discrete</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">Discrete</span><span class="p">(</span><span class="mi">2</span><span class="p">)]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;This model only supports the [2, 2] action space&quot;</span><span class="p">)</span>

        <span class="c1"># Inputs</span>
        <span class="n">obs_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;obs_input&quot;</span><span class="p">)</span>
        <span class="n">a1_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;a1_input&quot;</span><span class="p">)</span>
        <span class="n">ctx_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ctx_input&quot;</span><span class="p">)</span>

        <span class="c1"># Output of the model (normally &#39;logits&#39;, but for an autoregressive</span>
        <span class="c1"># dist this is more like a context/feature layer encoding the obs)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
            <span class="n">num_outputs</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;hidden&quot;</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">normc_initializer</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))(</span><span class="n">obs_input</span><span class="p">)</span>

        <span class="c1"># P(a1 | obs)</span>
        <span class="n">a1_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
            <span class="mi">2</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;a1_logits&quot;</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">normc_initializer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))(</span><span class="n">ctx_input</span><span class="p">)</span>

        <span class="c1"># P(a2 | a1)</span>
        <span class="c1"># --note: typically you&#39;d want to implement P(a2 | a1, obs) as follows:</span>
        <span class="c1"># a2_context = tf.keras.layers.Concatenate(axis=1)(</span>
        <span class="c1">#     [ctx_input, a1_input])</span>
        <span class="n">a2_context</span> <span class="o">=</span> <span class="n">a1_input</span>
        <span class="n">a2_hidden</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
            <span class="mi">16</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;a2_hidden&quot;</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">normc_initializer</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))(</span><span class="n">a2_context</span><span class="p">)</span>
        <span class="n">a2_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
            <span class="mi">2</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;a2_logits&quot;</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">normc_initializer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))(</span><span class="n">a2_hidden</span><span class="p">)</span>

        <span class="c1"># Base layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">obs_input</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_variables</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

        <span class="c1"># Autoregressive action sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">([</span><span class="n">ctx_input</span><span class="p">,</span> <span class="n">a1_input</span><span class="p">],</span>
                                           <span class="p">[</span><span class="n">a1_logits</span><span class="p">,</span> <span class="n">a2_logits</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_variables</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_model</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Not all algorithms support autoregressive action distributions; see the <a class="reference external" href="rllib-algorithms.html#available-algorithms-overview">algorithm overview table</a> for more information.</p>
</div>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="rllib-advanced-api.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Advanced Python APIs</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="rllib-saving-and-loading-algos-and-policies.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Saving and Loading your RL Algorithms and Policies</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>