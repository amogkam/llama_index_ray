
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>RL Modules (Alpha) &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/versionwarning.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../_static/js/docsearch.js"></script>
    <script src="../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../_static/js/termynal.js"></script>
    <script defer="defer" src="../_static/js/custom.js"></script>
    <script defer="defer" src="../_static/js/top-navigation.js"></script>
    <script src="../_static/js/tags.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/rllib/rllib-rlmodule.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Fault Tolerance And Elastic Training" href="rllib-fault-tolerance.html" />
    <link rel="prev" title="Connectors (Alpha)" href="rllib-connector.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "rllib/rllib-rlmodule", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Ray RLlib
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-training.html">
     Getting Started with RLlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rllib-env.html">
     Environments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-algorithms.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="user-guides.html">
     User Guides
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-advanced-api.html">
       Advanced Python APIs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-models.html">
       Models, Preprocessors, and Action Distributions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-saving-and-loading-algos-and-policies.html">
       Saving and Loading your RL Algorithms and Policies
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-concepts.html">
       How To Customize Policies
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-sample-collection.html">
       Sample Collections and Trajectory Views
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-replay-buffers.html">
       Replay Buffers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-offline.html">
       Working With Offline Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-catalogs.html">
       Catalog (Alpha)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-connector.html">
       Connectors (Alpha)
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="rllib-rlmodule.html#">
       RL Modules (Alpha)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-fault-tolerance.html">
       Fault Tolerance And Elastic Training
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-dev.html">
       How To Contribute to RLlib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib-cli.html">
       Working with the RLlib CLI
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-examples.html">
     Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="package_ref/index.html">
     Ray RLlib API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Frllib/rllib-rlmodule.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/rllib/rllib-rlmodule.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/rllib/rllib-rlmodule.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#enabling-rl-modules-in-the-configuration">
   Enabling RL Modules in the Configuration
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#constructing-rl-modules">
   Constructing RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#writing-custom-single-agent-rl-modules">
   Writing Custom Single Agent RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#writing-custom-multi-agent-rl-modules-advanced">
   Writing Custom Multi-Agent RL Modules (Advanced)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#extending-existing-rllib-rl-modules">
   Extending Existing RLlib RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#migrating-from-custom-policies-and-models-to-rl-modules">
   Migrating from Custom Policies and Models to RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#notable-todos">
   Notable TODOs
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>RL Modules (Alpha)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#enabling-rl-modules-in-the-configuration">
   Enabling RL Modules in the Configuration
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#constructing-rl-modules">
   Constructing RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#writing-custom-single-agent-rl-modules">
   Writing Custom Single Agent RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#writing-custom-multi-agent-rl-modules-advanced">
   Writing Custom Multi-Agent RL Modules (Advanced)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#extending-existing-rllib-rl-modules">
   Extending Existing RLlib RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#migrating-from-custom-policies-and-models-to-rl-modules">
   Migrating from Custom Policies and Models to RL Modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-rlmodule.html#notable-todos">
   Notable TODOs
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/top.png" /></a>
<div class="bottom-right-promo-banner docutils">
<a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/square.png" /></a>
</div>
<section id="rl-modules-alpha">
<h1>RL Modules (Alpha)<a class="headerlink" href="rllib-rlmodule.html#rl-modules-alpha" title="Permalink to this headline">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is an experimental module that serves as a general replacement for ModelV2, and is subject to change. It will eventually match the functionality of the previous stack. If you only use high-level RLlib APIs such as <a class="reference internal" href="package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.html#ray.rllib.algorithms.algorithm.Algorithm" title="ray.rllib.algorithms.algorithm.Algorithm"><code class="xref py py-class docutils literal notranslate"><span class="pre">Algorithm</span></code></a> you should not experience significant changes, except for a few new parameters to the configuration object. If you’ve used custom models or policies before, you’ll need to migrate them to the new modules. Check the Migration guide for more information.</p>
<p>The table below shows the list of migrated algorithms and their current supported features, which will be updated as we progress.</p>
<table class="colwidths-given table">
<colgroup>
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Algorithm</p></th>
<th class="head"><p>Independent MARL</p></th>
<th class="head"><p>Fully-connected</p></th>
<th class="head"><p>Image inputs (CNN)</p></th>
<th class="head"><p>RNN support (LSTM)</p></th>
<th class="head"><p>Complex observations (ComplexNet)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>PPO</strong></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Impala</strong></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a></p></td>
</tr>
<tr class="row-even"><td><p><strong>APPO</strong></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td><p><a class="inline-figure reference internal" href="../_images/pytorch.png"><img alt="pytorch" class="inline-figure" src="../_images/pytorch.png" style="width: 16px;" /></a> <a class="inline-figure reference internal" href="../_images/tensorflow.png"><img alt="tensorflow" class="inline-figure" src="../_images/tensorflow.png" style="width: 16px;" /></a></p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>RL Module is a neural network container that implements three public methods: <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_train.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_train" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_train"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_train()</span></code></a>, <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_exploration()</span></code></a>, and <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_inference()</span></code></a>. Each method corresponds to a distinct reinforcement learning phase.</p>
<p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_exploration()</span></code></a> handles acting and data collection, balancing exploration and exploitation. On the other hand, the <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_inference()</span></code></a> serves the learned model during evaluation, often being less stochastic.</p>
<p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_train.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_train" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_train"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_train()</span></code></a> manages the training phase, handling calculations exclusive to computing losses, such as learning Q values in a DQN model.</p>
<section id="enabling-rl-modules-in-the-configuration">
<h2>Enabling RL Modules in the Configuration<a class="headerlink" href="rllib-rlmodule.html#enabling-rl-modules-in-the-configuration" title="Permalink to this headline">#</a></h2>
<p>Enable RL Modules by setting the <code class="docutils literal notranslate"><span class="pre">_enable_rl_module_api</span></code> flag to <code class="docutils literal notranslate"><span class="pre">True</span></code> in the configuration object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="kn">from</span> <span class="nn">ray.rllib.algorithms.ppo</span> <span class="kn">import</span> <span class="n">PPOConfig</span>

<span class="n">config</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">PPOConfig</span><span class="p">()</span>
    <span class="o">.</span><span class="n">framework</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">environment</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rl_module</span><span class="p">(</span><span class="n">_enable_rl_module_api</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="o">.</span><span class="n">training</span><span class="p">(</span><span class="n">_enable_learner_api</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">algorithm</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>

<span class="c1"># run for 2 training steps</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">pprint</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="constructing-rl-modules">
<h2>Constructing RL Modules<a class="headerlink" href="rllib-rlmodule.html#constructing-rl-modules" title="Permalink to this headline">#</a></h2>
<p>The RLModule API provides a unified way to define custom reinforcement learning models in RLlib. This API enables you to design and implement your own models to suit specific needs.</p>
<p>To maintain consistency and usability, RLlib offers a standardized approach for defining module objects for both single-agent and multi-agent reinforcement learning environments. This is achieved through the <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec.html#ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec" title="ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleAgentRLModuleSpec</span></code></a> and <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec.html#ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec" title="ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAgentRLModuleSpec</span></code></a> classes. The built-in RLModules in RLlib follow this consistent design pattern, making it easier for you to understand and utilize these modules.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-0">
Single Agent</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">SingleAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.testing.torch.bc_module</span> <span class="kn">import</span> <span class="n">DiscreteBCTorchModule</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>

<span class="n">spec</span> <span class="o">=</span> <span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span>
    <span class="n">module_class</span><span class="o">=</span><span class="n">DiscreteBCTorchModule</span><span class="p">,</span>
    <span class="n">observation_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
    <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">]},</span>
<span class="p">)</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-1">
Multi Agent</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">SingleAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.marl_module</span> <span class="kn">import</span> <span class="n">MultiAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.testing.torch.bc_module</span> <span class="kn">import</span> <span class="n">DiscreteBCTorchModule</span>

<span class="n">spec</span> <span class="o">=</span> <span class="n">MultiAgentRLModuleSpec</span><span class="p">(</span>
    <span class="n">module_specs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;module_1&quot;</span><span class="p">:</span> <span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span>
            <span class="n">module_class</span><span class="o">=</span><span class="n">DiscreteBCTorchModule</span><span class="p">,</span>
            <span class="n">observation_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,)),</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">]},</span>
        <span class="p">),</span>
        <span class="s2">&quot;module_2&quot;</span><span class="p">:</span> <span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span>
            <span class="n">module_class</span><span class="o">=</span><span class="n">DiscreteBCTorchModule</span><span class="p">,</span>
            <span class="n">observation_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,)),</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">16</span><span class="p">]},</span>
        <span class="p">),</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">marl_module</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>You can pass RL Module specs to the algorithm configuration to be used by the algorithm.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-2" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-2">
Single Agent</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">SingleAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.testing.torch.bc_module</span> <span class="kn">import</span> <span class="n">DiscreteBCTorchModule</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.testing.bc_algorithm</span> <span class="kn">import</span> <span class="n">BCConfigTest</span>


<span class="n">config</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">BCConfigTest</span><span class="p">()</span>
    <span class="o">.</span><span class="n">environment</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rl_module</span><span class="p">(</span>
        <span class="n">_enable_rl_module_api</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">rl_module_spec</span><span class="o">=</span><span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span><span class="n">module_class</span><span class="o">=</span><span class="n">DiscreteBCTorchModule</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">training</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]},</span>
        <span class="n">_enable_learner_api</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">algo</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For passing RL Module specs, all fields do not have to be filled as they are filled based on the described environment or other algorithm configuration parameters (i.e. ,``observation_space``, <code class="docutils literal notranslate"><span class="pre">action_space</span></code>, <code class="docutils literal notranslate"><span class="pre">model_config_dict</span></code> are not required fields when passing a custom RL Module spec to the algorithm config.)</p>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-3">
Multi Agent</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">SingleAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.marl_module</span> <span class="kn">import</span> <span class="n">MultiAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.testing.torch.bc_module</span> <span class="kn">import</span> <span class="n">DiscreteBCTorchModule</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.testing.bc_algorithm</span> <span class="kn">import</span> <span class="n">BCConfigTest</span>
<span class="kn">from</span> <span class="nn">ray.rllib.examples.env.multi_agent</span> <span class="kn">import</span> <span class="n">MultiAgentCartPole</span>


<span class="n">config</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">BCConfigTest</span><span class="p">()</span>
    <span class="o">.</span><span class="n">environment</span><span class="p">(</span><span class="n">MultiAgentCartPole</span><span class="p">,</span> <span class="n">env_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_agents&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
    <span class="o">.</span><span class="n">rl_module</span><span class="p">(</span>
        <span class="n">_enable_rl_module_api</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">rl_module_spec</span><span class="o">=</span><span class="n">MultiAgentRLModuleSpec</span><span class="p">(</span>
            <span class="n">module_specs</span><span class="o">=</span><span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span><span class="n">module_class</span><span class="o">=</span><span class="n">DiscreteBCTorchModule</span><span class="p">)</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">training</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]},</span>
        <span class="n">_enable_learner_api</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="writing-custom-single-agent-rl-modules">
<h2>Writing Custom Single Agent RL Modules<a class="headerlink" href="rllib-rlmodule.html#writing-custom-single-agent-rl-modules" title="Permalink to this headline">#</a></h2>
<p>For single-agent algorithms (e.g., PPO, DQN) or independent multi-agent algorithms (e.g., PPO-MultiAgent), use <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">RLModule</span></code></a>. For more advanced multi-agent use cases with a shared communication between agents, extend the <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.marl_module.MultiAgentRLModule.html#ray.rllib.core.rl_module.marl_module.MultiAgentRLModule" title="ray.rllib.core.rl_module.marl_module.MultiAgentRLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAgentRLModule</span></code></a> class.</p>
<p>RLlib treats single-agent modules as a special case of <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.marl_module.MultiAgentRLModule.html#ray.rllib.core.rl_module.marl_module.MultiAgentRLModule" title="ray.rllib.core.rl_module.marl_module.MultiAgentRLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAgentRLModule</span></code></a> with only one module. Create the multi-agent representation of all RLModules by calling <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.as_multi_agent.html#ray.rllib.core.rl_module.rl_module.RLModule.as_multi_agent" title="ray.rllib.core.rl_module.rl_module.RLModule.as_multi_agent"><code class="xref py py-meth docutils literal notranslate"><span class="pre">as_multi_agent()</span></code></a>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">SingleAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.testing.torch.bc_module</span> <span class="kn">import</span> <span class="n">DiscreteBCTorchModule</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span>
    <span class="n">module_class</span><span class="o">=</span><span class="n">DiscreteBCTorchModule</span><span class="p">,</span>
    <span class="n">observation_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
    <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">]},</span>
<span class="p">)</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="n">marl_module</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">as_multi_agent</span><span class="p">()</span>
</pre></div>
</div>
<p>RLlib implements the following abstract framework specific base classes:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchRLModule</span></code>: For PyTorch-based RL Modules.</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">TfRLModule</span></code>: For TensorFlow-based RL Modules.</p></li>
</ul>
<p>The minimum requirement is for sub-classes of <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">RLModule</span></code></a> is to implement the following methods:</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">_forward_train()</span></code>: Forward pass for training.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">_forward_inference()</span></code>: Forward pass for inference.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">_forward_exploration()</span></code>: Forward pass for exploration.</p></li>
</ul>
<p>For your custom <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_exploration()</span></code></a> and <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_inference()</span></code></a>
methods, you must return a dictionary that either contains the key “actions” and/or the key “action_dist_inputs”.</p>
<p>If you return the “actions” key:</p>
<ul class="simple">
<li><p>RLlib will use the actions provided thereunder as-is.</p></li>
<li><p>If you also returned the “action_dist_inputs” key: RLlib will also create a <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code> object from the distribution parameters under that key and - in the case of <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_exploration()</span></code></a> - compute action probs and logp values from the given actions automatically.</p></li>
</ul>
<p>If you do not return the “actions” key:</p>
<ul class="simple">
<li><p>You must return the “action_dist_inputs” key instead from your <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_exploration()</span></code></a> and <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_inference()</span></code></a> methods.</p></li>
<li><p>RLlib will create a <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code> object from the distribution parameters under that key and sample actions from the thus generated distribution.</p></li>
<li><p>In the case of <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_exploration()</span></code></a>, RLlib will also compute action probs and logp values from the sampled actions automatically.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the case of <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_inference()</span></code></a>,
the generated distributions (from returned key “action_dist_inputs”) will always be made deterministic first via
the <code class="xref py py-meth docutils literal notranslate"><span class="pre">to_deterministic()</span></code> utility before a possible action sample step.
Thus, for example, sampling from a Categorical distribution will be reduced to simply selecting the argmax actions from the distribution’s logits/probs.</p>
</div>
<p>Commonly used distribution implementations can be found under <code class="docutils literal notranslate"><span class="pre">ray.rllib.models.tf.tf_distributions</span></code> for tensorflow and
<code class="docutils literal notranslate"><span class="pre">ray.rllib.models.torch.torch_distributions</span></code> for torch. You can choose to return determinstic actions, by creating a determinstic distribution instance.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-4" name="sd-tab-set-2" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-4">
Returning “actions” key</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">An RLModule whose forward_exploration/inference methods return the</span>
<span class="sd">&quot;actions&quot; key.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">MyRLModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">_forward_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;actions&quot;</span><span class="p">:</span> <span class="o">...</span>  <span class="c1"># actions will be used as-is</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">_forward_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;actions&quot;</span><span class="p">:</span> <span class="o">...</span>  <span class="c1"># actions will be used as-is (no sampling step!)</span>
            <span class="s2">&quot;action_dist_inputs&quot;</span><span class="p">:</span> <span class="o">...</span>  <span class="c1"># optional: If provided, will be used to compute action probs and logp.</span>
        <span class="p">}</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-2" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-5">
Not returning “actions” key</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">An RLModule whose forward_exploration/inference methods do NOT return the</span>
<span class="sd">&quot;actions&quot; key.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">MyRLModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">_forward_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="c1"># RLlib will:</span>
            <span class="c1"># - Generate distribution from these parameters.</span>
            <span class="c1"># - Convert distribution to a deterministic equivalent.</span>
            <span class="c1"># - &quot;sample&quot; from the deterministic distribution.</span>
            <span class="s2">&quot;action_dist_inputs&quot;</span><span class="p">:</span> <span class="o">...</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">_forward_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="c1"># RLlib will:</span>
            <span class="c1"># - Generate distribution from these parameters.</span>
            <span class="c1"># - &quot;sample&quot; from the (stochastic) distribution.</span>
            <span class="c1"># - Compute action probs/logs automatically using the sampled</span>
            <span class="c1">#   actions and the generated distribution object.</span>
            <span class="s2">&quot;action_dist_inputs&quot;</span><span class="p">:</span> <span class="o">...</span>
        <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Also the <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">RLModule</span></code></a> class’s constrcutor requires a dataclass config object called <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.html#ray.rllib.core.rl_module.rl_module.RLModuleConfig" title="ray.rllib.core.rl_module.rl_module.RLModuleConfig"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RLModuleConfig</span></code></a> which contains the following fields:</p>
<ul class="simple">
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.observation_space.html#ray.rllib.core.rl_module.rl_module.RLModuleConfig.observation_space" title="ray.rllib.core.rl_module.rl_module.RLModuleConfig.observation_space"><code class="xref py py-attr docutils literal notranslate"><span class="pre">observation_space</span></code></a>: The observation space of the environment (either processed or raw).</p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.action_space.html#ray.rllib.core.rl_module.rl_module.RLModuleConfig.action_space" title="ray.rllib.core.rl_module.rl_module.RLModuleConfig.action_space"><code class="xref py py-attr docutils literal notranslate"><span class="pre">action_space</span></code></a>: The action space of the environment.</p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.model_config_dict.html#ray.rllib.core.rl_module.rl_module.RLModuleConfig.model_config_dict" title="ray.rllib.core.rl_module.rl_module.RLModuleConfig.model_config_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">model_config_dict</span></code></a>: The model config dictionary of the algorithm. Model hyper-parameters such as number of layers, type of activation, etc. are defined here.</p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.catalog_class.html#ray.rllib.core.rl_module.rl_module.RLModuleConfig.catalog_class" title="ray.rllib.core.rl_module.rl_module.RLModuleConfig.catalog_class"><code class="xref py py-attr docutils literal notranslate"><span class="pre">catalog_class</span></code></a>: The <a class="reference internal" href="package_ref/doc/ray.rllib.core.models.catalog.Catalog.html#ray.rllib.core.models.catalog.Catalog" title="ray.rllib.core.models.catalog.Catalog"><code class="xref py py-class docutils literal notranslate"><span class="pre">Catalog</span></code></a> object of the algorithm.</p></li>
</ul>
<p>When writing RL Modules, you need to use these fields to construct your model.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-6" name="sd-tab-set-3" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-6">
Single Agent (torch)</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Any</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.torch.torch_rl_module</span> <span class="kn">import</span> <span class="n">TorchRLModule</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">RLModuleConfig</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.nested_dict</span> <span class="kn">import</span> <span class="n">NestedDict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">DiscreteBCTorchModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">RLModuleConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">input_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_config_dict</span><span class="p">[</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">output_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>

    <span class="k">def</span> <span class="nf">_forward_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">NestedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_train</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">NestedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_train</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">NestedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">action_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;action_dist&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">action_logits</span><span class="p">)}</span>


</pre></div>
</div>
</div>
<input id="sd-tab-item-7" name="sd-tab-set-3" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-7">
Single Agent (tensorflow)</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Any</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.tf.tf_rl_module</span> <span class="kn">import</span> <span class="n">TfRLModule</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">RLModuleConfig</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.nested_dict</span> <span class="kn">import</span> <span class="n">NestedDict</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>


<span class="k">class</span> <span class="nc">DiscreteBCTfModule</span><span class="p">(</span><span class="n">TfRLModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">RLModuleConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">input_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_config_dict</span><span class="p">[</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">output_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>

    <span class="k">def</span> <span class="nf">_forward_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">NestedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_train</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">NestedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_train</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">NestedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">action_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;action_dist&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">action_logits</span><span class="p">)}</span>


</pre></div>
</div>
</div>
</div>
<p>In <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">RLModule</span></code></a> you can enforce the checking for the existence of certain input or output keys in the data that is communicated into and out of RL Modules. This serves multiple purposes:</p>
<ul class="simple">
<li><p>For the I/O requirement of each method to be self-documenting.</p></li>
<li><p>For failures to happen quickly. If users extend the modules and implement something that does not match the assumptions of the I/O specs, the check reports missing keys and their expected format. For example, RLModule should always have an <code class="docutils literal notranslate"><span class="pre">obs</span></code> key in the input batch and an <code class="docutils literal notranslate"><span class="pre">action_dist</span></code> key in the output.</p></li>
</ul>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-8" name="sd-tab-set-4" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-8">
Single Level Keys</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DiscreteBCTorchModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">input_specs_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpecType</span><span class="p">:</span>
        <span class="c1"># Enforce that input nested dict to exploration method has a key &quot;obs&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">output_specs_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpecType</span><span class="p">:</span>
        <span class="c1"># Enforce that output nested dict from exploration method has a key</span>
        <span class="c1"># &quot;action_dist&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;action_dist&quot;</span><span class="p">]</span>


</pre></div>
</div>
</div>
<input id="sd-tab-item-9" name="sd-tab-set-4" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-9">
Nested Keys</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DiscreteBCTorchModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">input_specs_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpecType</span><span class="p">:</span>
        <span class="c1"># Enforce that input nested dict to exploration method has a key &quot;obs&quot;</span>
        <span class="c1"># and within that key, it has a key &quot;global&quot; and &quot;local&quot;. There should</span>
        <span class="c1"># also be a key &quot;action_mask&quot;</span>
        <span class="k">return</span> <span class="p">[(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="s2">&quot;global&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="s2">&quot;local&quot;</span><span class="p">),</span> <span class="s2">&quot;action_mask&quot;</span><span class="p">]</span>


</pre></div>
</div>
</div>
<input id="sd-tab-item-10" name="sd-tab-set-4" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-10">
TensorShape Spec</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DiscreteBCTorchModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">input_specs_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpecType</span><span class="p">:</span>
        <span class="c1"># Enforce that input nested dict to exploration method has a key &quot;obs&quot;</span>
        <span class="c1"># and its value is a torch.Tensor with shape (b, h) where b is the</span>
        <span class="c1"># batch size (determined at run-time) and h is the hidden size</span>
        <span class="c1"># (fixed at 10).</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;obs&quot;</span><span class="p">:</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="s2">&quot;b, h&quot;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">)}</span>


</pre></div>
</div>
</div>
<input id="sd-tab-item-11" name="sd-tab-set-4" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-11">
Type Spec</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DiscreteBCTorchModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">output_specs_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpecType</span><span class="p">:</span>
        <span class="c1"># Enforce that output nested dict from exploration method has a key</span>
        <span class="c1"># &quot;action_dist&quot; and its value is a torch.distribution.Categorical</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;action_dist&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">Categorical</span><span class="p">}</span>


</pre></div>
</div>
</div>
</div>
<p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">RLModule</span></code></a> has two methods for each forward method, totaling 6 methods that can be override to describe the specs of the input and output of each method:</p>
<ul class="simple">
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.input_specs_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.input_specs_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.input_specs_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">input_specs_inference()</span></code></a></p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.output_specs_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.output_specs_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.output_specs_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">output_specs_inference()</span></code></a></p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.input_specs_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.input_specs_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.input_specs_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">input_specs_exploration()</span></code></a></p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.output_specs_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.output_specs_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.output_specs_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">output_specs_exploration()</span></code></a></p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.input_specs_train.html#ray.rllib.core.rl_module.rl_module.RLModule.input_specs_train" title="ray.rllib.core.rl_module.rl_module.RLModule.input_specs_train"><code class="xref py py-meth docutils literal notranslate"><span class="pre">input_specs_train()</span></code></a></p></li>
<li><p><a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.output_specs_train.html#ray.rllib.core.rl_module.rl_module.RLModule.output_specs_train" title="ray.rllib.core.rl_module.rl_module.RLModule.output_specs_train"><code class="xref py py-meth docutils literal notranslate"><span class="pre">output_specs_train()</span></code></a></p></li>
</ul>
<p>To learn more, see the <code class="xref py py-obj docutils literal notranslate"><span class="pre">SpecType</span></code> documentation.</p>
</section>
<section id="writing-custom-multi-agent-rl-modules-advanced">
<h2>Writing Custom Multi-Agent RL Modules (Advanced)<a class="headerlink" href="rllib-rlmodule.html#writing-custom-multi-agent-rl-modules-advanced" title="Permalink to this headline">#</a></h2>
<p>For multi-agent modules, RLlib implements <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.marl_module.MultiAgentRLModule.html#ray.rllib.core.rl_module.marl_module.MultiAgentRLModule" title="ray.rllib.core.rl_module.marl_module.MultiAgentRLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAgentRLModule</span></code></a>, which is a dictionary of <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">RLModule</span></code></a> objects, one for each policy, and possibly some shared modules. The base-class implementation works for most of use cases that need to define independent neural networks for sub-groups of agents. For more complex, multi-agent use cases, where the agents share some part of their neural network, you should inherit from this class and override the default implementation.</p>
<p>The <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.marl_module.MultiAgentRLModule.html#ray.rllib.core.rl_module.marl_module.MultiAgentRLModule" title="ray.rllib.core.rl_module.marl_module.MultiAgentRLModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAgentRLModule</span></code></a> offers an API for constructing custom models tailored to specific needs. The key method for this customization is <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.marl_module.MultiAgentRLModule.html#ray.rllib.core.rl_module.marl_module.MultiAgentRLModule" title="ray.rllib.core.rl_module.marl_module.MultiAgentRLModule"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MultiAgentRLModule()</span></code></a>.build.</p>
<p>The following example creates a custom multi-agent RL module with underlying modules. The modules share an encoder, which gets applied to the global part of the observations space. The local part passes through a separate encoder, specific to each policy.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-12" name="sd-tab-set-5" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-12">
Multi agent with shared encoder (Torch)</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.torch.torch_rl_module</span> <span class="kn">import</span> <span class="n">TorchRLModule</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.marl_module</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MultiAgentRLModuleConfig</span><span class="p">,</span>
    <span class="n">MultiAgentRLModule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.nested_dict</span> <span class="kn">import</span> <span class="n">NestedDict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">BCTorchRLModuleWithSharedGlobalEncoder</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;An RLModule with a shared encoder between agents for global observation.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">local_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">+</span> <span class="n">local_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_common_forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_common_forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_common_forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_common_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]</span>
        <span class="n">global_enc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;global&quot;</span><span class="p">])</span>
        <span class="n">policy_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">global_enc</span><span class="p">,</span> <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;local&quot;</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">action_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_head</span><span class="p">(</span><span class="n">policy_in</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;action_dist&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">action_logits</span><span class="p">)}</span>


<span class="k">class</span> <span class="nc">BCTorchMultiAgentModuleWithSharedEncoder</span><span class="p">(</span><span class="n">MultiAgentRLModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">MultiAgentRLModuleConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="n">module_specs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">modules</span>
        <span class="n">module_spec</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">module_specs</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="n">global_dim</span> <span class="o">=</span> <span class="n">module_spec</span><span class="o">.</span><span class="n">observation_space</span><span class="p">[</span><span class="s2">&quot;global&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">module_spec</span><span class="o">.</span><span class="n">model_config_dict</span><span class="p">[</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">shared_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">global_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="n">rl_modules</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">module_id</span><span class="p">,</span> <span class="n">module_spec</span> <span class="ow">in</span> <span class="n">module_specs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">rl_modules</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">BCTorchRLModuleWithSharedGlobalEncoder</span><span class="p">(</span>
                <span class="n">encoder</span><span class="o">=</span><span class="n">shared_encoder</span><span class="p">,</span>
                <span class="n">local_dim</span><span class="o">=</span><span class="n">module_spec</span><span class="o">.</span><span class="n">observation_space</span><span class="p">[</span><span class="s2">&quot;local&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
                <span class="n">action_dim</span><span class="o">=</span><span class="n">module_spec</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_rl_modules</span> <span class="o">=</span> <span class="n">rl_modules</span>


</pre></div>
</div>
</div>
</div>
<p>To construct this custom multi-agent RL module, pass the class to the <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec.html#ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec" title="ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAgentRLModuleSpec</span></code></a> constructor. Also, pass the <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec.html#ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec" title="ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleAgentRLModuleSpec</span></code></a> for each agent because RLlib requires the observation, action spaces, and model hyper-parameters for each agent.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">SingleAgentRLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.marl_module</span> <span class="kn">import</span> <span class="n">MultiAgentRLModuleSpec</span>

<span class="n">spec</span> <span class="o">=</span> <span class="n">MultiAgentRLModuleSpec</span><span class="p">(</span>
    <span class="n">marl_module_class</span><span class="o">=</span><span class="n">BCTorchMultiAgentModuleWithSharedEncoder</span><span class="p">,</span>
    <span class="n">module_specs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;local_2d&quot;</span><span class="p">:</span> <span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span>
            <span class="n">observation_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;global&quot;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,)),</span>
                    <span class="s2">&quot;local&quot;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,)),</span>
                <span class="p">}</span>
            <span class="p">),</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">]},</span>
        <span class="p">),</span>
        <span class="s2">&quot;local_5d&quot;</span><span class="p">:</span> <span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span>
            <span class="n">observation_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;global&quot;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,)),</span>
                    <span class="s2">&quot;local&quot;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,)),</span>
                <span class="p">}</span>
            <span class="p">),</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
            <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fcnet_hiddens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">]},</span>
        <span class="p">),</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="extending-existing-rllib-rl-modules">
<h2>Extending Existing RLlib RL Modules<a class="headerlink" href="rllib-rlmodule.html#extending-existing-rllib-rl-modules" title="Permalink to this headline">#</a></h2>
<p>RLlib provides a number of RL Modules for different frameworks (e.g., PyTorch, TensorFlow, etc.). Extend these modules by inheriting from them and overriding the methods you need to customize. For example, extend <code class="xref py py-class docutils literal notranslate"><span class="pre">PPOTorchRLModule</span></code> and augment it with your own customization. Then pass the new customized class into the algorithm configuration.</p>
<p>There are two possible ways to extend existing RL Modules:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-13" name="sd-tab-set-6" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-13">
Inheriting existing RL Modules</label><div class="sd-tab-content docutils">
<p>One way to extend existing RL Modules is to inherit from them and override the methods you need to customize. For example, extend <code class="xref py py-class docutils literal notranslate"><span class="pre">PPOTorchRLModule</span></code> and augment it with your own customization. Then pass the new customized class into the algorithm configuration to use the PPO algorithm to optimize your custom RL Module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyPPORLModule</span><span class="p">(</span><span class="n">PPORLModule</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">RLModuleConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="o">...</span>

<span class="c1"># Pass in the custom RL Module class to the spec</span>
<span class="n">algo_config</span> <span class="o">=</span> <span class="n">algo_config</span><span class="o">.</span><span class="n">rl_module</span><span class="p">(</span>
    <span class="n">rl_module_spec</span><span class="o">=</span><span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span><span class="n">module_class</span><span class="o">=</span><span class="n">MyPPORLModule</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-14" name="sd-tab-set-6" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-14">
Extending RL Module Catalog</label><div class="sd-tab-content docutils">
<p>Another way to customize your module is by extending its <a class="reference internal" href="package_ref/doc/ray.rllib.core.models.catalog.Catalog.html#ray.rllib.core.models.catalog.Catalog" title="ray.rllib.core.models.catalog.Catalog"><code class="xref py py-class docutils literal notranslate"><span class="pre">Catalog</span></code></a>. The <a class="reference internal" href="package_ref/doc/ray.rllib.core.models.catalog.Catalog.html#ray.rllib.core.models.catalog.Catalog" title="ray.rllib.core.models.catalog.Catalog"><code class="xref py py-class docutils literal notranslate"><span class="pre">Catalog</span></code></a> is a component that defines the default architecture and behavior of a model based on factors such as <code class="docutils literal notranslate"><span class="pre">observation_space</span></code>, <code class="docutils literal notranslate"><span class="pre">action_space</span></code>, etc. To modify sub-components of an existing RL Module, extend the corresponding Catalog class.</p>
<p>For instance, to adapt the existing <code class="docutils literal notranslate"><span class="pre">PPORLModule</span></code> for a custom graph observation space not supported by RLlib out-of-the-box, extend the <a class="reference internal" href="package_ref/doc/ray.rllib.core.models.catalog.Catalog.html#ray.rllib.core.models.catalog.Catalog" title="ray.rllib.core.models.catalog.Catalog"><code class="xref py py-class docutils literal notranslate"><span class="pre">Catalog</span></code></a> class used to create the <code class="docutils literal notranslate"><span class="pre">PPORLModule</span></code> and override the method responsible for returning the encoder component to ensure that your custom encoder replaces the default one initially provided by RLlib. For more information on the <a class="reference internal" href="package_ref/doc/ray.rllib.core.models.catalog.Catalog.html#ray.rllib.core.models.catalog.Catalog" title="ray.rllib.core.models.catalog.Catalog"><code class="xref py py-class docutils literal notranslate"><span class="pre">Catalog</span></code></a> class, refer to the <a class="reference external" href="rllib-catalogs.html">Catalog user guide</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyAwesomeCatalog</span><span class="p">(</span><span class="n">PPOCatalog</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">get_actor_critic_encoder_config</span><span class="p">():</span>
        <span class="c1"># create your awesome graph encoder here and return it</span>
        <span class="k">pass</span>


<span class="c1"># Pass in the custom catalog class to the spec</span>
<span class="n">algo_config</span> <span class="o">=</span> <span class="n">algo_config</span><span class="o">.</span><span class="n">rl_module</span><span class="p">(</span>
    <span class="n">rl_module_spec</span><span class="o">=</span><span class="n">SingleAgentRLModuleSpec</span><span class="p">(</span><span class="n">catalog_class</span><span class="o">=</span><span class="n">MyAwesomeCatalog</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="migrating-from-custom-policies-and-models-to-rl-modules">
<h2>Migrating from Custom Policies and Models to RL Modules<a class="headerlink" href="rllib-rlmodule.html#migrating-from-custom-policies-and-models-to-rl-modules" title="Permalink to this headline">#</a></h2>
<p>This document is for those who have implemented custom policies and models in RLlib and want to migrate to the new <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RLModule</span></code></a> API. If you have implemented custom policies that extended the <a class="reference internal" href="package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.html#ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2" title="ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EagerTFPolicyV2</span></code></a> or <a class="reference internal" href="package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.html#ray.rllib.policy.torch_policy_v2.TorchPolicyV2" title="ray.rllib.policy.torch_policy_v2.TorchPolicyV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TorchPolicyV2</span></code></a> classes, you likely did so that you could either modify the behavior of constructing models and distributions (via overriding <a class="reference internal" href="package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model.html#ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model" title="ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_model</span></code></a>, <a class="reference internal" href="package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model_and_action_dist.html#ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model_and_action_dist" title="ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model_and_action_dist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_model_and_action_dist</span></code></a>), control the action sampling logic (via overriding <a class="reference internal" href="package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_distribution_fn.html#ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_distribution_fn" title="ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_distribution_fn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">action_distribution_fn</span></code></a> or <a class="reference internal" href="package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_sampler_fn.html#ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_sampler_fn" title="ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_sampler_fn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">action_sampler_fn</span></code></a>), or control the logic for infernce (via overriding <a class="reference internal" href="package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions_from_input_dict.html#ray.rllib.policy.policy.Policy.compute_actions_from_input_dict" title="ray.rllib.policy.policy.Policy.compute_actions_from_input_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_actions_from_input_dict</span></code></a>, <a class="reference internal" href="package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions.html#ray.rllib.policy.policy.Policy.compute_actions" title="ray.rllib.policy.policy.Policy.compute_actions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_actions</span></code></a>, or <a class="reference internal" href="package_ref/doc/ray.rllib.policy.policy.Policy.compute_log_likelihoods.html#ray.rllib.policy.policy.Policy.compute_log_likelihoods" title="ray.rllib.policy.policy.Policy.compute_log_likelihoods"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_log_likelihoods</span></code></a>). These APIs were built with <a class="reference internal" href="package_ref/doc/ray.rllib.models.modelv2.ModelV2.html#ray.rllib.models.modelv2.ModelV2" title="ray.rllib.models.modelv2.ModelV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ray.rllib.models.modelv2.ModelV2</span></code></a> models in mind to enable you to customize the behavior of those functions. However <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RLModule</span></code></a> is a more general abstraction that will reduce the amount of functions that you need to override.</p>
<p>In the new <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html#ray.rllib.core.rl_module.rl_module.RLModule" title="ray.rllib.core.rl_module.rl_module.RLModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RLModule</span></code></a> API the construction of the models and the action distribution class that should be used are best defined in the constructor. That RL Module is constructed automatically if users follow the instructions outlined in the sections <a class="reference internal" href="rllib-rlmodule.html#enabling-rl-modules-in-the-configuration">Enabling RL Modules in the Configuration</a> and <a class="reference internal" href="rllib-rlmodule.html#constructing-rl-modules">Constructing RL Modules</a>. <a class="reference internal" href="package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions.html#ray.rllib.policy.policy.Policy.compute_actions" title="ray.rllib.policy.policy.Policy.compute_actions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_actions</span></code></a> and <a class="reference internal" href="package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions_from_input_dict.html#ray.rllib.policy.policy.Policy.compute_actions_from_input_dict" title="ray.rllib.policy.policy.Policy.compute_actions_from_input_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_actions_from_input_dict</span></code></a> can still be used for sampling actions for inference or exploration by using the <code class="docutils literal notranslate"><span class="pre">explore=True|False</span></code> parameter. If called with <code class="docutils literal notranslate"><span class="pre">explore=True</span></code> these functions will invoke <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward_exploration</span></code></a> and if <code class="docutils literal notranslate"><span class="pre">explore=False</span></code> then they will call <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_inference"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward_inference</span></code></a>.</p>
<p>What your customization could have looked like before:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-15" name="sd-tab-set-7" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-15">
ModelV2</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.rllib.models.torch.torch_modelv2</span> <span class="kn">import</span> <span class="n">TorchModelV2</span>
<span class="kn">from</span> <span class="nn">ray.rllib.policy.torch_policy_v2</span> <span class="kn">import</span> <span class="n">TorchPolicyV2</span>


<span class="k">class</span> <span class="nc">MyCustomModel</span><span class="p">(</span><span class="n">TorchModelV2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Code for your previous custom model&quot;&quot;&quot;</span>
    <span class="o">...</span>


<span class="k">class</span> <span class="nc">CustomPolicy</span><span class="p">(</span><span class="n">TorchPolicyV2</span><span class="p">):</span>

    <span class="nd">@DeveloperAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">make_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelV2</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create model.</span>

<span class="sd">        Note: only one of make_model or make_model_and_action_dist</span>
<span class="sd">        can be overridden.</span>

<span class="sd">        Returns:</span>
<span class="sd">        ModelV2 model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">MyCustomModel</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-16" name="sd-tab-set-7" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-16">
ModelV2 + Distribution</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.rllib.models.torch.torch_modelv2</span> <span class="kn">import</span> <span class="n">TorchModelV2</span>
<span class="kn">from</span> <span class="nn">ray.rllib.policy.torch_policy_v2</span> <span class="kn">import</span> <span class="n">TorchPolicyV2</span>


<span class="k">class</span> <span class="nc">MyCustomModel</span><span class="p">(</span><span class="n">TorchModelV2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Code for your previous custom model&quot;&quot;&quot;</span>
    <span class="o">...</span>


<span class="k">class</span> <span class="nc">CustomPolicy</span><span class="p">(</span><span class="n">TorchPolicyV2</span><span class="p">):</span>

    <span class="nd">@DeveloperAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">make_model_and_action_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create model and action distribution function.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ModelV2 model.</span>
<span class="sd">            ActionDistribution class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">my_model</span> <span class="o">=</span> <span class="n">MyCustomModel</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="c1"># construct some ModelV2 instance here</span>
        <span class="n">dist_class</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># Action distribution cls</span>

        <span class="k">return</span> <span class="n">my_model</span><span class="p">,</span> <span class="n">dist_class</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-17" name="sd-tab-set-7" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-17">
Sampler functions</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.rllib.models.torch.torch_modelv2</span> <span class="kn">import</span> <span class="n">TorchModelV2</span>
<span class="kn">from</span> <span class="nn">ray.rllib.policy.torch_policy_v2</span> <span class="kn">import</span> <span class="n">TorchPolicyV2</span>

<span class="k">class</span> <span class="nc">CustomPolicy</span><span class="p">(</span><span class="n">TorchPolicyV2</span><span class="p">):</span>

    <span class="nd">@DeveloperAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">action_sampler_fn</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">ModelV2</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">TensorType</span><span class="p">,</span>
        <span class="n">state_batches</span><span class="p">:</span> <span class="n">TensorType</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Custom function for sampling new actions given policy.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: Underlying model.</span>
<span class="sd">            obs_batch: Observation tensor batch.</span>
<span class="sd">            state_batches: Action sampling state batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Sampled action</span>
<span class="sd">            Log-likelihood</span>
<span class="sd">            Action distribution inputs</span>
<span class="sd">            Updated state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>


    <span class="nd">@DeveloperAPI</span>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">action_distribution_fn</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">ModelV2</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">TensorType</span><span class="p">,</span>
        <span class="n">state_batches</span><span class="p">:</span> <span class="n">TensorType</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Action distribution function for this Policy.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: Underlying model.</span>
<span class="sd">            obs_batch: Observation tensor batch.</span>
<span class="sd">            state_batches: Action sampling state batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Distribution input.</span>
<span class="sd">            ActionDistribution class.</span>
<span class="sd">            State outs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
<p>All of the <code class="docutils literal notranslate"><span class="pre">Policy.compute_***</span></code> functions expect that
<a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_exploration()</span></code></a> and <a class="reference internal" href="package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html#ray.rllib.core.rl_module.rl_module.RLModule.forward_inference" title="ray.rllib.core.rl_module.rl_module.RLModule.forward_inference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_inference()</span></code></a>
return a dictionary that either contains the key “actions” and/or the key “action_dist_inputs”.</p>
<p>See <a class="reference internal" href="rllib-rlmodule.html#writing-custom-single-agent-rl-modules">Writing Custom Single Agent RL Modules</a> for more details on how to implement your own custom RL Modules.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-18" name="sd-tab-set-8" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-18">
The Equivalent RL Module</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">No need to override any policy functions. Simply instead implement any custom logic in your custom RL Module</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">ray.rllib.models.torch.torch_distributions</span> <span class="kn">import</span> <span class="n">YOUR_DIST_CLASS</span>


<span class="k">class</span> <span class="nc">MyRLModule</span><span class="p">(</span><span class="n">TorchRLModule</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">RLConfig</span><span class="p">):</span>
        <span class="c1"># construct any custom networks here using config</span>
        <span class="c1"># specify an action distribution class here</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">_forward_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">_forward_exploration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="notable-todos">
<h2>Notable TODOs<a class="headerlink" href="rllib-rlmodule.html#notable-todos" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>[] Add support for RNNs.</p></li>
<li><p>[] Checkpointing.</p></li>
<li><p>[] End to end example for custom RL Modules extending PPORLModule (e.g. LLM)</p></li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="rllib-connector.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Connectors (Alpha)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="rllib-fault-tolerance.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Fault Tolerance And Elastic Training</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>