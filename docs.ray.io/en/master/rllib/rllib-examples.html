
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Examples &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/versionwarning.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../_static/js/docsearch.js"></script>
    <script src="../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../_static/js/termynal.js"></script>
    <script defer="defer" src="../_static/js/custom.js"></script>
    <script defer="defer" src="../_static/js/top-navigation.js"></script>
    <script src="../_static/js/tags.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/rllib/rllib-examples.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Ray RLlib API" href="package_ref/index.html" />
    <link rel="prev" title="Working with the RLlib CLI" href="rllib-cli.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "rllib/rllib-examples", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Ray RLlib
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-training.html">
     Getting Started with RLlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rllib-env.html">
     Environments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rllib-algorithms.html">
     Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="user-guides.html">
     User Guides
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="rllib-examples.html#">
     Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="package_ref/index.html">
     Ray RLlib API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Frllib/rllib-examples.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/rllib/rllib-examples.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/rllib/rllib-examples.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#tuned-examples">
   Tuned Examples
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#blog-posts">
   Blog Posts
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#environments-and-adapters">
   Environments and Adapters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#custom-and-complex-models">
   Custom- and Complex Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#training-workflows">
   Training Workflows
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#evaluation">
   Evaluation:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#serving-and-offline">
   Serving and Offline
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#multi-agent-and-hierarchical">
   Multi-Agent and Hierarchical
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#gpu-examples">
   GPU examples
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#special-action-and-observation-spaces">
   Special Action- and Observation Spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#community-examples">
   Community Examples
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Examples</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#tuned-examples">
   Tuned Examples
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#blog-posts">
   Blog Posts
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#environments-and-adapters">
   Environments and Adapters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#custom-and-complex-models">
   Custom- and Complex Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#training-workflows">
   Training Workflows
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#evaluation">
   Evaluation:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#serving-and-offline">
   Serving and Offline
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#multi-agent-and-hierarchical">
   Multi-Agent and Hierarchical
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#gpu-examples">
   GPU examples
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#special-action-and-observation-spaces">
   Special Action- and Observation Spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="rllib-examples.html#community-examples">
   Community Examples
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/top.png" /></a>
<div class="bottom-right-promo-banner docutils">
<a class="reference external image-reference" href="https://ray-docs-promo.netlify.app/rllib"><img alt="" src="https://ray-docs-promo.netlify.app/assets/img/rllib/square.png" /></a>
</div>
<section id="examples">
<h1>Examples<a class="headerlink" href="rllib-examples.html#examples" title="Permalink to this headline">#</a></h1>
<p>This page is an index of examples for the various use cases and features of RLlib.</p>
<p>If any example is broken, or if you’d like to add an example to this page,
feel free to raise an issue on our Github repository.</p>
<section id="tuned-examples">
<h2>Tuned Examples<a class="headerlink" href="rllib-examples.html#tuned-examples" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/tuned_examples">Tuned examples</a>:</dt><dd><p>Collection of tuned hyperparameters by algorithm.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/rl-experiments">MuJoCo and Atari benchmarks</a>:</dt><dd><p>Collection of reasonably optimized Atari and MuJoCo results.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="blog-posts">
<h2>Blog Posts<a class="headerlink" href="rllib-examples.html#blog-posts" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://medium.com/distributed-computing-with-ray/attention-nets-and-more-with-rllibs-trajectory-view-api-d326339a6e65">Attention Nets and More with RLlib’s Trajectory View API</a>:</dt><dd><p>This blog describes RLlib’s new “trajectory view API” and how it enables implementations of GTrXL (attention net) architectures.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://medium.com/distributed-computing-with-ray/reinforcement-learning-with-rllib-in-the-unity-game-engine-1a98080a7c0d">Reinforcement Learning with RLlib in the Unity Game Engine</a>:</dt><dd><p>A how-to on connecting RLlib with the Unity3D game engine for running visual- and physics-based RL experiments.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://medium.com/distributed-computing-with-ray/lessons-from-implementing-12-deep-rl-algorithms-in-tf-and-pytorch-1b412009297d">Lessons from Implementing 12 Deep RL Algorithms in TF and PyTorch</a>:</dt><dd><p>Discussion on how we ported 12 of RLlib’s algorithms from TensorFlow to PyTorch and what we learnt on the way.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="http://bair.berkeley.edu/blog/2018/12/12/rllib">Scaling Multi-Agent Reinforcement Learning</a>:</dt><dd><p>This blog post is a brief tutorial on multi-agent RL and its design in RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://medium.com/riselab/functional-rl-with-keras-and-tensorflow-eager-7973f81d6345">Functional RL with Keras and TensorFlow Eager</a>:</dt><dd><p>Exploration of a functional paradigm for implementing reinforcement learning (RL) algorithms.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="environments-and-adapters">
<h2>Environments and Adapters<a class="headerlink" href="rllib-examples.html#environments-and-adapters" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_env.py">Registering a custom env and model</a>:</dt><dd><p>Example of defining and registering a gym env and model for use with RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/tree/master/rllib/examples/unity3d_env_local.py">Local Unity3D multi-agent environment example</a>:</dt><dd><p>Example of how to setup an RLlib Algorithm against a locally running Unity3D editor instance to
learn any Unity3D game (including support for multi-agent).
Use this example to try things out and watch the game and the learning progress live in the editor.
Providing a compiled game, this example could also run in distributed fashion with <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_workers</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>.
For a more heavy-weight, distributed, cloud-based example, see <code class="docutils literal notranslate"><span class="pre">Unity3D</span> <span class="pre">client/server</span></code> below.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/env_rendering_and_recording.py">Rendering and recording of an environment</a>:</dt><dd><p>Example showing how to switch on rendering and recording of an env.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/coin_game_env.py">Coin Game Example</a>:</dt><dd><p>Coin Game Env Example (provided by the “Center on Long Term Risk”).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/dmlab_watermaze.py">DMLab Watermaze example</a>:</dt><dd><p>Example for how to use a DMLab environment (Watermaze).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/recommender_system_with_recsim_and_slateq.py">RecSym environment example (for recommender systems) using the SlateQ algorithm</a>:</dt><dd><p>Script showing how to train SlateQ on a RecSym environment.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/sumo_env_local.py">SUMO (Simulation of Urban MObility) environment example</a>:</dt><dd><p>Example demonstrating how to use the SUMO simulator in connection with RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/vizdoom_with_attention_net.py">VizDoom example script using RLlib’s auto-attention wrapper</a>:</dt><dd><p>Script showing how to run PPO with an attention net against a VizDoom gym environment.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/env/tests/test_env_with_subprocess.py">Subprocess environment</a>:</dt><dd><p>Example of how to ensure subprocesses spawned by envs are killed when RLlib exits.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="custom-and-complex-models">
<h2>Custom- and Complex Models<a class="headerlink" href="rllib-examples.html#custom-and-complex-models" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/attention_net.py">Attention Net (GTrXL) learning the “repeat-after-me” environment</a>:</dt><dd><p>Example showing how to use the auto-attention wrapper for your default- and custom models in RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/lstm_auto_wrapping.py">LSTM model learning the “repeat-after-me” environment</a>:</dt><dd><p>Example showing how to use the auto-LSTM wrapper for your default- and custom models in RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_keras_model.py">Custom Keras model</a>:</dt><dd><p>Example of using a custom Keras model.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_rnn_model.py">Custom Keras/PyTorch RNN model</a>:</dt><dd><p>Example of using a custom Keras- or PyTorch RNN model.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_loss.py">Registering a custom model with supervised loss</a>:</dt><dd><p>Example of defining and registering a custom model with a supervised loss.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/batch_norm_model.py">Batch normalization</a>:</dt><dd><p>Example of adding batch norm layers to a custom model.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/eager_execution.py">Eager execution</a>:</dt><dd><p>Example of how to leverage TensorFlow eager to simplify debugging and design of custom models and policies.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_fast_model.py">Custom “Fast” Model</a>:</dt><dd><p>Example of a “fast” Model learning only one parameter for tf and torch.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_model_api.py">Custom model API example</a>:</dt><dd><p>Shows how to define a custom Model API in RLlib, such that it can be used inside certain algorithms.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/trajectory_view_api.py">Trajectory View API utilizing model</a>:</dt><dd><p>An example on how a model can use the trajectory view API to specify its own input.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/mobilenet_v2_with_lstm.py">MobileNetV2 wrapping example model</a>:</dt><dd><p>Implementations of <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.applications.mobilenet_v2.MobileNetV2</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.hub</span> <span class="pre">(mobilenet_v2)</span></code>-wrapping example models.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/models/neural_computer.py">Differentiable Neural Computer</a>:</dt><dd><p>Example of DeepMind’s Differentiable Neural Computer for partially-observable environments.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="training-workflows">
<h2>Training Workflows<a class="headerlink" href="rllib-examples.html#training-workflows" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_train_fn.py">Custom training workflows</a>:</dt><dd><p>Example of how to use Tune’s support for custom training functions to implement custom training workflows.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/curriculum_learning.py">Curriculum learning with the TaskSettableEnv API</a>:</dt><dd><p>Example of how to advance the environment through different phases (tasks) over time.
Also see the <a class="reference external" href="rllib-training.html#example-curriculum-learning">curriculum learning how-to</a> from the documentation here.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_logger.py">Custom logger</a>:</dt><dd><p>How to setup a custom Logger object in RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_metrics_and_callbacks.py">Custom metrics</a>:</dt><dd><p>Example of how to output custom training metrics to TensorBoard.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_tf_policy.py">Custom Policy class (TensorFlow)</a>:</dt><dd><p>How to setup a custom TFPolicy.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_torch_policy.py">Custom Policy class (PyTorch)</a>:</dt><dd><p>How to setup a custom TorchPolicy.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/rollout_worker_custom_workflow.py">Using rollout workers directly for control over the whole training workflow</a>:</dt><dd><p>Example of how to use RLlib’s lower-level building blocks to implement a fully customized training workflow.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/two_trainer_workflow.py">Custom execution plan function handling two different Policies (DQN and PPO) at the same time</a>:</dt><dd><p>Example of how to use the exec. plan of an Algorithm to trin two different policies in parallel (also using multi-agent API).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_experiment.py">Custom tune experiment</a>:</dt><dd><p>How to run a custom Ray Tune experiment with RLlib with custom training- and evaluation phases.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="evaluation">
<h2>Evaluation:<a class="headerlink" href="rllib-examples.html#evaluation" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_eval.py">Custom evaluation function</a>:</dt><dd><p>Example of how to write a custom evaluation function that is called instead of the default behavior, which is running with the evaluation worker set through n episodes.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/parallel_evaluation_and_training.py">Parallel evaluation and training</a>:</dt><dd><p>Example showing how the evaluation workers and the “normal” rollout workers can run (to some extend) in parallel to speed up training.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="serving-and-offline">
<h2>Serving and Offline<a class="headerlink" href="rllib-examples.html#serving-and-offline" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/tree/master/rllib/examples/offline_rl.py">Offline RL with CQL</a>:</dt><dd><p>Example showing how to run an offline RL training job using a historic-data json file.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference internal" href="../serve/tutorials/rllib.html#serve-rllib-tutorial"><span class="std std-ref">Serving RLlib models with Ray Serve</span></a>: Example of using Ray Serve to serve RLlib models</dt><dd><p>with HTTP and JSON interface. <strong>This is the recommended way to expose RLlib for online serving use case</strong>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/tree/master/rllib/examples/inference_and_serving/serve_and_rllib.py">Another example for using RLlib with Ray Serve</a></dt><dd><p>This script offers a simple workflow for 1) training a policy with RLlib first, 2) creating a new policy 3) restoring its weights from the trained
one and serving the new policy via Ray Serve.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/tree/master/rllib/examples/serving/unity3d_server.py">Unity3D client/server</a>:</dt><dd><p>Example of how to setup n distributed Unity3D (compiled) games in the cloud that function as data collecting
clients against a central RLlib Policy server learning how to play the game.
The n distributed clients could themselves be servers for external/human players and allow for control
being fully in the hands of the Unity entities instead of RLlib.
Note: Uses Unity’s MLAgents SDK (&gt;=1.0) and supports all provided MLAgents example games and multi-agent setups.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/tree/master/rllib/examples/serving/cartpole_server.py">CartPole client/server</a>:</dt><dd><p>Example of online serving of predictions for a simple CartPole policy.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/saving_experiences.py">Saving experiences</a>:</dt><dd><p>Example of how to externally generate experience batches in RLlib-compatible format.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/checkpoint_by_custom_criteria.py">Finding a checkpoint using custom criteria</a>:</dt><dd><p>Example of how to find a <a class="reference internal" href="rllib-saving-and-loading-algos-and-policies.html#rllib-saving-and-loading-algos-and-policies-docs"><span class="std std-ref">checkpoint</span></a> after a <code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuner.fit()</span></code> via some custom defined criteria.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="multi-agent-and-hierarchical">
<h2>Multi-Agent and Hierarchical<a class="headerlink" href="rllib-examples.html#multi-agent-and-hierarchical" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/multi_agent_independent_learning.py">Simple independent multi-agent setup vs a PettingZoo env</a>:</dt><dd><p>Setup RLlib to run any algorithm in (independent) multi-agent mode against a multi-agent environment.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/multi_agent_parameter_sharing.py">More complex (shared-parameter) multi-agent setup vs a PettingZoo env</a>:</dt><dd><p>Setup RLlib to run any algorithm in (shared-parameter) multi-agent mode against a multi-agent environment.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/rock_paper_scissors_multiagent.py">Rock-paper-scissors</a>:</dt><dd><p>Example of different heuristic and learned policies competing against each other in rock-paper-scissors.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/two_step_game.py">Two-step game</a>:</dt><dd><p>Example of the two-step game from the <a class="reference external" href="https://arxiv.org/pdf/1803.11485.pdf">QMIX paper</a>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/Farama-Foundation/PettingZoo/blob/master/tutorials/Ray/rllib_pistonball.py">PettingZoo multi-agent example</a>:</dt><dd><p>Example on how to use RLlib to learn in <a class="reference external" href="https://www.pettingzoo.ml">PettingZoo</a> multi-agent environments.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/centralized_critic.py">PPO with centralized critic on two-step game</a>:</dt><dd><p>Example of customizing PPO to leverage a centralized value function.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/centralized_critic_2.py">Centralized critic in the env</a>:</dt><dd><p>A simpler method of implementing a centralized critic by augmentating agent observations with global information.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/multi_agent_custom_policy.py">Hand-coded policy</a>:</dt><dd><p>Example of running a custom hand-coded policy alongside trainable policies.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/multi_agent_cartpole.py">Weight sharing between policies</a>:</dt><dd><p>Example of how to define weight-sharing layers between two different policies.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/multi_agent_two_trainers.py">Multiple algorithms</a>:</dt><dd><p>Example of alternating training between DQN and PPO.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/hierarchical_training.py">Hierarchical training</a>:</dt><dd><p>Example of hierarchical training using the multi-agent API.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/iterated_prisoners_dilemma_env.py">Iterated Prisoner’s Dilemma environment example</a>:</dt><dd><p>Example of an iterated prisoner’s dilemma environment solved by RLlib.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="gpu-examples">
<h2>GPU examples<a class="headerlink" href="rllib-examples.html#gpu-examples" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/partial_gpus.py">Example showing how to setup fractional GPUs</a>:</dt><dd><p>Example of how to setup fractional GPUs for learning (driver) and environment rollouts (remote workers).</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="special-action-and-observation-spaces">
<h2>Special Action- and Observation Spaces<a class="headerlink" href="rllib-examples.html#special-action-and-observation-spaces" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/nested_action_spaces.py">Nested action spaces</a>:</dt><dd><p>Learning in arbitrarily nested action spaces.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/parametric_actions_cartpole.py">Parametric actions</a>:</dt><dd><p>Example of how to handle variable-length or parametric action spaces (see also <a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/random_parametric_agent.py">this example here</a>).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/custom_observation_filters.py">Custom observation filters</a>:</dt><dd><p>How to filter raw observations coming from the environment for further processing by the Agent’s model(s).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/complex_struct_space.py">Using the “Repeated” space of RLlib for variable lengths observations</a>:</dt><dd><p>How to use RLlib’s <code class="xref py py-obj docutils literal notranslate"><span class="pre">Repeated</span></code> space to handle variable length observations.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ray-project/ray/blob/master/rllib/examples/autoregressive_action_dist.py">Autoregressive action distribution example</a>:</dt><dd><p>Learning with auto-regressive action dependencies (e.g. 2 action components; distribution for 2nd component depends on the 1st component’s actually sampled value).</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="community-examples">
<h2>Community Examples<a class="headerlink" href="rllib-examples.html#community-examples" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference external" href="https://sites.google.com/view/arena-unity/home">Arena AI</a>:</dt><dd><p>A General Evaluation Platform and Building Toolkit for Single/Multi-Agent Intelligence
with RLlib-generated baselines.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/layssi/Carla_Ray_Rlib">CARLA</a>:</dt><dd><p>Example of training autonomous vehicles with RLlib and <a class="reference external" href="http://carla.org/">CARLA</a> simulator.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2008.02616.pdf">The Emergence of Adversarial Communication in Multi-Agent Reinforcement Learning</a>:</dt><dd><p>Using Graph Neural Networks and RLlib to train multiple cooperative and adversarial agents to solve the
“cover the area”-problem, thereby learning how to best communicate (or - in the adversarial case - how to disturb communication) (<a class="reference external" href="https://github.com/proroklab/adversarial_comms">code</a>).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://flatland.aicrowd.com/intro.html">Flatland</a>:</dt><dd><p>A dense traffic simulating environment with RLlib-generated baselines.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/google-research/football/blob/master/gfootball/examples/run_multiagent_rllib.py">GFootball</a>:</dt><dd><p>Example of setting up a multi-agent version of <a class="reference external" href="https://github.com/google-research">GFootball</a> with RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/NeuralMMO/environment">Neural MMO</a>:</dt><dd><p>A multiagent AI research environment inspired by Massively Multiplayer Online (MMO) role playing games –
self-contained worlds featuring thousands of agents per persistent macrocosm, diverse skilling systems, local and global economies, complex emergent social structures,
and ad-hoc high-stakes single and team based conflict.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/neurocuts/neurocuts">NeuroCuts</a>:</dt><dd><p>Example of building packet classification trees using RLlib / multi-agent in a bandit-like setting.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/ucb-bar/NeuroVectorizer">NeuroVectorizer</a>:</dt><dd><p>Example of learning optimal LLVM vectorization compiler pragmas for loops in C and C++ codes using RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/awslabs/amazon-sagemaker-examples/tree/master/reinforcement_learning/rl_roboschool_ray">Roboschool / SageMaker</a>:</dt><dd><p>Example of training robotic control policies in SageMaker with RLlib.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/eugenevinitsky/sequential_social_dilemma_games">Sequential Social Dilemma Games</a>:</dt><dd><p>Example of using the multi-agent API to model several <a class="reference external" href="https://arxiv.org/abs/1702.03037">social dilemma games</a>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/lcipolina/Ray_tutorials/blob/main/RLLIB_Ray2_0.ipynb">Simple custom environment for single RL with Ray 2.0, Tune and Air</a>:</dt><dd><p>Create a custom environment and train a single agent RL using Ray 2.0 with Tune and Air.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/oxwhirl/smac">StarCraft2</a>:</dt><dd><p>Example of training in StarCraft2 maps with RLlib / multi-agent.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://berkeleyflow.readthedocs.io/en/latest/flow_setup.html">Traffic Flow</a>:</dt><dd><p>Example of optimizing mixed-autonomy traffic simulations with RLlib / multi-agent.</p>
</dd>
</dl>
</li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="rllib-cli.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Working with the RLlib CLI</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="package_ref/index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Ray RLlib API</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>