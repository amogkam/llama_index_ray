
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Serving ML Models (Tensorflow, PyTorch, Scikit-Learn, others) &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/versionwarning.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../_static/js/docsearch.js"></script>
    <script src="../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../_static/js/custom.js"></script>
    <script defer="defer" src="../../_static/js/top-navigation.js"></script>
    <script src="../../_static/js/tags.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/serve/tutorials/serve-ml-models.html" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Batching Tutorial" href="batch.html" />
    <link rel="prev" title="Examples" href="index.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "serve/tutorials/serve-ml-models", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".md", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Ray Serve
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../getting_started.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model_composition.html">
     Deploy a Composition of Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deploy-many-models/index.html">
     Deploy Many Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../http-guide.html">
     Set Up FastAPI and HTTP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../production-guide/index.html">
     Production Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../monitoring.html">
     Monitor Your Application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scaling-and-resource-allocation.html">
     Set Up Autoscaling and Resource Allocation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../advanced-guides/index.html">
     Advanced Guides
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../architecture.html">
     Architecture
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     Examples
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="serve-ml-models.html#">
       Serving ML Models (Tensorflow, PyTorch, Scikit-Learn, others)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="batch.html">
       Batching Tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rllib.html">
       Serving RLlib Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gradio-integration.html">
       Scaling your Gradio app with Ray Serve
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gradio-dag-visualization.html">
       Visualizing a Deployment Graph with Gradio
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="java.html">
       Java Tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="stable-diffusion.html">
       Serving a Stable Diffusion Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="text-classification.html">
       Serving a Distilbert Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="object-detection.html">
       Serving an Object Detection Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="deployment-graph-patterns.html">
       Deployment Graph Patterns
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/index.html">
     Ray Serve API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Fserve/tutorials/serve-ml-models.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/serve/tutorials/serve-ml-models.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/serve/tutorials/serve-ml-models.md.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Serving ML Models (Tensorflow, PyTorch, Scikit-Learn, others)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="serving-ml-models-tensorflow-pytorch-scikit-learn-others">
<span id="serve-ml-models-tutorial"></span><h1>Serving ML Models (Tensorflow, PyTorch, Scikit-Learn, others)<a class="headerlink" href="serve-ml-models.html#serving-ml-models-tensorflow-pytorch-scikit-learn-others" title="Permalink to this headline">#</a></h1>
<p>In this guide, we will show you how to train models from various machine learning frameworks and deploy them to Ray Serve.</p>
<p>Please see the <a class="reference internal" href="../key-concepts.html#serve-key-concepts"><span class="std std-ref">Key Concepts</span></a> to learn more general information about Ray Serve.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-0">
Keras and Tensorflow</label><div class="sd-tab-content docutils">
<p>Let’s train and deploy a simple Tensorflow neural net.
In particular, we will show:</p>
<ul class="simple">
<li><p>How to train a Tensorflow model and load the model from your file system in your Ray Serve deployment.</p></li>
<li><p>How to parse the JSON request and make a prediction.</p></li>
</ul>
<p>Ray Serve is framework-agnostic – you can use any version of Tensorflow.
However, for this tutorial, we will use Tensorflow 2 and Keras. We will also need <code class="docutils literal notranslate"><span class="pre">requests</span></code> to send HTTP requests to your model deployment. If you haven’t already, please install Tensorflow 2 and requests by running:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>pip install <span class="s2">&quot;tensorflow&gt;=2.0&quot;</span> requests
</pre></div>
</div>
<p>Open a new Python file called <code class="docutils literal notranslate"><span class="pre">tutorial_tensorflow.py</span></code>. First, let’s import Ray Serve and some other helpers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">serve</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">starlette.requests</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
<p>Next, let’s train a simple MNIST model using Keras.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TRAINED_MODEL_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">gettempdir</span><span class="p">(),</span> <span class="s2">&quot;mnist_model.h5&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_and_save_model</span><span class="p">():</span>
    <span class="c1"># Load mnist dataset</span>
    <span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>
    <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

    <span class="c1"># Train a simple neural net model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

    <span class="c1"># Save the model in h5 format in local file system</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">TRAINED_MODEL_PATH</span><span class="p">)</span>


<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">TRAINED_MODEL_PATH</span><span class="p">):</span>
    <span class="n">train_and_save_model</span><span class="p">()</span>
</pre></div>
</div>
<p>Next, we define a class <code class="docutils literal notranslate"><span class="pre">TFMnistModel</span></code> that will accept HTTP requests and run the MNIST model that we trained. It is decorated with <code class="docutils literal notranslate"><span class="pre">&#64;serve.deployment</span></code> to make it a deployment object, so it can be deployed onto Ray Serve. Note that the Serve deployment is exposed over an HTTP route, and by default the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method is invoked when a request is sent to your deployment over HTTP.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@serve</span><span class="o">.</span><span class="n">deployment</span>
<span class="k">class</span> <span class="nc">TFMnistModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span> <span class="o">=</span> <span class="n">model_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">starlette_request</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="c1"># Step 1: transform HTTP request -&gt; tensorflow input</span>
        <span class="c1"># Here we define the request schema to be a json array.</span>
        <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="k">await</span> <span class="n">starlette_request</span><span class="o">.</span><span class="n">json</span><span class="p">())[</span><span class="s2">&quot;array&quot;</span><span class="p">])</span>
        <span class="n">reshaped_array</span> <span class="o">=</span> <span class="n">input_array</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>

        <span class="c1"># Step 2: tensorflow input -&gt; tensorflow output</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">reshaped_array</span><span class="p">)</span>

        <span class="c1"># Step 3: tensorflow output -&gt; web output</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">prediction</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code class="docutils literal notranslate"><span class="pre">TFMnistModel</span></code> is deployed and instantiated, it will load the Tensorflow model from your file system so that it can be ready to run inference on the model and serve requests later.</p>
</div>
<p>Now that we’ve defined our Serve deployment, let’s prepare it so that it can be deployed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_model</span> <span class="o">=</span> <span class="n">TFMnistModel</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">TRAINED_MODEL_PATH</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">TFMnistModel.bind(TRAINED_MODEL_PATH)</span></code> binds the argument <code class="docutils literal notranslate"><span class="pre">TRAINED_MODEL_PATH</span></code> to our deployment and returns a <code class="docutils literal notranslate"><span class="pre">DeploymentNode</span></code> object (wrapping an <code class="docutils literal notranslate"><span class="pre">TFMnistModel</span></code> deployment object) that can then be used to connect with other <code class="docutils literal notranslate"><span class="pre">DeploymentNodes</span></code> to form a more complex <a class="reference internal" href="../advanced-guides/deployment-graphs.html#serve-deployment-graphs"><span class="std std-ref">deployment graph</span></a>.</p>
</div>
<p>Finally, we can deploy our model to Ray Serve through the terminal.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>serve run tutorial_tensorflow:mnist_model
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you see the following error:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">TypeError: Descriptors cannot not be created directly.</span>
<span class="go">    If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc &gt;= 3.19.0.</span>
<span class="go">    If you cannot immediately regenerate your protos, some other possible workarounds are:</span>
<span class="go">     1. Downgrade the protobuf package to 3.20.x or lower.</span>
<span class="go">     2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).</span>
</pre></div>
</div>
<p>You can downgrade the protobuf package to 3.20.x or lower in your Docker image, or tell Ray to do it at runtime by specifying a <a class="reference internal" href="../../ray-core/handling-dependencies.html#runtime-environments"><span class="std std-ref">runtime environment</span></a>:</p>
<p>Open a new YAML file called <code class="docutils literal notranslate"><span class="pre">tf_env.yaml</span></code> for runtime environment.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pip</span><span class="p">:</span><span class="w"></span>
<span class="w"> </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">protobuf==3.20.3</span><span class="w"></span>
</pre></div>
</div>
<p>Then, run the following command to deploy the model with the runtime environment.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>serve run --runtime-env tf_env.yaml tutorial_tensorflow:mnist_model
</pre></div>
</div>
</div>
<p>Let’s query it! While Serve is running, open a separate terminal window, and run the following in an interactive Python shell or a separate Python script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
    <span class="s2">&quot;http://localhost:8000/&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;array&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
<p>You should get an output like the following (the exact prediction may vary):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">{</span>
 <span class="s2">&quot;prediction&quot;</span>: <span class="o">[[</span>-1.504277229309082, ..., -6.793371200561523<span class="o">]]</span>,
 <span class="s2">&quot;file&quot;</span>: <span class="s2">&quot;/tmp/mnist_model.h5&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-1">
Pytorch</label><div class="sd-tab-content docutils">
<p>Let’s load and deploy a PyTorch Resnet Model.
In particular, we will show:</p>
<ul class="simple">
<li><p>How to load the model from PyTorch’s pre-trained modelzoo.</p></li>
<li><p>How to parse the JSON request, transform the payload and make a prediction.</p></li>
</ul>
<p>This tutorial will require PyTorch and Torchvision. Ray Serve is framework agnostic and works with any version of PyTorch. We will also need <code class="docutils literal notranslate"><span class="pre">requests</span></code> to send HTTP requests to your model deployment. If you haven’t already, please install them by running:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>pip install torch torchvision requests
</pre></div>
</div>
<p>Open a new Python file called <code class="docutils literal notranslate"><span class="pre">tutorial_pytorch.py</span></code>. First, let’s import Ray Serve and some other helpers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">serve</span>

<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">starlette.requests</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">resnet18</span>
</pre></div>
</div>
<p>We define a class <code class="docutils literal notranslate"><span class="pre">ImageModel</span></code> that parses the input data, transforms the images, and runs the ResNet18 model loaded from <code class="docutils literal notranslate"><span class="pre">torchvision</span></code>. It is decorated with <code class="docutils literal notranslate"><span class="pre">&#64;serve.deployment</span></code> to make it a deployment object so it can be deployed onto Ray Serve. Note that the Serve deployment is exposed over an HTTP route, and by default the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method is invoked when a request is sent to your deployment over HTTP.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@serve</span><span class="o">.</span><span class="n">deployment</span>
<span class="k">class</span> <span class="nc">ImageModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="o">...</span><span class="p">]),</span>  <span class="c1"># remove alpha channel</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
                    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                <span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">starlette_request</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="n">image_payload_bytes</span> <span class="o">=</span> <span class="k">await</span> <span class="n">starlette_request</span><span class="o">.</span><span class="n">body</span><span class="p">()</span>
        <span class="n">pil_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image_payload_bytes</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[1/3] Parsed image data: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pil_image</span><span class="p">))</span>

        <span class="n">pil_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">pil_image</span><span class="p">]</span>  <span class="c1"># Our current batch size is one</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">preprocessor</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pil_images</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[2/3] Images transformed, tensor shape </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">output_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[3/3] Inference done!&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;class_index&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]))}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code class="docutils literal notranslate"><span class="pre">ImageModel</span></code> is deployed and instantiated, it will load the resnet18 model from <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> so that it can be ready to run inference on the model and serve requests later.</p>
</div>
<p>Now that we’ve defined our Serve deployment, let’s prepare it so that it can be deployed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">image_model</span> <span class="o">=</span> <span class="n">ImageModel</span><span class="o">.</span><span class="n">bind</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">ImageModel.bind()</span></code> returns a <code class="docutils literal notranslate"><span class="pre">DeploymentNode</span></code> object (wrapping an <code class="docutils literal notranslate"><span class="pre">ImageModel</span></code> deployment object) that can then be used to connect with other <code class="docutils literal notranslate"><span class="pre">DeploymentNodes</span></code> to form a more complex <a class="reference internal" href="../advanced-guides/deployment-graphs.html#serve-deployment-graphs"><span class="std std-ref">deployment graph</span></a>.</p>
</div>
<p>Finally, we can deploy our model to Ray Serve through the terminal.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>serve run tutorial_pytorch:image_model
</pre></div>
</div>
<p>Let’s query it! While Serve is running, open a separate terminal window, and run the following in an interactive Python shell or a separate Python script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>

<span class="n">ray_logo_bytes</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
    <span class="s2">&quot;https://raw.githubusercontent.com/ray-project/&quot;</span>
    <span class="s2">&quot;ray/master/doc/source/images/ray_header_logo.png&quot;</span>
<span class="p">)</span><span class="o">.</span><span class="n">content</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s2">&quot;http://localhost:8000/&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">ray_logo_bytes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
<p>You should get an output like the following (the exact number may vary):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">{</span><span class="s1">&#39;class_index&#39;</span>: <span class="m">919</span><span class="o">}</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-2">
Scikit-Learn</label><div class="sd-tab-content docutils">
<p>Let’s train and deploy a simple Scikit-Learn classifier.
In particular, we will show:</p>
<ul class="simple">
<li><p>How to load the Scikit-Learn model from file system in your Ray Serve definition.</p></li>
<li><p>How to parse the JSON request and make a prediction.</p></li>
</ul>
<p>Ray Serve is framework-agnostic. You can use any version of sklearn. We will also need <code class="docutils literal notranslate"><span class="pre">requests</span></code> to send HTTP requests to your model deployment. If you haven’t already, please install scikit-learn and requests by running:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>pip install scikit-learn requests
</pre></div>
</div>
<p>Open a new Python file called <code class="docutils literal notranslate"><span class="pre">tutorial_sklearn.py</span></code>. Let’s import Ray Serve and some other helpers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">serve</span>

<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">starlette.requests</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
</pre></div>
</div>
<p><strong>Train a Classifier</strong></p>
<p>We will train a classifier with the <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html">iris dataset</a>.</p>
<p>First, let’s instantiate a <code class="docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> loaded from Scikit-Learn.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">()</span>
</pre></div>
</div>
<p>Next, load the iris dataset and split the data into training and validation sets.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">iris_dataset</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">target_names</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">iris_dataset</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span>
    <span class="n">iris_dataset</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">],</span>
    <span class="n">iris_dataset</span><span class="p">[</span><span class="s2">&quot;target_names&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">target</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
<span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">100</span><span class="p">:],</span> <span class="n">target</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span>
</pre></div>
</div>
<p>We then train the model and save it to file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_x</span><span class="p">),</span> <span class="n">val_y</span><span class="p">))</span>

<span class="c1"># Save the model and label to file</span>
<span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">tempfile</span><span class="o">.</span><span class="n">gettempdir</span><span class="p">(),</span> <span class="s2">&quot;iris_model_gradient_boosting_classifier.pkl&quot;</span>
<span class="p">)</span>
<span class="n">LABEL_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">gettempdir</span><span class="p">(),</span> <span class="s2">&quot;iris_labels.json&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">LABEL_PATH</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">target_names</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Deploy with Ray Serve</strong></p>
<p>Finally, we are ready to deploy the classifier using Ray Serve!</p>
<p>We define a class <code class="docutils literal notranslate"><span class="pre">BoostingModel</span></code> that runs inference on the <code class="docutils literal notranslate"><span class="pre">GradientBoosingClassifier</span></code> model we trained and returns the resulting label. It is decorated with <code class="docutils literal notranslate"><span class="pre">&#64;serve.deployment</span></code> to make it a deployment object so it can be deployed onto Ray Serve. Note that the Serve deployment is exposed over an HTTP route, and by default the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method is invoked when a request is sent to your deployment over HTTP.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@serve</span><span class="o">.</span><span class="n">deployment</span>
<span class="k">class</span> <span class="nc">BoostingModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">label_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">label_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">starlette_request</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">starlette_request</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Worker: received starlette request with data&quot;</span><span class="p">,</span> <span class="n">payload</span><span class="p">)</span>

        <span class="n">input_vector</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;sepal length&quot;</span><span class="p">],</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;sepal width&quot;</span><span class="p">],</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;petal length&quot;</span><span class="p">],</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;petal width&quot;</span><span class="p">],</span>
        <span class="p">]</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">input_vector</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">human_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">[</span><span class="n">prediction</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="n">human_name</span><span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code class="docutils literal notranslate"><span class="pre">BoostingModel</span></code> is deployed and instantiated, it will load the classifier model that we trained from your file system so that it can be ready to run inference on the model and serve requests later.</p>
</div>
<p>Now that we’ve defined our Serve deployment, let’s prepare it so that it can be deployed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">boosting_model</span> <span class="o">=</span> <span class="n">BoostingModel</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">,</span> <span class="n">LABEL_PATH</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">BoostingModel.bind(MODEL_PATH,</span> <span class="pre">LABEL_PATH)</span></code> binds the arguments <code class="docutils literal notranslate"><span class="pre">MODEL_PATH</span></code> and <code class="docutils literal notranslate"><span class="pre">LABEL_PATH</span></code> to our deployment and returns a <code class="docutils literal notranslate"><span class="pre">DeploymentNode</span></code> object (wrapping an <code class="docutils literal notranslate"><span class="pre">BoostingModel</span></code> deployment object) that can then be used to connect with other <code class="docutils literal notranslate"><span class="pre">DeploymentNodes</span></code> to form a more complex <a class="reference internal" href="../advanced-guides/deployment-graphs.html#serve-deployment-graphs"><span class="std std-ref">deployment graph</span></a>.</p>
</div>
<p>Finally, we can deploy our model to Ray Serve through the terminal.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>serve run tutorial_sklearn:boosting_model
</pre></div>
</div>
<p>Let’s query it! While Serve is running, open a separate terminal window, and run the following in an interactive Python shell or a separate Python script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>

<span class="n">sample_request_input</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;sepal length&quot;</span><span class="p">:</span> <span class="mf">1.2</span><span class="p">,</span>
    <span class="s2">&quot;sepal width&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s2">&quot;petal length&quot;</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span>
    <span class="s2">&quot;petal width&quot;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;http://localhost:8000/&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">sample_request_input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>You should get an output like the following (the exact prediction may vary):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="s2">&quot;versicolor&quot;</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Examples</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="batch.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Batching Tutorial</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>