
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Incremental Learning with Ray AIR &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/versionwarning.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../_static/js/docsearch.js"></script>
    <script src="../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../_static/js/custom.js"></script>
    <script defer="defer" src="../../_static/js/top-navigation.js"></script>
    <script src="../../_static/js/tags.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/ray-air/examples/torch_incremental_learning.html" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Serving reinforcement learning policy models" href="rl_serving_example.html" />
    <link rel="prev" title="Training a model with distributed LightGBM" href="lightgbm_example.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "ray-air/examples/torch_incremental_learning", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".ipynb", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../getting-started.html">
   Ray AI Runtime (AIR)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../user-guides.html">
     User Guides
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     Examples
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="opt_deepspeed_batch_inference.html">
       Batch Inference with OPT 30B and Ray Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="torch_image_example.html">
       Training a Torch Image Classifier
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="torch_detection.html">
       Fine-tuning a Torch object detection model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="convert_existing_pytorch_code_to_ray_air.html">
       Convert existing PyTorch code to Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="convert_existing_tf_code_to_ray_air.html">
       Convert existing Tensorflow/Keras code to Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tfx_tabular_train_to_serve.html">
       Tabular data training and serving with Keras and Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="huggingface_text_classification.html">
       Fine-tune a 🤗 Transformers model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="sklearn_example.html">
       Training a model with Sklearn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="xgboost_example.html">
       Training a model with distributed XGBoost
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="analyze_tuning_results.html">
       Hyperparameter tuning with XGBoostTrainer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="lightgbm_example.html">
       Training a model with distributed LightGBM
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="torch_incremental_learning.html#">
       Incremental Learning with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rl_serving_example.html">
       Serving reinforcement learning policy models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rl_online_example.html">
       Online reinforcement learning with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rl_offline_example.html">
       Offline reinforcement learning with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="upload_to_comet_ml.html">
       Logging results and uploading models to Comet ML
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="upload_to_wandb.html">
       Logging results and uploading models to Weights &amp; Biases
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="feast_example.html">
       Integrate Ray AIR with Feast feature store
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="automl_with_ray_air.html">
       AutoML for time series forecasting with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="batch_tuning.html">
       Batch training &amp; tuning on Ray Tune
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="batch_forecasting.html">
       Parallel demand forecasting at scale using Ray Tune
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="stablediffusion_batch_prediction.html">
       Stable Diffusion Batch Prediction with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gptj_deepspeed_fine_tuning.html">
       GPT-J-6B Fine-Tuning with Ray AIR and DeepSpeed
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gptj_batch_prediction.html">
       GPT-J-6B Batch Prediction with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gptj_serving.html">
       GPT-J-6B Serving with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="dreambooth_finetuning.html">
       Fine-tuning DreamBooth with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="dolly_lightning_fsdp_finetuning.html">
       Fine-tune
       <code class="docutils literal notranslate">
        <span class="pre">
         dolly-v2-7b
        </span>
       </code>
       with Ray AIR LightningTrainer and FSDP
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/api.html">
     Ray AIR API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../benchmarks.html">
     Benchmarks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Fray-air/examples/torch_incremental_learning.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/ray-air/examples/torch_incremental_learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/ray-air/examples/torch_incremental_learning.ipynb.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#">
   Incremental Learning with Ray AIR
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-1-installations-and-initializing-ray">
   Step 1: Installations and Initializing Ray
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-2-define-our-pytorch-model">
   Step 2: Define our PyTorch Model
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-3-create-the-stream-of-tasks">
   Step 3: Create the Stream of tasks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#a-load-mnist-dataset-to-a-dataset">
     3a: Load MNIST Dataset to a Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#b-create-our-stream-abstraction">
     3b: Create our Stream abstraction
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-4-define-the-logic-for-training-and-inference-prediction">
   Step 4: Define the logic for Training and Inference/Prediction
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#a-define-our-training-logic-for-each-data-parallel-worker">
     4a: Define our training logic for each Data Parallel worker
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#b-define-our-preprocessor">
     4b: Define our Preprocessor
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#c-define-logic-for-batch-offline-prediction">
     4c: Define logic for Batch/Offline Prediction.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#d-define-logic-for-deploying-and-querying-our-model">
     4d: Define logic for Deploying and Querying our model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-5-putting-it-all-together">
   Step 5: Putting it all together
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#optional-step-6-compare-against-full-training">
   [Optional] Step 6: Compare against full training.
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#next-steps">
   Next Steps
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Incremental Learning with Ray AIR</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#">
   Incremental Learning with Ray AIR
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-1-installations-and-initializing-ray">
   Step 1: Installations and Initializing Ray
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-2-define-our-pytorch-model">
   Step 2: Define our PyTorch Model
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-3-create-the-stream-of-tasks">
   Step 3: Create the Stream of tasks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#a-load-mnist-dataset-to-a-dataset">
     3a: Load MNIST Dataset to a Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#b-create-our-stream-abstraction">
     3b: Create our Stream abstraction
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-4-define-the-logic-for-training-and-inference-prediction">
   Step 4: Define the logic for Training and Inference/Prediction
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#a-define-our-training-logic-for-each-data-parallel-worker">
     4a: Define our training logic for each Data Parallel worker
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#b-define-our-preprocessor">
     4b: Define our Preprocessor
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#c-define-logic-for-batch-offline-prediction">
     4c: Define logic for Batch/Offline Prediction.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_incremental_learning.html#d-define-logic-for-deploying-and-querying-our-model">
     4d: Define logic for Deploying and Querying our model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#step-5-putting-it-all-together">
   Step 5: Putting it all together
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#optional-step-6-compare-against-full-training">
   [Optional] Step 6: Compare against full training.
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_incremental_learning.html#next-steps">
   Next Steps
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><em>This example is adapted from Continual AI Avalanche quick start https://avalanche.continualai.org/</em></p>
<section class="tex2jax_ignore mathjax_ignore" id="incremental-learning-with-ray-air">
<h1>Incremental Learning with Ray AIR<a class="headerlink" href="torch_incremental_learning.html#incremental-learning-with-ray-air" title="Permalink to this headline">#</a></h1>
<p>In this example, we show how to use Ray AIR to incrementally train a simple image classification PyTorch model
on a stream of incoming tasks.</p>
<p>Each task is a random permutation of the MNIST Dataset, which is a common benchmark
used for continual training. After training on all the
tasks, the model is expected to be able to make predictions on data from any task.</p>
<p>In this example, we use just a naive finetuning strategy, where the model is trained
on each task, without any special methods to prevent <a class="reference external" href="https://en.wikipedia.org/wiki/Catastrophic_interference">catastrophic forgetting</a>. Model performance is
expected to be poor.</p>
<p>More precisely, this example showcases domain incremental training, in which during
prediction/testing
time, the model is asked to predict on data from tasks trained on so far with the
task ID not provided. This is opposed to task incremental training, where the task ID is
provided during prediction/testing time.</p>
<p>For more information on the 3 different categories for incremental/continual
learning, please see <a class="reference external" href="https://arxiv.org/pdf/1904.07734.pdf">“Three scenarios for continual learning” by van de Ven and Tolias</a></p>
<p>This example will cover the following:</p>
<ol class="simple">
<li><p>Loading a PyTorch Dataset to Ray Data</p></li>
<li><p>Create an <code class="docutils literal notranslate"><span class="pre">Iterator[ray.data.Dataset]</span></code> abstraction to represent a stream of data to train on for incremental training.</p></li>
<li><p>Implement a custom Ray AIR preprocessor to preprocess the dataset.</p></li>
<li><p>Incrementally train a model using data parallel training.</p></li>
<li><p>Use our trained model to perform batch prediction on test data.</p></li>
<li><p>Incrementally deploying our trained model with Ray Serve and performing online prediction queries.</p></li>
</ol>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-1-installations-and-initializing-ray">
<h1>Step 1: Installations and Initializing Ray<a class="headerlink" href="torch_incremental_learning.html#step-1-installations-and-initializing-ray" title="Permalink to this headline">#</a></h1>
<p>To get started, let’s first install the necessary packages: Ray AIR, torch, and torchvision. Uncomment the below lines and run the cell to install the necessary packages.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !pip install -q &quot;ray[air]&quot;</span>
<span class="c1"># !pip install -q torch</span>
<span class="c1"># !pip install -q torchvision</span>
</pre></div>
</div>
</div>
</div>
<p>Then, let’s initialize Ray! We can just import and call <code class="docutils literal notranslate"><span class="pre">ray.init()</span></code>. If you are running on a Ray cluster, then you can do <code class="docutils literal notranslate"><span class="pre">ray.init(&quot;auto&quot;)</span></code> to connect to the cluster instead of initiailzing a new local Ray instance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="c1"># If runnning on a cluster, use the below line instead.</span>
<span class="c1"># ray.init(&quot;auto&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-09-23 16:31:18,554	INFO worker.py:1509 -- Started a local Ray instance. View the dashboard at <span class=" -Color -Color-Bold -Color-Bold-Green">127.0.0.1:8265 </span>
</pre></div>
</div>
<div class="output text_html"><div>
    <div style="margin-left: 50px;display: flex;flex-direction: row;align-items: center">
        <h3 style="color: var(--jp-ui-font-color0)">Ray</h3>
        <svg version="1.1" id="ray" width="3em" viewBox="0 0 144.5 144.6" style="margin-left: 3em;margin-right: 3em">
            <g id="layer-1">
                <path fill="#00a2e9" class="st0" d="M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1
                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2
                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9
                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5
                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5
                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7
                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1
                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9
                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2
                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3
                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3
                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3
                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7
                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3
                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6
                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10
                    C71.6,134.6,71.7,134.6,71.8,134.6z"/>
            </g>
        </svg>
        <table>
            <tr>
                <td style="text-align: left"><b>Python version:</b></td>
                <td style="text-align: left"><b>3.10.6</b></td>
            </tr>
            <tr>
                <td style="text-align: left"><b>Ray version:</b></td>
                <td style="text-align: left"><b> 3.0.0.dev0</b></td>
            </tr>
            <tr>
    <td style="text-align: left"><b>Dashboard:</b></td>
    <td style="text-align: left"><b><a href="http://127.0.0.1:8265" target="_blank">http://127.0.0.1:8265</a></b></td>
</tr>

        </table>
    </div>
</div>
</div></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-2-define-our-pytorch-model">
<h1>Step 2: Define our PyTorch Model<a class="headerlink" href="torch_incremental_learning.html#step-2-define-our-pytorch-model" title="Permalink to this headline">#</a></h1>
<p>Now that we have the necessary installations, let’s define our PyTorch model. For this example to classify MNIST images, we will use a simple multi-layer perceptron.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">SimpleMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleMLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span> <span class="o">=</span> <span class="n">input_size</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/pdmurray/.pyenv/versions/mambaforge/envs/ray/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-3-create-the-stream-of-tasks">
<h1>Step 3: Create the Stream of tasks<a class="headerlink" href="torch_incremental_learning.html#step-3-create-the-stream-of-tasks" title="Permalink to this headline">#</a></h1>
<p>We can now create a stream of tasks (where each task contains a dataset to train on). For this example, we will create an artificial stream of tasks consisting of
permuted variations of MNIST, which is a classic benchmark in continual learning
research.</p>
<p>For real-world scenarios, this step is not necessary as fresh data will already be
arriving as a stream of tasks. It does not need to be artificially created.</p>
<section id="a-load-mnist-dataset-to-a-dataset">
<h2>3a: Load MNIST Dataset to a Dataset<a class="headerlink" href="torch_incremental_learning.html#a-load-mnist-dataset-to-a-dataset" title="Permalink to this headline">#</a></h2>
<p>Let’s first define a simple function that will return the original MNIST Dataset as a distributed Dataset. Ray Data is the standard way to load and exchange data in Ray libraries and applications, read more about the library <a class="reference internal" href="../../data/data.html#data"><span class="std std-ref">here</span></a>!</p>
<p>The function in the below code snippet does the following:</p>
<ol class="simple">
<li><p>Downloads the MNIST Dataset from torchvision in-memory</p></li>
<li><p>Loads the in-memory Torch Dataset into a Dataset</p></li>
<li><p>Converts the Dataset into Numpy format. Instead of the Dataset iterating over tuples, it will have 2 columns: “image” &amp; “label”.
This will allow us to apply built-in preprocessors to the Dataset and allow Datasets to be used with Ray AIR Predictors.</p></li>
</ol>
<p>For this example, since we are just working with MNIST dataset, which is small, we use the <code class="xref py py-class docutils literal notranslate"><span class="pre">from_torch</span></code> which just loads the full MNIST dataset into memory.</p>
<p>For loading larger datasets in a parallel fashion, you should use <a class="reference internal" href="../../data/api/input_output.html#input-output"><span class="std std-ref">Dataset’s additional read APIs</span></a> to load data from parquet, csv, image files, and more!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">RandomCrop</span>

<span class="kn">import</span> <span class="nn">ray</span>


<span class="k">def</span> <span class="nf">get_mnist_dataset</span><span class="p">(</span><span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Returns MNIST Dataset as a ray.data.Dataset.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        train: Whether to return the train dataset or test dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
        <span class="c1"># Only perform random cropping on the Train dataset.</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">RandomCrop</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
    <span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">mnist_dataset</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">convert_batch_to_numpy</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;item&quot;</span><span class="p">]])</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;item&quot;</span><span class="p">]])</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>

    <span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">mnist_dataset</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">convert_batch_to_numpy</span><span class="p">)</span><span class="o">.</span><span class="n">materialize</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mnist_dataset</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="b-create-our-stream-abstraction">
<h2>3b: Create our Stream abstraction<a class="headerlink" href="torch_incremental_learning.html#b-create-our-stream-abstraction" title="Permalink to this headline">#</a></h2>
<p>Now we can create our “stream” abstraction. This abstraction provides two
methods (<code class="docutils literal notranslate"><span class="pre">generate_train_stream</span></code> and <code class="docutils literal notranslate"><span class="pre">generate_test_stream</span></code>) that each returns an Iterator
over Ray Data. Each item in this iterator contains a unique permutation of
MNIST, and is one task that we want to train on.</p>
<p>In this example, “the stream of tasks” is contrived since all the data for all tasks exist already in an offline setting. For true online continual learning, you would want to implement a custom dataset iterator that reads from some stream datasource to produce new tasks. The only abstraction that’s needed is <code class="docutils literal notranslate"><span class="pre">Iterator[ray.data.Dataset]</span></code>.</p>
<p>Note that the test dataset stream has the same permutations that are used for the training dataset stream. In general for continual learning, it is expected that the data distribution of the test/prediction data follows what the model was trained on. If you notice that the distribution of new prediction queries is changing compared to the distribution of the training data, then you should probably trigger training of a new task.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">ray.data</span> <span class="kn">import</span> <span class="n">ActorPoolStrategy</span>


<span class="k">class</span> <span class="nc">PermutedMNISTStream</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Generates streams of permuted MNIST Datasets.</span>
<span class="sd">    </span>
<span class="sd">    Example:</span>
<span class="sd">        </span>
<span class="sd">        permuted_mnist = PermutedMNISTStream(n_tasks=3)</span>
<span class="sd">        train_stream = permuted_mnist.generate_train_stream()</span>
<span class="sd">        </span>
<span class="sd">        # Iterate through the train_stream</span>
<span class="sd">        for train_dataset in train_stream:</span>
<span class="sd">            ...</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        n_tasks: The number of tasks to generate.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_tasks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_tasks</span> <span class="o">=</span> <span class="n">n_tasks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">permutations</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_tasks</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_mnist_dataset</span> <span class="o">=</span> <span class="n">get_mnist_dataset</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_mnist_dataset</span> <span class="o">=</span> <span class="n">get_mnist_dataset</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">random_permute_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">permutation</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Randomly permutes the pixels for each image in the dataset.&quot;&quot;&quot;</span>

        <span class="k">class</span> <span class="nc">PixelsPermutation</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
            <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
                <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">image</span><span class="p">:</span> <span class="n">image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">permutation</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
                <span class="k">return</span> <span class="n">batch</span>

        <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">PixelsPermutation</span><span class="p">,</span> <span class="n">compute</span><span class="o">=</span><span class="n">ActorPoolStrategy</span><span class="p">(),</span> <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate_train_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">permutation</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">permutations</span><span class="p">:</span>
            <span class="n">permuted_mnist_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_permute_dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_mnist_dataset</span><span class="p">,</span> <span class="n">permutation</span>
            <span class="p">)</span>
            <span class="k">yield</span> <span class="n">permuted_mnist_dataset</span>

    <span class="k">def</span> <span class="nf">generate_test_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">permutation</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">permutations</span><span class="p">:</span>
            <span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">get_mnist_dataset</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">permuted_mnist_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_permute_dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test_mnist_dataset</span><span class="p">,</span> <span class="n">permutation</span>
            <span class="p">)</span>
            <span class="k">yield</span> <span class="n">permuted_mnist_dataset</span>

    <span class="k">def</span> <span class="nf">generate_test_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Generates num_samples permuted MNIST images.&quot;&quot;&quot;</span>
        <span class="n">random_permutation</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">permutations</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_permute_dataset</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_mnist_dataset</span><span class="o">.</span><span class="n">random_shuffle</span><span class="p">()</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">num_samples</span><span class="p">),</span>
            <span class="n">random_permutation</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-4-define-the-logic-for-training-and-inference-prediction">
<h1>Step 4: Define the logic for Training and Inference/Prediction<a class="headerlink" href="torch_incremental_learning.html#step-4-define-the-logic-for-training-and-inference-prediction" title="Permalink to this headline">#</a></h1>
<p>Now that we can get an Iterator over Ray Data, we can incrementally train our model in a data parallel fashion via Ray Train, while incrementally deploying our model via Ray Serve. Let’s define some helper functions to allow us to do this!</p>
<p>If you are not familiar with data parallel training, it is a form of distributed training strategies, where we have multiple model replicas, and each replica trains on a different batch of data. After each batch, the gradients are synchronized across the replicas. This effecitively allows us to train on more data in a shorter amount of time.</p>
<section id="a-define-our-training-logic-for-each-data-parallel-worker">
<h2>4a: Define our training logic for each Data Parallel worker<a class="headerlink" href="torch_incremental_learning.html#a-define-our-training-logic-for-each-data-parallel-worker" title="Permalink to this headline">#</a></h2>
<p>The first thing we need to do is to define the training loop that will be run on each training worker.</p>
<p>The training loop takes in a <code class="docutils literal notranslate"><span class="pre">config</span></code> Dict as an argument that we can use to pass in any configurations for training.</p>
<p>This is just standard PyTorch training, with the difference being that we can leverage <a class="reference internal" href="../../train/api/api.html#train-pytorch-integration"><span class="std std-ref">Ray Train’s utility functions</span></a> and <a class="reference internal" href="../api/session.html#air-session-ref"><span class="std std-ref">Ray AIR Sesssion</span></a>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ray.train.torch.prepare_model(...)</span></code>: This will prepare the model for distributed training by wrapping it in either PyTorch <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> or <code class="docutils literal notranslate"><span class="pre">FullyShardedDataParallel</span></code> and moving it to the correct accelerator device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ray.air.session.get_dataset_shard(...)</span></code>: This will get the Dataset shard for this particular Data Parallel worker.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ray.air.session.report({},</span> <span class="pre">checkpoint=...)</span></code>: This will tell Ray Train to persist the provided <code class="docutils literal notranslate"><span class="pre">Checkpoint</span></code> object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ray.air.session.get_checkpoint()</span></code>: Returns a checkpoint to resume from. This is useful for either fault tolerance purposes, or for our purposes, to continue training the same model on a new incoming dataset.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">ray.air</span> <span class="kn">import</span> <span class="n">session</span><span class="p">,</span> <span class="n">Checkpoint</span>

<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span>

<span class="k">def</span> <span class="nf">train_loop_per_worker</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">]</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">SimpleMLP</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="c1"># Load model from checkpoint if there is a checkpoint to load from.</span>
    <span class="n">checkpoint_to_load</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_checkpoint</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">checkpoint_to_load</span><span class="p">:</span>
        <span class="n">state_dict_to_resume_from</span> <span class="o">=</span> <span class="n">checkpoint_to_load</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict_to_resume_from</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># Get the Dataset shard for this data parallel worker, and convert it to a PyTorch Dataset.</span>
    <span class="n">dataset_shard</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset_shard</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">train_mb_x</span><span class="p">,</span> <span class="n">train_mb_y</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
            <span class="n">train_mb_x</span> <span class="o">=</span> <span class="n">train_mb_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">get_device</span><span class="p">())</span>
            <span class="n">train_mb_y</span> <span class="o">=</span> <span class="n">train_mb_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">get_device</span><span class="p">())</span>

            <span class="c1"># Forward</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_mb_x</span><span class="p">)</span>
            <span class="c1"># Loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">train_mb_y</span><span class="p">)</span>
            <span class="c1"># Backward</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="c1"># Update</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">session</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;7f</span><span class="si">}</span><span class="s2">, epoch: </span><span class="si">{</span><span class="n">epoch_idx</span><span class="si">}</span><span class="s2">, iteration: </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Checkpoint model after every epoch.</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">state_dict</span><span class="p">))</span>
        <span class="n">session</span><span class="o">.</span><span class="n">report</span><span class="p">({</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">running_loss</span><span class="p">},</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="b-define-our-preprocessor">
<h2>4b: Define our Preprocessor<a class="headerlink" href="torch_incremental_learning.html#b-define-our-preprocessor" title="Permalink to this headline">#</a></h2>
<p>Next, we define our <code class="docutils literal notranslate"><span class="pre">Preprocessor</span></code> to preprocess our data before training and prediction. Our preprocessor will normalize the MNIST Images by the mean and standard deviation of the MNIST training dataset. This is a common operation to do on MNIST to improve training: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="kn">from</span> <span class="nn">ray.data.preprocessors</span> <span class="kn">import</span> <span class="n">TorchVisionPreprocessor</span>


<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
<span class="p">])</span>
<span class="n">mnist_normalize_preprocessor</span> <span class="o">=</span> <span class="n">TorchVisionPreprocessor</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="c-define-logic-for-batch-offline-prediction">
<h2>4c: Define logic for Batch/Offline Prediction.<a class="headerlink" href="torch_incremental_learning.html#c-define-logic-for-batch-offline-prediction" title="Permalink to this headline">#</a></h2>
<p>After training on each task, we want to use our trained model to do batch (i.e. offline) inference on a test dataset.</p>
<p>To do this, we leverage the built-in <code class="docutils literal notranslate"><span class="pre">ray.air.BatchPredictor</span></code>. We define a <code class="docutils literal notranslate"><span class="pre">batch_predict</span></code> function that will take in a Checkpoint and a Test Dataset and outputs the accuracy our model achieves on the test dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train.batch_predictor</span> <span class="kn">import</span> <span class="n">BatchPredictor</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchPredictor</span>

<span class="k">def</span> <span class="nf">batch_predict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">air</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
  <span class="sd">&quot;&quot;&quot;Perform batch prediction on the provided test dataset, and return accuracy results.&quot;&quot;&quot;</span>

  <span class="n">batch_predictor</span> <span class="o">=</span> <span class="n">BatchPredictor</span><span class="o">.</span><span class="n">from_checkpoint</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">predictor_cls</span><span class="o">=</span><span class="n">TorchPredictor</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">SimpleMLP</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
  <span class="n">model_output</span> <span class="o">=</span> <span class="n">batch_predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">feature_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span> <span class="n">keep_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
        <span class="p">)</span>
  
  <span class="c1"># Postprocess model outputs.</span>
  <span class="c1"># Convert logits outputted from model into actual class predictions.</span>
  <span class="k">def</span> <span class="nf">convert_logits_to_classes</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
     <span class="n">best_class</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;predictions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>
     <span class="n">df</span><span class="p">[</span><span class="s2">&quot;predictions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_class</span>
     <span class="k">return</span> <span class="n">df</span>
    
  <span class="n">prediction_results</span> <span class="o">=</span> <span class="n">model_output</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">convert_logits_to_classes</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>
  
  <span class="c1"># Then, for each prediction output, see if it matches with the ground truth</span>
  <span class="c1"># label.</span>
  <span class="k">def</span> <span class="nf">calculate_prediction_scores</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;correct&quot;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;predictions&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]})</span>

  <span class="n">correct_dataset</span> <span class="o">=</span> <span class="n">prediction_results</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
      <span class="n">calculate_prediction_scores</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span>
  <span class="p">)</span>

  <span class="k">return</span> <span class="n">correct_dataset</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">on</span><span class="o">=</span><span class="s2">&quot;correct&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="n">correct_dataset</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="d-define-logic-for-deploying-and-querying-our-model">
<h2>4d: Define logic for Deploying and Querying our model<a class="headerlink" href="torch_incremental_learning.html#d-define-logic-for-deploying-and-querying-our-model" title="Permalink to this headline">#</a></h2>
<p>In addition to batch inference, we also want to deploy our model so that we can submit live queries to it for online inference. We use Ray Serve’s <code class="docutils literal notranslate"><span class="pre">PredictorDeployment</span></code> utility to deploy our trained model.</p>
<p>Once we deploy the model, we can send HTTP requests to our deployment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">requests</span> <span class="kn">import</span> <span class="n">Response</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">ray.serve.http_adapters</span> <span class="kn">import</span> <span class="n">json_to_ndarray</span>


<span class="k">def</span> <span class="nf">deploy_model</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">air</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Deploys the model from the provided Checkpoint and returns the URL for the endpoint of the model deployment.&quot;&quot;&quot;</span>
    <span class="n">serve</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">PredictorDeployment</span><span class="o">.</span><span class="n">options</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mnist_model&quot;</span><span class="p">,</span>
            <span class="n">route_prefix</span><span class="o">=</span><span class="s2">&quot;/mnist_predict&quot;</span><span class="p">,</span>
            <span class="n">num_replicas</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span>
            <span class="n">http_adapter</span><span class="o">=</span><span class="n">json_to_ndarray</span><span class="p">,</span>
            <span class="n">predictor_cls</span><span class="o">=</span><span class="n">TorchPredictor</span><span class="p">,</span>
            <span class="n">checkpoint</span><span class="o">=</span><span class="n">latest_checkpoint</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="n">SimpleMLP</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="s2">&quot;http://localhost:8000/mnist_predict&quot;</span>

<span class="c1"># Function that queries our deployed model</span>
<span class="k">def</span> <span class="nf">query_deployment</span><span class="p">(</span><span class="n">test_samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">endpoint_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Response</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Given a set of test samples, queries the model deployment at the provided endpoint and returns the results.&quot;&quot;&quot;</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Convert to Python List since Numpy arrays are not Json serializable.</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">test_samples</span><span class="p">:</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">endpoint_uri</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;array&quot;</span><span class="p">:</span> <span class="n">sample</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="s2">&quot;float32&quot;</span><span class="p">}))</span>
    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="step-5-putting-it-all-together">
<h1>Step 5: Putting it all together<a class="headerlink" href="torch_incremental_learning.html#step-5-putting-it-all-together" title="Permalink to this headline">#</a></h1>
<p>Once we have defined our training logic and our preprocessor, we can put everything together!</p>
<p>For each dataset in our stream, we do the following:</p>
<ol class="simple">
<li><p>Train on the dataset in Data Parallel fashion. We create a <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code>, specify the config for the training loop we defined above, the dataset to train on, and how much we want to scale. <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> also accepts a <code class="docutils literal notranslate"><span class="pre">checkpoint</span></code> arg to continue training from a previously saved checkpoint.</p></li>
<li><p>Get the saved checkpoint from the training run.</p></li>
<li><p>Test our trained model on a test set containing test data from all the tasks trained on so far.</p></li>
<li><p>After training on each task, we deploy our model so we can query it for predictions.</p></li>
</ol>
<p>In this example, the training and test data for each task is well-defined beforehand by the benchmark. For real-world scenarios, this probably will not be the case. It is very likely that the prediction requests after training on one task will become the training data for the next task.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="kn">from</span> <span class="nn">ray.air.config</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchPredictor</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">serve</span>
<span class="kn">from</span> <span class="nn">ray.serve</span> <span class="kn">import</span> <span class="n">PredictorDeployment</span>
<span class="kn">from</span> <span class="nn">ray.serve.http_adapters</span> <span class="kn">import</span> <span class="n">json_to_ndarray</span>

<span class="c1"># The number of tasks (i.e. datasets in our stream) that we want to use for this example.</span>
<span class="n">n_tasks</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># Number of epochs to train each task for.</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># Batch size.</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1"># Optimizer args.</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>

<span class="c1"># Number of data parallel workers to use for training.</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Whether to use GPU or not.</span>
<span class="n">use_gpu</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">available_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;GPU&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

<span class="n">permuted_mnist</span> <span class="o">=</span> <span class="n">PermutedMNISTStream</span><span class="p">(</span><span class="n">n_tasks</span><span class="o">=</span><span class="n">n_tasks</span><span class="p">)</span>
<span class="n">train_stream</span> <span class="o">=</span> <span class="n">permuted_mnist</span><span class="o">.</span><span class="n">generate_train_stream</span><span class="p">()</span>
<span class="n">test_stream</span> <span class="o">=</span> <span class="n">permuted_mnist</span><span class="o">.</span><span class="n">generate_test_stream</span><span class="p">()</span>

<span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">accuracy_for_all_tasks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">task_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">all_test_datasets_seen_so_far</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">train_stream</span><span class="p">,</span> <span class="n">test_stream</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting training for task: </span><span class="si">{</span><span class="n">task_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">task_idx</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="c1"># *********Training*****************</span>

  <span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
          <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_loop_per_worker</span><span class="p">,</span>
          <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span>
              <span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
              <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
              <span class="s2">&quot;momentum&quot;</span><span class="p">:</span> <span class="n">momentum</span><span class="p">,</span>
              <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
          <span class="p">},</span>
          <span class="c1"># Have to specify trainer_resources as 0 so that the example works on Colab. </span>
          <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">,</span> <span class="n">trainer_resources</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;CPU&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
          <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">},</span>
          <span class="n">preprocessor</span><span class="o">=</span><span class="n">mnist_normalize_preprocessor</span><span class="p">,</span>
          <span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="n">latest_checkpoint</span><span class="p">,</span>
      <span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
  <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span>

  <span class="c1"># **************Batch Prediction**************************</span>

  <span class="c1"># We can do batch prediction on the test data for the tasks seen so far.</span>
  <span class="c1"># TODO: Fix type signature in Ray Data</span>
  <span class="c1"># TODO: Fix dataset.union when used with empty list.</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_test_datasets_seen_so_far</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">full_test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_test_datasets_seen_so_far</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">full_test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span>

  <span class="n">all_test_datasets_seen_so_far</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>

  <span class="n">accuracy_for_this_task</span> <span class="o">=</span> <span class="n">batch_predict</span><span class="p">(</span><span class="n">latest_checkpoint</span><span class="p">,</span> <span class="n">full_test_dataset</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for task </span><span class="si">{</span><span class="n">task_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">accuracy_for_this_task</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">accuracy_for_all_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_for_this_task</span><span class="p">)</span>

  <span class="c1"># *************Model Deployment &amp; Online Inference***************************</span>
  
  <span class="c1"># We can also deploy our model to do online inference with Ray Serve.</span>
  <span class="c1"># Start Ray Serve.</span>
  <span class="n">test_samples</span> <span class="o">=</span> <span class="n">permuted_mnist</span><span class="o">.</span><span class="n">generate_test_samples</span><span class="p">()</span>
  <span class="n">endpoint_uri</span> <span class="o">=</span> <span class="n">deploy_model</span><span class="p">(</span><span class="n">latest_checkpoint</span><span class="p">)</span>
  <span class="n">online_inference_results</span> <span class="o">=</span> <span class="n">query_deployment</span><span class="p">(</span><span class="n">test_samples</span><span class="p">,</span> <span class="n">endpoint_uri</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">available_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_workers</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span>
    <span class="c1"># If there are no more CPUs left, then shutdown the Serve replicas so we can continue training on the next task.</span>
    <span class="n">serve</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>

  
<span class="n">serve</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Read-&gt;Map_Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03&lt;00:00,  3.42s/it]
Read-&gt;Map_Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  5.27it/s]
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.40it/s]
Read-&gt;Map_Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  4.17it/s]
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.78it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting training for task: 0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output text_html"><div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2022-09-23 16:31:51</td></tr>
<tr><td>Running for: </td><td>00:00:20.79        </td></tr>
<tr><td>Memory:      </td><td>17.1/62.7 GiB      </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/32.53 GiB heap, 0.0/16.26 GiB objects
    </div>

  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name              </th><th>status    </th><th>loc                  </th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th><th style="text-align: right;">  loss</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _time_this_iter_s</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_da157_00000</td><td>TERMINATED</td><td>10.109.175.190:856770</td><td style="text-align: right;">     4</td><td style="text-align: right;">         17.0121</td><td style="text-align: right;">     0</td><td style="text-align: right;">  1663975908</td><td style="text-align: right;">          0.0839479</td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=856836)</span> 2022-09-23 16:31:37,847	INFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=856836)</span> 2022-09-23 16:31:38,047	INFO train_loop_utils.py:354 -- Moving model to device: cuda:0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=856836)</span> loss: 2.436360, epoch: 0, iteration: 0
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=856836)</span> loss: 1.608793, epoch: 0, iteration: 500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=856836)</span> loss: 1.285775, epoch: 0, iteration: 1000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=856836)</span> loss: 0.785092, epoch: 0, iteration: 1500
</pre></div>
</div>
<div class="output text_html"><div class="trialProgress">
  <h3>Trial Progress</h3>
  <table>
<thead>
<tr><th>Trial name              </th><th style="text-align: right;">  _time_this_iter_s</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style="text-align: right;">  experiment_tag</th><th>hostname  </th><th style="text-align: right;">  iterations_since_restore</th><th style="text-align: right;">  loss</th><th>node_ip       </th><th style="text-align: right;">   pid</th><th>should_checkpoint  </th><th style="text-align: right;">  time_since_restore</th><th style="text-align: right;">  time_this_iter_s</th><th style="text-align: right;">  time_total_s</th><th style="text-align: right;">  timestamp</th><th style="text-align: right;">  timesteps_since_restore</th><th>timesteps_total  </th><th style="text-align: right;">  training_iteration</th><th>trial_id   </th><th style="text-align: right;">  warmup_time</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_da157_00000</td><td style="text-align: right;">          0.0839479</td><td style="text-align: right;">  1663975908</td><td style="text-align: right;">                    4</td><td>2022-09-23_16-31-49</td><td>True  </td><td>                </td><td>96c794a64d6f43d79b87130a76d21f1f</td><td style="text-align: right;">               0</td><td>corvus    </td><td style="text-align: right;">                         4</td><td style="text-align: right;">     0</td><td>10.109.175.190</td><td style="text-align: right;">856770</td><td>True               </td><td style="text-align: right;">             17.0121</td><td style="text-align: right;">           0.11111</td><td style="text-align: right;">       17.0121</td><td style="text-align: right;"> 1663975909</td><td style="text-align: right;">                        0</td><td>                 </td><td style="text-align: right;">                   4</td><td>da157_00000</td><td style="text-align: right;">   0.00297165</td></tr>
</tbody>
</table>
</div>
<style>
.trialProgress {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
}
.trialProgress h3 {
  font-weight: bold;
}
.trialProgress td {
  white-space: nowrap;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-09-23 16:31:51,231	INFO tune.py:762 -- Total run time: 20.91 seconds (20.79 seconds for the tuning loop).
Map_Batches:   0%|                                                                                                                                                                                                                                                                                                                                                                                              | 0/1 [00:00&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=857028)</span> 2022-09-23 16:31:52,652	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02&lt;00:00,  2.17s/it]
Map_Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 40.09it/s]
Map_Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 116.17it/s]
Shuffle Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 141.72it/s]
Shuffle Reduce: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 220.51it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for task 1: 0.8678
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shuffle Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 58.32it/s]
Shuffle Reduce: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 79.30it/s]
Map Progress (1 actors 1 pending):   0%|                                                                                                                                                                                                                                                                                                                                                                        | 0/1 [00:00&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=857062)</span> 2022-09-23 16:31:54,055	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.77it/s]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:31:54,643 controller 857134 http_state.py:129 - Starting HTTP proxy with name &#39;SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-610d4158d56aeda61abd25d5751611d23ba1aa97eddb34d2ee4e6020&#39; on node &#39;610d4158d56aeda61abd25d5751611d23ba1aa97eddb34d2ee4e6020&#39; listening on &#39;127.0.0.1:8000&#39;
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO:     Started server process [857184]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:31:55,258 controller 857134 deployment_state.py:1277 - Adding 2 replicas to deployment &#39;mnist_model&#39;.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> 2022-09-23 16:31:56,857	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> 2022-09-23 16:31:56,871	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:31:57,276 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:31:57,275 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:02,313 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 5035.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:02,360 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:02,359 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:02,312 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 5031.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:07,340 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4978.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:07,339 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4975.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:07,391 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:07,390 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:12,367 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4974.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:12,364 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4970.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:12,414 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.4ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:12,413 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:17,394 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4977.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:17,444 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 4.6ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:17,443 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:17,392 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4973.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:22,419 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4972.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:22,471 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 4.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:22,470 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.4ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:22,417 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4969.1ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:27,440 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4966.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:27,439 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4963.6ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:27,490 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:27,489 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:32,469 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4977.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:32,520 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:32,519 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:32,467 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4974.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:37,496 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4974.4ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:37,495 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4971.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:37,544 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:37,543 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:42,522 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4975.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:42,570 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:42,520 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 4972.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857234)</span> INFO 2022-09-23 16:32:42,569 mnist_model mnist_model#PEPxlw replica.py:505 - HANDLE __call__ OK 0.2ms
Map_Batches:   0%|                                                                                                                                                                                                                                                                                                                                                                                              | 0/1 [00:00&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:32:47,614 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 5042.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=857227)</span> INFO 2022-09-23 16:32:47,612 mnist_model mnist_model#QckEDj replica.py:505 - HANDLE __call__ OK 5039.0ms
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.34it/s]
Read-&gt;Map_Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  4.26it/s]
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.72it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting training for task: 1
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output text_html"><div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2022-09-23 16:33:08</td></tr>
<tr><td>Running for: </td><td>00:00:19.49        </td></tr>
<tr><td>Memory:      </td><td>18.2/62.7 GiB      </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/32.53 GiB heap, 0.0/16.26 GiB objects
    </div>

  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name              </th><th>status    </th><th>loc                  </th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th><th style="text-align: right;">  loss</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _time_this_iter_s</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_09424_00000</td><td>TERMINATED</td><td>10.109.175.190:857781</td><td style="text-align: right;">     4</td><td style="text-align: right;">         15.3611</td><td style="text-align: right;">     0</td><td style="text-align: right;">  1663975986</td><td style="text-align: right;">          0.0699804</td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=857818)</span> 2022-09-23 16:32:55,672	INFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=857818)</span> 2022-09-23 16:32:55,954	INFO train_loop_utils.py:354 -- Moving model to device: cuda:0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=857818)</span> loss: 2.457292, epoch: 0, iteration: 0
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=857818)</span> loss: 1.339169, epoch: 0, iteration: 500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=857818)</span> loss: 1.032746, epoch: 0, iteration: 1000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=857818)</span> loss: 0.707931, epoch: 0, iteration: 1500
</pre></div>
</div>
<div class="output text_html"><div class="trialProgress">
  <h3>Trial Progress</h3>
  <table>
<thead>
<tr><th>Trial name              </th><th style="text-align: right;">  _time_this_iter_s</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style="text-align: right;">  experiment_tag</th><th>hostname  </th><th style="text-align: right;">  iterations_since_restore</th><th style="text-align: right;">  loss</th><th>node_ip       </th><th style="text-align: right;">   pid</th><th>should_checkpoint  </th><th style="text-align: right;">  time_since_restore</th><th style="text-align: right;">  time_this_iter_s</th><th style="text-align: right;">  time_total_s</th><th style="text-align: right;">  timestamp</th><th style="text-align: right;">  timesteps_since_restore</th><th>timesteps_total  </th><th style="text-align: right;">  training_iteration</th><th style="text-align: right;">   trial_id</th><th style="text-align: right;">  warmup_time</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_09424_00000</td><td style="text-align: right;">          0.0699804</td><td style="text-align: right;">  1663975986</td><td style="text-align: right;">                    4</td><td>2022-09-23_16-33-06</td><td>True  </td><td>                </td><td>77c9c5f109fa4a47b459b0afadf3ba33</td><td style="text-align: right;">               0</td><td>corvus    </td><td style="text-align: right;">                         4</td><td style="text-align: right;">     0</td><td>10.109.175.190</td><td style="text-align: right;">857781</td><td>True               </td><td style="text-align: right;">             15.3611</td><td style="text-align: right;">         0.0725608</td><td style="text-align: right;">       15.3611</td><td style="text-align: right;"> 1663975986</td><td style="text-align: right;">                        0</td><td>                 </td><td style="text-align: right;">                   4</td><td style="text-align: right;">09424_00000</td><td style="text-align: right;">   0.00418878</td></tr>
</tbody>
</table>
</div>
<style>
.trialProgress {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
}
.trialProgress h3 {
  font-weight: bold;
}
.trialProgress td {
  white-space: nowrap;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-09-23 16:33:09,072	INFO tune.py:762 -- Total run time: 19.62 seconds (19.49 seconds for the tuning loop).
Map Progress (1 actors 1 pending):   0%|                                                                                                                                                                                                                                                                                                                                                                        | 0/2 [00:01&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=857874)</span> 2022-09-23 16:33:10,528	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (2 actors 1 pending):  50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                | 1/2 [00:02&lt;00:02,  2.23s/it]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=857902)</span> 2022-09-23 16:33:11,882	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (2 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03&lt;00:00,  1.53s/it]
Map_Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00&lt;00:00,  7.46it/s]
Map_Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 125.99it/s]
Shuffle Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 269.85it/s]
Shuffle Reduce: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 261.75it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for task 2: 0.86465
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shuffle Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 97.22it/s]
Shuffle Reduce: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 96.18it/s]
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.83it/s]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:33:13,164 controller 857134 deployment_state.py:1234 - Stopping 1 replicas of deployment &#39;mnist_model&#39; with outdated versions.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=857930)</span> 2022-09-23 16:33:13,290	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:33:15,301 controller 857134 deployment_state.py:1277 - Adding 1 replica to deployment &#39;mnist_model&#39;.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> 2022-09-23 16:33:16,792	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:33:16,946 controller 857134 deployment_state.py:1234 - Stopping 1 replicas of deployment &#39;mnist_model&#39; with outdated versions.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:33:19,087 controller 857134 deployment_state.py:1277 - Adding 1 replica to deployment &#39;mnist_model&#39;.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> 2022-09-23 16:33:20,575	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:21,138 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 4.4ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:21,137 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:26,162 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 5021.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:26,210 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:26,209 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:33:26,160 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 5017.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:31,190 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4979.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:31,237 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:31,236 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:33:31,189 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4975.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:36,219 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4980.6ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:33:36,218 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4977.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:36,266 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.6ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:36,265 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:41,246 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4979.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:33:41,245 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4977.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:41,293 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.1ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:41,292 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:46,274 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4979.4ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:46,320 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.1ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:46,319 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:33:46,272 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4976.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:51,292 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4970.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:51,340 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:51,339 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:33:51,290 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4966.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:56,315 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4973.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:33:56,364 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:33:56,363 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:33:56,314 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4969.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:01,344 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4978.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:34:01,342 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4975.1ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:01,390 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:34:01,389 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:06,367 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4975.1ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:34:06,366 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4972.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:06,413 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858036)</span> INFO 2022-09-23 16:34:06,412 mnist_model mnist_model#JcKoby replica.py:505 - HANDLE __call__ OK 0.3ms
Map_Batches:   0%|                                                                                                                                                                                                                                                                                                                                                                                              | 0/1 [00:00&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:11,392 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4977.5ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858081)</span> INFO 2022-09-23 16:34:11,391 mnist_model mnist_model#BpvmYM replica.py:505 - HANDLE __call__ OK 4975.0ms
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.37it/s]
Read-&gt;Map_Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  5.31it/s]
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.76it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting training for task: 2
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output text_html"><div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2022-09-23 16:34:33</td></tr>
<tr><td>Running for: </td><td>00:00:19.45        </td></tr>
<tr><td>Memory:      </td><td>18.4/62.7 GiB      </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/32.53 GiB heap, 0.0/16.26 GiB objects
    </div>

  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name              </th><th>status    </th><th>loc                  </th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th><th style="text-align: right;">  loss</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _time_this_iter_s</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_3b7e3_00000</td><td>TERMINATED</td><td>10.109.175.190:858536</td><td style="text-align: right;">     4</td><td style="text-align: right;">         15.3994</td><td style="text-align: right;">     0</td><td style="text-align: right;">  1663976070</td><td style="text-align: right;">          0.0710998</td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=858579)</span> 2022-09-23 16:34:19,902	INFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=858579)</span> 2022-09-23 16:34:20,191	INFO train_loop_utils.py:354 -- Moving model to device: cuda:0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=858579)</span> loss: 2.515887, epoch: 0, iteration: 0
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=858579)</span> loss: 1.260738, epoch: 0, iteration: 500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=858579)</span> loss: 0.892560, epoch: 0, iteration: 1000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=858579)</span> loss: 0.497198, epoch: 0, iteration: 1500
</pre></div>
</div>
<div class="output text_html"><div class="trialProgress">
  <h3>Trial Progress</h3>
  <table>
<thead>
<tr><th>Trial name              </th><th style="text-align: right;">  _time_this_iter_s</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style="text-align: right;">  experiment_tag</th><th>hostname  </th><th style="text-align: right;">  iterations_since_restore</th><th style="text-align: right;">  loss</th><th>node_ip       </th><th style="text-align: right;">   pid</th><th>should_checkpoint  </th><th style="text-align: right;">  time_since_restore</th><th style="text-align: right;">  time_this_iter_s</th><th style="text-align: right;">  time_total_s</th><th style="text-align: right;">  timestamp</th><th style="text-align: right;">  timesteps_since_restore</th><th>timesteps_total  </th><th style="text-align: right;">  training_iteration</th><th>trial_id   </th><th style="text-align: right;">  warmup_time</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_3b7e3_00000</td><td style="text-align: right;">          0.0710998</td><td style="text-align: right;">  1663976070</td><td style="text-align: right;">                    4</td><td>2022-09-23_16-34-30</td><td>True  </td><td>                </td><td>c9312be01e964b958b931d1796623509</td><td style="text-align: right;">               0</td><td>corvus    </td><td style="text-align: right;">                         4</td><td style="text-align: right;">     0</td><td>10.109.175.190</td><td style="text-align: right;">858536</td><td>True               </td><td style="text-align: right;">             15.3994</td><td style="text-align: right;">         0.0705044</td><td style="text-align: right;">       15.3994</td><td style="text-align: right;"> 1663976070</td><td style="text-align: right;">                        0</td><td>                 </td><td style="text-align: right;">                   4</td><td>3b7e3_00000</td><td style="text-align: right;">   0.00414133</td></tr>
</tbody>
</table>
</div>
<style>
.trialProgress {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
}
.trialProgress h3 {
  font-weight: bold;
}
.trialProgress td {
  white-space: nowrap;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-09-23 16:34:33,315	INFO tune.py:762 -- Total run time: 19.59 seconds (19.45 seconds for the tuning loop).
Map Progress (1 actors 1 pending):   0%|                                                                                                                                                                                                                                                                                                                                                                        | 0/3 [00:01&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=858662)</span> 2022-09-23 16:34:34,737	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (2 actors 1 pending):  33%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                          | 1/3 [00:02&lt;00:04,  2.18s/it]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=858688)</span> 2022-09-23 16:34:36,116	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (2 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03&lt;00:00,  1.25s/it]
Map_Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 10.84it/s]
Map_Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 165.80it/s]
Shuffle Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 350.61it/s]
Shuffle Reduce: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 186.97it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for task 3: 0.8439
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shuffle Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 114.31it/s]
Shuffle Reduce: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 102.29it/s]
Map_Batches:   0%|                                                                                                                                                                                                                                                                                                                                                                                              | 0/1 [00:00&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=858715)</span> 2022-09-23 16:34:37,520	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.83it/s]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:34:38,052 controller 857134 deployment_state.py:1234 - Stopping 1 replicas of deployment &#39;mnist_model&#39; with outdated versions.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:34:40,199 controller 857134 deployment_state.py:1277 - Adding 1 replica to deployment &#39;mnist_model&#39;.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> 2022-09-23 16:34:41,756	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:34:41,943 controller 857134 deployment_state.py:1234 - Stopping 1 replicas of deployment &#39;mnist_model&#39; with outdated versions.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:34:44,087 controller 857134 deployment_state.py:1277 - Adding 1 replica to deployment &#39;mnist_model&#39;.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> 2022-09-23 16:34:45,635	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:46,091 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.5ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:34:46,091 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:51,133 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 5039.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:51,181 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:34:51,180 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:34:51,131 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 5035.4ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:56,160 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4977.5ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:34:56,207 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:34:56,206 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:34:56,158 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4974.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:01,188 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4979.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:01,186 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4976.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:01,237 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:35:01,236 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:06,210 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4970.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:06,208 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4967.5ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:06,257 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:35:06,256 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:11,236 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4978.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:11,291 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 10.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:35:11,283 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.5ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:11,235 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4974.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:16,259 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4966.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:16,307 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:35:16,306 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:16,258 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4962.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:21,284 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4975.8ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:21,330 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:35:21,329 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:21,283 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4972.7ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:26,312 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4980.6ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:26,311 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4977.5ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:26,363 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 2.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:35:26,362 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:31,337 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4971.5ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:31,383 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 307 3.0ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858821)</span> INFO 2022-09-23 16:35:31,382 mnist_model mnist_model#moUXYX replica.py:505 - HANDLE __call__ OK 0.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:31,335 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4968.3ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(HTTPProxyActor pid=857184)</span> INFO 2022-09-23 16:35:36,366 http_proxy 10.109.175.190 http_proxy.py:315 - POST /mnist_predict 200 4981.2ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeReplica:mnist_model pid=858865)</span> INFO 2022-09-23 16:35:36,364 mnist_model mnist_model#UYagxG replica.py:505 - HANDLE __call__ OK 4977.9ms
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(ServeController pid=857134)</span> INFO 2022-09-23 16:35:36,511 controller 857134 deployment_state.py:1303 - Removing 2 replicas from deployment &#39;mnist_model&#39;.
</pre></div>
</div>
</div>
</div>
<p>Now that we have finished all of our training, let’s see the accuracy of our model after training on each task.</p>
<p>We should see the accuracy decrease over time. This is to be expected since we are using just a naive fine-tuning strategy so our model is prone to catastrophic forgetting.</p>
<p>As we increase the number of tasks, the model performance on all the tasks trained on so far should decrease.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_for_all_tasks</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.8678, 0.86465, 0.8439]
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="optional-step-6-compare-against-full-training">
<h1>[Optional] Step 6: Compare against full training.<a class="headerlink" href="torch_incremental_learning.html#optional-step-6-compare-against-full-training" title="Permalink to this headline">#</a></h1>
<p>We have now incrementally trained our simple multi-layer perceptron. Let’s compare the incrementally trained model via fine tuning against a model that is trained on all the tasks up front.</p>
<p>Since we are using a naive fine-tuning strategy, we should expect that our incrementally trained model will perform worse than the one that is fully trained! However, there’s various other strategies that have been developed and are actively being researched to improve accuracy for incremental training. And overall, incremental/continual learning allows you to train in many real world settings where the entire dataset is not available up front, but new data is arriving at a relatively high rate.</p>
<p>Let’s first combine all of our datasets for each task into a single, unified dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_stream</span> <span class="o">=</span> <span class="n">permuted_mnist</span><span class="o">.</span><span class="n">generate_train_stream</span><span class="p">()</span>

<span class="c1"># Collect all datasets in the stream into a single dataset.</span>
<span class="n">all_training_datasets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_dataset</span> <span class="ow">in</span> <span class="n">train_stream</span><span class="p">:</span>
  <span class="n">all_training_datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">combined_training_dataset</span> <span class="o">=</span> <span class="n">all_training_datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_training_datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>


<span class="n">combined_training_dataset</span> <span class="o">=</span> <span class="n">combined_training_dataset</span><span class="o">.</span><span class="n">random_shuffle</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.37it/s]
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.37it/s]
Map Progress (1 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.40it/s]
Shuffle Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 40.34it/s]
Shuffle Reduce: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 28.99it/s]
</pre></div>
</div>
</div>
</div>
<p>Then, we train a new model on the unified dataset using the same configurations as before.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now we do training with the same configurations as before</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
            <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_loop_per_worker</span><span class="p">,</span>
            <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
                <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                <span class="s2">&quot;momentum&quot;</span><span class="p">:</span> <span class="n">momentum</span><span class="p">,</span>
                <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="c1"># Have to specify trainer_resources as 0 so that the example works on Colab. </span>
            <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">,</span> <span class="n">trainer_resources</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;CPU&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
            <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">combined_training_dataset</span><span class="p">},</span>
            <span class="n">preprocessor</span><span class="o">=</span><span class="n">mnist_normalize_preprocessor</span><span class="p">,</span>
        <span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">full_training_checkpoint</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2022-09-23 16:37:13</td></tr>
<tr><td>Running for: </td><td>00:00:25.97        </td></tr>
<tr><td>Memory:      </td><td>19.4/62.7 GiB      </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/32.53 GiB heap, 0.0/16.26 GiB objects
    </div>

  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name              </th><th>status    </th><th>loc                  </th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th><th style="text-align: right;">  loss</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _time_this_iter_s</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_971af_00000</td><td>TERMINATED</td><td>10.109.175.190:860035</td><td style="text-align: right;">     4</td><td style="text-align: right;">         22.1282</td><td style="text-align: right;">     0</td><td style="text-align: right;">  1663976231</td><td style="text-align: right;">          0.0924587</td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> 2022-09-23 16:36:55,188	INFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> 2022-09-23 16:36:55,399	INFO train_loop_utils.py:354 -- Moving model to device: cuda:0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 2.301066, epoch: 0, iteration: 0
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 1.869080, epoch: 0, iteration: 500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 1.489264, epoch: 0, iteration: 1000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 1.646756, epoch: 0, iteration: 1500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 1.582330, epoch: 0, iteration: 2000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 1.246018, epoch: 0, iteration: 2500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 1.035204, epoch: 0, iteration: 3000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 0.872962, epoch: 0, iteration: 3500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 1.138829, epoch: 0, iteration: 4000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 0.753354, epoch: 0, iteration: 4500
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 0.991935, epoch: 0, iteration: 5000
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=860154)</span> loss: 0.928292, epoch: 0, iteration: 5500
</pre></div>
</div>
<div class="output text_html"><div class="trialProgress">
  <h3>Trial Progress</h3>
  <table>
<thead>
<tr><th>Trial name              </th><th style="text-align: right;">  _time_this_iter_s</th><th style="text-align: right;">  _timestamp</th><th style="text-align: right;">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style="text-align: right;">  experiment_tag</th><th>hostname  </th><th style="text-align: right;">  iterations_since_restore</th><th style="text-align: right;">  loss</th><th>node_ip       </th><th style="text-align: right;">   pid</th><th>should_checkpoint  </th><th style="text-align: right;">  time_since_restore</th><th style="text-align: right;">  time_this_iter_s</th><th style="text-align: right;">  time_total_s</th><th style="text-align: right;">  timestamp</th><th style="text-align: right;">  timesteps_since_restore</th><th>timesteps_total  </th><th style="text-align: right;">  training_iteration</th><th>trial_id   </th><th style="text-align: right;">  warmup_time</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_971af_00000</td><td style="text-align: right;">          0.0924587</td><td style="text-align: right;">  1663976231</td><td style="text-align: right;">                    4</td><td>2022-09-23_16-37-11</td><td>True  </td><td>                </td><td>26d685b2612a4752b7d062d1ebfb89f0</td><td style="text-align: right;">               0</td><td>corvus    </td><td style="text-align: right;">                         4</td><td style="text-align: right;">     0</td><td>10.109.175.190</td><td style="text-align: right;">860035</td><td>True               </td><td style="text-align: right;">             22.1282</td><td style="text-align: right;">         0.0941384</td><td style="text-align: right;">       22.1282</td><td style="text-align: right;"> 1663976231</td><td style="text-align: right;">                        0</td><td>                 </td><td style="text-align: right;">                   4</td><td>971af_00000</td><td style="text-align: right;">    0.0034101</td></tr>
</tbody>
</table>
</div>
<style>
.trialProgress {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
}
.trialProgress h3 {
  font-weight: bold;
}
.trialProgress td {
  white-space: nowrap;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-09-23 16:37:13,525	INFO tune.py:762 -- Total run time: 26.08 seconds (25.96 seconds for the tuning loop).
</pre></div>
</div>
</div>
</div>
<p>Then, let’s test model that was trained on all the tasks up front.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Then, we used the fully trained model and do batch prediction on the entire test set.</span>

<span class="c1"># `full_test_dataset` should already contain the combined test datasets.</span>
<span class="n">fully_trained_accuracy</span> <span class="o">=</span> <span class="n">batch_predict</span><span class="p">(</span><span class="n">full_training_checkpoint</span><span class="p">,</span> <span class="n">full_test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Map Progress (1 actors 1 pending):   0%|                                                                                                                                                                                                                                                                                                                                                                        | 0/3 [00:01&lt;?, ?it/s]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=860261)</span> 2022-09-23 16:37:15,152	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (2 actors 1 pending):  33%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                          | 1/3 [00:03&lt;00:04,  2.45s/it]<span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=860289)</span> 2022-09-23 16:37:16,696	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
Map Progress (2 actors 1 pending): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04&lt;00:00,  1.37s/it]
Map_Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 74.29it/s]
Map_Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 134.64it/s]
Shuffle Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 304.26it/s]
Shuffle Reduce: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 108.41it/s]
</pre></div>
</div>
</div>
</div>
<p>Finally, let’s compare the accuracies between the incrementally trained model and the fully trained model. We should see that the fully trained model performs better.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fully trained model accuracy: &quot;</span><span class="p">,</span> <span class="n">fully_trained_accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Incrementally trained model accuracy: &quot;</span><span class="p">,</span> <span class="n">accuracy_for_all_tasks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fully trained model accuracy:  0.8888666666666667
Incrementally trained model accuracy:  0.8439
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(BlockWorker pid=860324)</span> 2022-09-23 16:37:18,256	WARNING torch_predictor.py:53 -- You have `use_gpu` as False but there are 1 GPUs detected on host where prediction will only use CPU. Please consider explicitly setting `TorchPredictor(use_gpu=True)` or `batch_predictor.predict(ds, num_gpus_per_worker=1)` to enable GPU prediction.
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="next-steps">
<h1>Next Steps<a class="headerlink" href="torch_incremental_learning.html#next-steps" title="Permalink to this headline">#</a></h1>
<p>Once you’ve completed this notebook, you should be set to play around with scalable incremental training using Ray, either by trying more fancy algorithms for incremental learning other than naive fine-tuning, or attempting to scale out to larger datasets!</p>
<p>If you run into any issues, or have any feature requests, please file an issue on the <a class="reference external" href="https://github.com/ray-project/ray/issues">Ray Github</a>.</p>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="lightgbm_example.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Training a model with distributed LightGBM</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="rl_serving_example.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Serving reinforcement learning policy models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>