
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Fine-tuning a Torch object detection model &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/versionwarning.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../_static/js/docsearch.js"></script>
    <script src="../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../_static/js/custom.js"></script>
    <script defer="defer" src="../../_static/js/top-navigation.js"></script>
    <script src="../../_static/js/tags.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/ray-air/examples/torch_detection.html" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Convert existing PyTorch code to Ray AIR" href="convert_existing_pytorch_code_to_ray_air.html" />
    <link rel="prev" title="Training a Torch Image Classifier" href="torch_image_example.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "ray-air/examples/torch_detection", "programming_language": "py", "project": "ray", "proxied_api_host": "/_", "source_suffix": ".ipynb", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../getting-started.html">
   Ray AI Runtime (AIR)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../user-guides.html">
     User Guides
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     Examples
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="opt_deepspeed_batch_inference.html">
       Batch Inference with OPT 30B and Ray Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="torch_image_example.html">
       Training a Torch Image Classifier
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="torch_detection.html#">
       Fine-tuning a Torch object detection model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="convert_existing_pytorch_code_to_ray_air.html">
       Convert existing PyTorch code to Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="convert_existing_tf_code_to_ray_air.html">
       Convert existing Tensorflow/Keras code to Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tfx_tabular_train_to_serve.html">
       Tabular data training and serving with Keras and Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="huggingface_text_classification.html">
       Fine-tune a ü§ó Transformers model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="sklearn_example.html">
       Training a model with Sklearn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="xgboost_example.html">
       Training a model with distributed XGBoost
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="analyze_tuning_results.html">
       Hyperparameter tuning with XGBoostTrainer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="lightgbm_example.html">
       Training a model with distributed LightGBM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="torch_incremental_learning.html">
       Incremental Learning with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rl_serving_example.html">
       Serving reinforcement learning policy models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rl_online_example.html">
       Online reinforcement learning with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="rl_offline_example.html">
       Offline reinforcement learning with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="upload_to_comet_ml.html">
       Logging results and uploading models to Comet ML
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="upload_to_wandb.html">
       Logging results and uploading models to Weights &amp; Biases
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="feast_example.html">
       Integrate Ray AIR with Feast feature store
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="automl_with_ray_air.html">
       AutoML for time series forecasting with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="batch_tuning.html">
       Batch training &amp; tuning on Ray Tune
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="batch_forecasting.html">
       Parallel demand forecasting at scale using Ray Tune
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="stablediffusion_batch_prediction.html">
       Stable Diffusion Batch Prediction with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gptj_deepspeed_fine_tuning.html">
       GPT-J-6B Fine-Tuning with Ray AIR and DeepSpeed
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gptj_batch_prediction.html">
       GPT-J-6B Batch Prediction with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gptj_serving.html">
       GPT-J-6B Serving with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="dreambooth_finetuning.html">
       Fine-tuning DreamBooth with Ray AIR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="dolly_lightning_fsdp_finetuning.html">
       Fine-tune
       <code class="docutils literal notranslate">
        <span class="pre">
         dolly-v2-7b
        </span>
       </code>
       with Ray AIR LightningTrainer and FSDP
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/api.html">
     Ray AIR API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../benchmarks.html">
     Benchmarks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Fray-air/examples/torch_detection.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/ray-air/examples/torch_detection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/ray-air/examples/torch_detection.ipynb.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#before-you-begin">
   Before you begin
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#create-a-dataset">
   Create a
   <code class="docutils literal notranslate">
    <span class="pre">
     Dataset
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#define-a-custom-datasource">
     Define a custom datasource
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#read-annotations">
     Read annotations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#load-images-into-memory">
     Load images into memory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#split-the-dataset-into-train-and-test-sets">
     Split the dataset into train and test sets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#define-preprocessing-logic">
   Define preprocessing logic
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#fine-tune-the-object-detection-model">
   Fine-tune the object detection model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#define-the-training-loop">
     Define the training loop
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#fine-tune-the-model">
     Fine-tune the model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#evaluate-the-model-on-test-data">
   Evaluate the model on test data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#generate-predictions-on-the-test-data">
     Generate predictions on the test data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#evaluate-the-model">
     Evaluate the model
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Fine-tuning a Torch object detection model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#before-you-begin">
   Before you begin
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#create-a-dataset">
   Create a
   <code class="docutils literal notranslate">
    <span class="pre">
     Dataset
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#define-a-custom-datasource">
     Define a custom datasource
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#read-annotations">
     Read annotations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#load-images-into-memory">
     Load images into memory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#split-the-dataset-into-train-and-test-sets">
     Split the dataset into train and test sets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#define-preprocessing-logic">
   Define preprocessing logic
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#fine-tune-the-object-detection-model">
   Fine-tune the object detection model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#define-the-training-loop">
     Define the training loop
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#fine-tune-the-model">
     Fine-tune the model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="torch_detection.html#evaluate-the-model-on-test-data">
   Evaluate the model on test data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#generate-predictions-on-the-test-data">
     Generate predictions on the test data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="torch_detection.html#evaluate-the-model">
     Evaluate the model
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="fine-tuning-a-torch-object-detection-model">
<h1>Fine-tuning a Torch object detection model<a class="headerlink" href="torch_detection.html#fine-tuning-a-torch-object-detection-model" title="Permalink to this headline">#</a></h1>
<p>This tutorial explains how to fine-tune <code class="docutils literal notranslate"><span class="pre">fasterrcnn_resnet50_fpn</span></code> using the <a class="reference internal" href="../getting-started.html#air"><span class="std std-ref">Ray AI Runtime</span></a> for parallel data ingest and training.</p>
<p>Here‚Äôs what you‚Äôll do:</p>
<ol class="simple">
<li><p>Load raw images and <a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">VOC-style</a> annotations into a Dataset</p></li>
<li><p>Fine-tune <code class="docutils literal notranslate"><span class="pre">fasterrcnn_resnet50_fpn</span></code> (the backbone is pre-trained on ImageNet)</p></li>
<li><p>Evaluate the model‚Äôs accuracy</p></li>
</ol>
<p>You should be familiar with <a class="reference external" href="https://pytorch.org/">PyTorch</a> before starting the
tutorial. If you need a refresher, read PyTorch‚Äôs
<a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">training a classifier</a>
tutorial.</p>
<section id="before-you-begin">
<h2>Before you begin<a class="headerlink" href="torch_detection.html#before-you-begin" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Install the <a class="reference internal" href="../getting-started.html#air"><span class="std std-ref">Ray AI Runtime</span></a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install <span class="s1">&#39;ray[air]&#39;</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Install <code class="docutils literal notranslate"><span class="pre">torch</span></code>, <code class="docutils literal notranslate"><span class="pre">torchmetrics</span></code>, <code class="docutils literal notranslate"><span class="pre">torchvision</span></code>, and <code class="docutils literal notranslate"><span class="pre">xmltodict</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install torch torchmetrics torchvision xmltodict
</pre></div>
</div>
</div>
</div>
</section>
<section id="create-a-dataset">
<h2>Create a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code><a class="headerlink" href="torch_detection.html#create-a-dataset" title="Permalink to this headline">#</a></h2>
<p>You‚Äôll work with a subset of <a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC</a> that contains cats and dogs (the full dataset has 20 classes).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CLASS_TO_LABEL</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;background&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;cat&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;dog&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>The dataset contain two subdirectories: <code class="docutils literal notranslate"><span class="pre">JPEGImages</span></code> and <code class="docutils literal notranslate"><span class="pre">Annotations</span></code>. <code class="docutils literal notranslate"><span class="pre">JPEGImages</span></code> contains raw images, and
<code class="docutils literal notranslate"><span class="pre">Annotations</span></code> contains XML annotations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>AnimalDetection
‚îú‚îÄ‚îÄ Annotations
‚îÇ   ‚îú‚îÄ‚îÄ 2007_000063.xml
‚îÇ   ‚îú‚îÄ‚îÄ 2007_000528.xml
‚îÇ   ‚îî‚îÄ‚îÄ  ...
‚îî‚îÄ‚îÄ JPEGImages
    ‚îú‚îÄ‚îÄ 2007_000063.jpg
    ‚îú‚îÄ‚îÄ 2007_000528.jpg
    ‚îî‚îÄ‚îÄ  ...
</pre></div>
</div>
<section id="define-a-custom-datasource">
<h3>Define a custom datasource<a class="headerlink" href="torch_detection.html#define-a-custom-datasource" title="Permalink to this headline">#</a></h3>
<p>Each annotation describes the objects in an image.</p>
<p>For example, view this image of a dog:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">io</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;https://s3-us-west-2.amazonaws.com/air-example-data/AnimalDetection/JPEGImages/2007_000063.jpg&quot;</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
<span class="n">image</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/torch_detection_9_0.png" src="../../_images/torch_detection_9_0.png" />
</div>
</div>
<p>Then, print the image‚Äôs annotation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>curl <span class="s2">&quot;https://s3-us-west-2.amazonaws.com/air-example-data/AnimalDetection/Annotations/2007_000063.xml&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;annotation&gt;
	&lt;folder&gt;VOC2012&lt;/folder&gt;
	&lt;filename&gt;2007_000063.jpg&lt;/filename&gt;
	&lt;source&gt;
		&lt;database&gt;The VOC2007 Database&lt;/database&gt;
		&lt;annotation&gt;PASCAL VOC2007&lt;/annotation&gt;
		&lt;image&gt;flickr&lt;/image&gt;
	&lt;/source&gt;
	&lt;size&gt;
		&lt;width&gt;500&lt;/width&gt;
		&lt;height&gt;375&lt;/height&gt;
		&lt;depth&gt;3&lt;/depth&gt;
	&lt;/size&gt;
	&lt;segmented&gt;1&lt;/segmented&gt;
	&lt;object&gt;
		&lt;name&gt;dog&lt;/name&gt;
		&lt;pose&gt;Unspecified&lt;/pose&gt;
		&lt;truncated&gt;0&lt;/truncated&gt;
		&lt;difficult&gt;0&lt;/difficult&gt;
		&lt;bndbox&gt;
			&lt;xmin&gt;123&lt;/xmin&gt;
			&lt;ymin&gt;115&lt;/ymin&gt;
			&lt;xmax&gt;379&lt;/xmax&gt;
			&lt;ymax&gt;275&lt;/ymax&gt;
		&lt;/bndbox&gt;
	&lt;/object&gt;
&lt;/annotation&gt;
</pre></div>
</div>
</div>
</div>
<p>Notice how there‚Äôs one object labeled ‚Äúdog‚Äù</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">name</span><span class="o">&gt;</span><span class="n">dog</span><span class="o">&lt;/</span><span class="n">name</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">pose</span><span class="o">&gt;</span><span class="n">Unspecified</span><span class="o">&lt;/</span><span class="n">pose</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">truncated</span><span class="o">&gt;</span><span class="mi">0</span><span class="o">&lt;/</span><span class="n">truncated</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">difficult</span><span class="o">&gt;</span><span class="mi">0</span><span class="o">&lt;/</span><span class="n">difficult</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">bndbox</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="n">xmin</span><span class="o">&gt;</span><span class="mi">123</span><span class="o">&lt;/</span><span class="n">xmin</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="n">ymin</span><span class="o">&gt;</span><span class="mi">115</span><span class="o">&lt;/</span><span class="n">ymin</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="n">xmax</span><span class="o">&gt;</span><span class="mi">379</span><span class="o">&lt;/</span><span class="n">xmax</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="n">ymax</span><span class="o">&gt;</span><span class="mi">275</span><span class="o">&lt;/</span><span class="n">ymax</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">bndbox</span><span class="o">&gt;</span>
</pre></div>
</div>
<p><a class="reference internal" href="../../data/data.html#data"><span class="std std-ref">Ray Data</span></a> lets you read and preprocess data in parallel. Ray Data doesn‚Äôt
have built-in support for VOC-style annotations, so you‚Äôll need to define a custom
datasource.</p>
<p>A Datasource is an object that reads data of a particular type. For example, Ray Data
implements a Datasource that reads CSV files. Your datasource will parse labels and
bounding boxes from XML files. Later, you‚Äôll read the corresponding images.</p>
<p>To implement the datasource, extend the built-in <code class="docutils literal notranslate"><span class="pre">FileBasedDatasource</span></code> class
and override the <code class="docutils literal notranslate"><span class="pre">_read_file</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">xmltodict</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

<span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="n">FileBasedDatasource</span>
<span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">TensorArray</span>


<span class="k">class</span> <span class="nc">VOCAnnotationDatasource</span><span class="p">(</span><span class="n">FileBasedDatasource</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_read_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">pa</span><span class="o">.</span><span class="n">NativeFile</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">reader_args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
        <span class="n">annotation</span> <span class="o">=</span> <span class="n">xmltodict</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">text</span><span class="p">)[</span><span class="s2">&quot;annotation&quot;</span><span class="p">]</span>

        <span class="n">objects</span> <span class="o">=</span> <span class="n">annotation</span><span class="p">[</span><span class="s2">&quot;object&quot;</span><span class="p">]</span>
        <span class="c1"># If there&#39;s one object, `objects` is a `dict`; otherwise, it&#39;s a `list[dict]`.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objects</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">objects</span> <span class="o">=</span> <span class="p">[</span><span class="n">objects</span><span class="p">]</span>

        <span class="n">boxes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objects</span><span class="p">:</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;bndbox&quot;</span><span class="p">][</span><span class="s2">&quot;xmin&quot;</span><span class="p">])</span>
            <span class="n">y1</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;bndbox&quot;</span><span class="p">][</span><span class="s2">&quot;ymin&quot;</span><span class="p">])</span>
            <span class="n">x2</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;bndbox&quot;</span><span class="p">][</span><span class="s2">&quot;xmax&quot;</span><span class="p">])</span>
            <span class="n">y2</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;bndbox&quot;</span><span class="p">][</span><span class="s2">&quot;ymax&quot;</span><span class="p">])</span>
            <span class="n">boxes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">))</span>

        <span class="n">labels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">CLASS_TO_LABEL</span><span class="p">[</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]]</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objects</span><span class="p">]</span>

        <span class="n">filename</span> <span class="o">=</span> <span class="n">annotation</span><span class="p">[</span><span class="s2">&quot;filename&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;boxes&quot;</span><span class="p">:</span> <span class="n">TensorArray</span><span class="p">([</span><span class="n">boxes</span><span class="p">]),</span>
                <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">TensorArray</span><span class="p">([</span><span class="n">labels</span><span class="p">]),</span>
                <span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">filename</span><span class="p">],</span>
            <span class="p">}</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_rows_per_file</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="read-annotations">
<h3>Read annotations<a class="headerlink" href="torch_detection.html#read-annotations" title="Permalink to this headline">#</a></h3>
<p>To load the annotations into a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, call <code class="docutils literal notranslate"><span class="pre">ray.data.read_datasource</span></code> and pass
the custom datasource to the constructor. Ray will read the annotations in parallel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">ray</span>


<span class="n">annotations</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_datasource</span><span class="p">(</span>
    <span class="n">VOCAnnotationDatasource</span><span class="p">(),</span> <span class="n">paths</span><span class="o">=</span><span class="s2">&quot;s3://anonymous@air-example-data/AnimalDetection/Annotations&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>find: ‚Äò.git‚Äô: No such file or directory
2023-03-01 13:05:51,314	INFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.26.109:6379...
2023-03-01 13:05:51,327	INFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at <span class=" -Color -Color-Bold -Color-Bold-Green">https://console.anyscale-staging.com/api/v2/sessions/ses_mf1limh36cs2yrh9wkf6h2a75k/services?redirect_to=dashboard </span>
2023-03-01 13:05:52,269	INFO packaging.py:330 -- Pushing file package &#39;gcs://_ray_pkg_00aff5a3a84ab6438be1961b97a5beaa.zip&#39; (266.32MiB) to Ray cluster...
2023-03-01 13:05:58,529	INFO packaging.py:343 -- Successfully pushed file package &#39;gcs://_ray_pkg_00aff5a3a84ab6438be1961b97a5beaa.zip&#39;.
</pre></div>
</div>
</div>
</div>
<p>Look at the first two samples. <code class="docutils literal notranslate"><span class="pre">VOCAnnotationDatasource</span></code> should‚Äôve correctly parsed
labels and bounding boxes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">annotations</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;boxes&#39;: array([[123., 115., 379., 275.]]),
  &#39;labels&#39;: 2,
  &#39;filename&#39;: &#39;2007_000063.jpg&#39;},
 {&#39;boxes&#39;: array([[124.,  68., 319., 310.]]),
  &#39;labels&#39;: 1,
  &#39;filename&#39;: &#39;2007_000528.jpg&#39;}]
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-images-into-memory">
<h3>Load images into memory<a class="headerlink" href="torch_detection.html#load-images-into-memory" title="Permalink to this headline">#</a></h3>
<p>Each row of <code class="docutils literal notranslate"><span class="pre">annotations</span></code> contains the filename of an image.</p>
<p>Write a user-defined function that loads these images. For each annotation, your function will:</p>
<ol class="simple">
<li><p>Open the image associated with the annotation.</p></li>
<li><p>Add the image to a new <code class="docutils literal notranslate"><span class="pre">&quot;image&quot;</span></code> column.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>


<span class="k">def</span> <span class="nf">read_images</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;filename&quot;</span><span class="p">]:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;https://s3-us-west-2.amazonaws.com/air-example-data/AnimalDetection/JPEGImages&quot;</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>


<span class="n">dataset</span> <span class="o">=</span> <span class="n">annotations</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">read_images</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-03-01 13:06:08,005	INFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[read-&gt;MapBatches(read_images)]
read-&gt;MapBatches(read_images): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:24&lt;00:00,  5.25it/s]
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "016ad4fe729a4949bf6f59153b039ec7", "version_major": 2, "version_minor": 0}
</script></div>
</div>
</section>
<section id="split-the-dataset-into-train-and-test-sets">
<h3>Split the dataset into train and test sets<a class="headerlink" href="torch_detection.html#split-the-dataset-into-train-and-test-sets" title="Permalink to this headline">#</a></h3>
<p>Once you‚Äôve created a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, split the dataset into train and test sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="define-preprocessing-logic">
<h2>Define preprocessing logic<a class="headerlink" href="torch_detection.html#define-preprocessing-logic" title="Permalink to this headline">#</a></h2>
<p>A <code class="docutils literal notranslate"><span class="pre">Preprocessor</span></code> is an object that defines preprocessing logic. It‚Äôs the standard way
to preprocess data with Ray.</p>
<p>Create two preprocessors: one to transpose and scale images (<code class="docutils literal notranslate"><span class="pre">ToTensor</span></code>), and another to
randomly augment images every epoch (<code class="docutils literal notranslate"><span class="pre">RandomHorizontalFlip</span></code>). You‚Äôll later pass these
preprocessors to a <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="kn">from</span> <span class="nn">ray.data.preprocessors</span> <span class="kn">import</span> <span class="n">TorchVisionPreprocessor</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">TorchVisionPreprocessor</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="n">per_epoch_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">per_epoch_preprocessor</span> <span class="o">=</span> <span class="n">TorchVisionPreprocessor</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span> <span class="n">transform</span><span class="o">=</span><span class="n">per_epoch_transform</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fine-tune-the-object-detection-model">
<h2>Fine-tune the object detection model<a class="headerlink" href="torch_detection.html#fine-tune-the-object-detection-model" title="Permalink to this headline">#</a></h2>
<section id="define-the-training-loop">
<h3>Define the training loop<a class="headerlink" href="torch_detection.html#define-the-training-loop" title="Permalink to this headline">#</a></h3>
<p>Write a function that trains <code class="docutils literal notranslate"><span class="pre">fasterrcnn_resnet50_fpn</span></code>. Your code will look like
standard Torch code with a few changes.</p>
<p>Here are a few things to point out:</p>
<ol class="simple">
<li><p>Distribute the model with <code class="docutils literal notranslate"><span class="pre">ray.train.torch.prepare_model</span></code>. Don‚Äôt use <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code>.</p></li>
<li><p>Pass your Dataset to the Trainer. The Trainer automatically shards the data across workers.</p></li>
<li><p>Iterate over data with <code class="docutils literal notranslate"><span class="pre">DataIterator.iter_batches</span></code>. Don‚Äôt use a Torch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p>Pass preprocessors to the Trainer.</p></li>
</ol>
<p>In addition, report metrics and checkpoints with <code class="docutils literal notranslate"><span class="pre">session.report</span></code>. <code class="docutils literal notranslate"><span class="pre">session.report</span></code> tracks these metrics in Ray AIR‚Äôs internal bookkeeping, allowing you to monitor training and analyze training runs after they‚Äôve finished.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>

<span class="kn">from</span> <span class="nn">ray.air</span> <span class="kn">import</span> <span class="n">Checkpoint</span>
<span class="kn">from</span> <span class="nn">ray.air</span> <span class="kn">import</span> <span class="n">session</span>


<span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warmup_factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">1000</span>
        <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LinearLR</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span> <span class="n">start_factor</span><span class="o">=</span><span class="n">warmup_factor</span><span class="p">,</span> <span class="n">total_iters</span><span class="o">=</span><span class="mi">250</span>
        <span class="p">)</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>
    <span class="n">train_dataset_shard</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>

    <span class="n">batches</span> <span class="o">=</span> <span class="n">train_dataset_shard</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]]</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;boxes&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">boxes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">boxes</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;boxes&quot;</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="n">loss_dict</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">loss</span> <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">session</span><span class="o">.</span><span class="n">report</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;losses&quot;</span><span class="p">:</span> <span class="n">losses</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span>
                <span class="o">**</span><span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="p">}</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">train_loop_per_worker</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="c1"># By default, `fasterrcnn_resnet50_fpn`&#39;s backbone is pre-trained on ImageNet.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">detection</span><span class="o">.</span><span class="n">fasterrcnn_resnet50_fpn</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
        <span class="n">parameters</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span>
        <span class="n">momentum</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">],</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span> <span class="n">milestones</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr_steps&quot;</span><span class="p">],</span> <span class="n">gamma</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr_gamma&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]):</span>
        <span class="n">train_one_epoch</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="n">session</span><span class="o">.</span><span class="n">report</span><span class="p">({},</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fine-tune-the-model">
<h3>Fine-tune the model<a class="headerlink" href="torch_detection.html#fine-tune-the-model" title="Permalink to this headline">#</a></h3>
<p>Once you‚Äôve defined the training loop, create a <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> and pass the training
loop to the constructor. Then, call <code class="docutils literal notranslate"><span class="pre">TorchTrainer.fit</span></code> to train the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.air.config</span> <span class="kn">import</span> <span class="n">DatasetConfig</span><span class="p">,</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_loop_per_worker</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.02</span><span class="p">,</span>
        <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># You&#39;d normally train for 26 epochs.</span>
        <span class="s2">&quot;momentum&quot;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="s2">&quot;lr_steps&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">22</span><span class="p">],</span>
        <span class="s2">&quot;lr_gamma&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">},</span>
    <span class="n">dataset_config</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># Don&#39;t augment test images. Only apply `per_epoch_preprocessor` to the train</span>
        <span class="c1"># set.</span>
        <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DatasetConfig</span><span class="p">(</span>
            <span class="n">per_epoch_preprocessor</span><span class="o">=</span><span class="n">per_epoch_preprocessor</span>
        <span class="p">),</span>
    <span class="p">},</span>
    <span class="n">preprocessor</span><span class="o">=</span><span class="n">preprocessor</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-03-01 13:06:39,486	INFO instantiator.py:21 -- Created a temporary directory at /tmp/tmp1stz0z_r
2023-03-01 13:06:39,488	INFO instantiator.py:76 -- Writing /tmp/tmp1stz0z_r/_remote_module_non_scriptable.py
</pre></div>
</div>
<div class="output text_html"><div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2023-03-01 13:08:45</td></tr>
<tr><td>Running for: </td><td>00:02:05.37        </td></tr>
<tr><td>Memory:      </td><td>50.5/480.2 GiB     </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using FIFO scheduling algorithm.<br>Resources requested: 0/64 CPUs, 0/8 GPUs, 0.0/324.83 GiB heap, 0.0/143.21 GiB objects (0.0/1.0 accelerator_type:V100)
    </div>

  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name              </th><th>status    </th><th>loc               </th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_f5aa9_00000</td><td>TERMINATED</td><td>10.0.26.109:175347</td><td style="text-align: right;">   244</td><td style="text-align: right;">         108.703</td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(RayTrainWorker pid=175611) 2023-03-01 13:06:56,331	INFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=4]
(TorchTrainer pid=175347) 2023-03-01 13:07:00,615	INFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[TorchVisionPreprocessor] -&gt; AllToAllOperator[randomize_block_order]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(autoscaler +1m25s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.
(autoscaler +1m25s) Warning: The following resource request cannot be scheduled right now: {&#39;CPU&#39;: 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(TorchTrainer pid=175347) /home/ray/anaconda3/lib/python3.9/site-packages/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DataIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DataIterator docs.
(TorchTrainer pid=175347)   warnings.warn(
Stage 0:   0%|          | 0/1 [00:00&lt;?, ?it/s]
  0%|          | 0/1 [00:00&lt;?, ?it/s]=191352) 
Stage 1:   0%|          | 0/1 [00:00&lt;?, ?it/s]
(RayTrainWorker pid=175611) 2023-03-01 13:07:26,094	INFO train_loop_utils.py:307 -- Moving model to device: cuda:3
(RayTrainWorker pid=175611) 2023-03-01 13:07:29,092	INFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.
Stage 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03&lt;00:00,  3.96s/it]2023-03-01 13:07:29,436	INFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[TorchVisionPreprocessor]
(PipelineSplitExecutorCoordinator pid=191352) 
Stage 0: : 2it [00:08,  4.31s/it]                     2023-03-01 13:07:33,990	INFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[TorchVisionPreprocessor]
(RayTrainWorker pid=175612) 2023-03-01 13:07:34,394	WARNING plan.py:527 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#data-and-tune
(PipelineSplitExecutorCoordinator pid=191352) 
Stage 0: : 3it [00:13,  4.48s/it]2023-03-01 13:07:38,660	INFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[TorchVisionPreprocessor]
(RayTrainWorker pid=175612) /tmp/ipykernel_160001/3839218723.py:23: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
(RayTrainWorker pid=175614) /tmp/ipykernel_160001/3839218723.py:26: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
(RayTrainWorker pid=175611) /tmp/ipykernel_160001/3839218723.py:26: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
(RayTrainWorker pid=175613) /tmp/ipykernel_160001/3839218723.py:23: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
</pre></div>
</div>
<div class="output text_html"><div class="trialProgress">
  <h3>Trial Progress</h3>
  <table>
<thead>
<tr><th>Trial name              </th><th>date               </th><th>done  </th><th style="text-align: right;">  experiment_tag</th><th>hostname      </th><th style="text-align: right;">  iterations_since_restore</th><th>node_ip    </th><th style="text-align: right;">   pid</th><th>should_checkpoint  </th><th style="text-align: right;">  time_since_restore</th><th style="text-align: right;">  time_this_iter_s</th><th style="text-align: right;">  time_total_s</th><th style="text-align: right;">  timestamp</th><th style="text-align: right;">  training_iteration</th><th>trial_id   </th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_f5aa9_00000</td><td>2023-03-01_13-08-41</td><td>True  </td><td style="text-align: right;">               0</td><td>ip-10-0-26-109</td><td style="text-align: right;">                       244</td><td>10.0.26.109</td><td style="text-align: right;">175347</td><td>True               </td><td style="text-align: right;">             108.703</td><td style="text-align: right;">            4.2088</td><td style="text-align: right;">       108.703</td><td style="text-align: right;"> 1677704918</td><td style="text-align: right;">                 244</td><td>f5aa9_00000</td></tr>
</tbody>
</table>
</div>
<style>
.trialProgress {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
}
.trialProgress h3 {
  font-weight: bold;
}
.trialProgress td {
  white-space: nowrap;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(RayTrainWorker pid=175612) 2023-03-01 13:07:41,980	INFO distributed.py:1027 -- Reducer buckets have been rebuilt in this iteration.
(PipelineSplitExecutorCoordinator pid=191352) 
Stage 0: : 4it [01:11, 25.77s/it]2023-03-01 13:08:37,068	INFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[TorchVisionPreprocessor]
(RayTrainWorker pid=175614) 2023-03-01 13:08:37,464	WARNING plan.py:527 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#data-and-tune
2023-03-01 13:08:45,074	INFO tune.py:825 -- Total run time: 125.51 seconds (125.36 seconds for the tuning loop).
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="evaluate-the-model-on-test-data">
<h2>Evaluate the model on test data<a class="headerlink" href="torch_detection.html#evaluate-the-model-on-test-data" title="Permalink to this headline">#</a></h2>
<p>Now that you‚Äôve fine-tuned the model, you‚Äôll evaluate it on the test data.</p>
<section id="generate-predictions-on-the-test-data">
<h3>Generate predictions on the test data<a class="headerlink" href="torch_detection.html#generate-predictions-on-the-test-data" title="Permalink to this headline">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Predictors</span></code> let you perform scalable <a class="reference internal" href="../predictors.html#batch-prediction"><span class="std std-ref">batch prediction</span></a> and
<a class="reference internal" href="serving_guide.html#air-serving-guide"><span class="std std-ref">online inference</span></a>. To evaluate the model, you‚Äôll use
<code class="docutils literal notranslate"><span class="pre">BatchPredictor</span></code> to perform inference in a distributed fashion.</p>
<p>Create a <code class="docutils literal notranslate"><span class="pre">BatchPredictor</span></code> and pass <code class="docutils literal notranslate"><span class="pre">TorchDetectionPredictor</span></code> to the constructor. Then,
call <code class="docutils literal notranslate"><span class="pre">BatchPredictor.predict</span></code> to detect objects in the test data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train.batch_predictor</span> <span class="kn">import</span> <span class="n">BatchPredictor</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchDetectionPredictor</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">detection</span><span class="o">.</span><span class="n">fasterrcnn_resnet50_fpn</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">BatchPredictor</span><span class="o">.</span><span class="n">from_checkpoint</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">TorchDetectionPredictor</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">test_dataset</span><span class="p">,</span>
    <span class="n">feature_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span>
    <span class="n">keep_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;boxes&quot;</span><span class="p">,</span> <span class="s2">&quot;labels&quot;</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_gpus_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">predictions</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-03-01 13:08:48,113	INFO batch_predictor.py:214 -- `num_gpus_per_worker` is set for `BatchPreditor`.Automatically enabling GPU prediction for this predictor. To disable set `use_gpu` to `False` in `BatchPredictor.predict`.
2023-03-01 13:08:48,945	INFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[TorchVisionPreprocessor] -&gt; ActorPoolMapOperator[MapBatches(ScoringWrapper)]
TorchVisionPreprocessor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:17&lt;00:00,  1.49it/s]
MapBatches(ScoringWrapper), 0 actors [26 locality hits, 0 misses]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:32&lt;00:00,  1.25s/it]           
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "468b32006b5f440dae152b288d84d5d3", "version_major": 2, "version_minor": 0}
</script></div>
</div>
</section>
<section id="evaluate-the-model">
<h3>Evaluate the model<a class="headerlink" href="torch_detection.html#evaluate-the-model" title="Permalink to this headline">#</a></h3>
<p>Once you‚Äôve created the <code class="docutils literal notranslate"><span class="pre">predictions</span></code> dataset, iterate over the rows of the dataset
and compute the accuracy of the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchmetrics.detection.mean_ap</span> <span class="kn">import</span> <span class="n">MeanAveragePrecision</span>


<span class="n">metric</span> <span class="o">=</span> <span class="n">MeanAveragePrecision</span><span class="p">()</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">predictions</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">():</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;boxes&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;pred_boxes&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;scores&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;pred_scores&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;pred_labels&quot;</span><span class="p">]),</span>
        <span class="p">}</span>
    <span class="p">]</span>
    <span class="n">target</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;boxes&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;boxes&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]),</span>
        <span class="p">}</span>
    <span class="p">]</span>
    <span class="n">metric</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_160001/1622602304.py:8: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  &quot;boxes&quot;: torch.as_tensor(row[&quot;pred_boxes&quot;]),
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;map&#39;: tensor(0.0898),
 &#39;map_50&#39;: tensor(0.3034),
 &#39;map_75&#39;: tensor(0.0244),
 &#39;map_small&#39;: tensor(0.),
 &#39;map_medium&#39;: tensor(0.0158),
 &#39;map_large&#39;: tensor(0.0964),
 &#39;mar_1&#39;: tensor(0.1799),
 &#39;mar_10&#39;: tensor(0.3551),
 &#39;mar_100&#39;: tensor(0.3635),
 &#39;mar_small&#39;: tensor(0.),
 &#39;mar_medium&#39;: tensor(0.1063),
 &#39;mar_large&#39;: tensor(0.3818),
 &#39;map_per_class&#39;: tensor(-1.),
 &#39;mar_100_per_class&#39;: tensor(-1.)}
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="torch_image_example.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Training a Torch Image Classifier</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="convert_existing_pytorch_code_to_ray_air.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Convert existing PyTorch code to Ray AIR</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>